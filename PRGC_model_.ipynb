{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRGC model .ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlwUYepF8H4lcHDu28rTl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e96a70248dfc4fd1a223ec33f3df9983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1aa4776df7c420095bc3ed0caf02200",
              "IPY_MODEL_df7d3fbda5cd4c83aa43df32f01ed93f",
              "IPY_MODEL_ad397893a1774d9d8833c0439b063bde"
            ],
            "layout": "IPY_MODEL_03e6fa6534514f0cb6661446fb0dfc96"
          }
        },
        "f1aa4776df7c420095bc3ed0caf02200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9270773f3a44e84811f86f9847ef1bc",
            "placeholder": "​",
            "style": "IPY_MODEL_0b408b14573441c684ba512541209a99",
            "value": "Downloading: 100%"
          }
        },
        "df7d3fbda5cd4c83aa43df32f01ed93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee044a395dd449fba6fda4a54301a210",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a233d73c60994c87b1062ca489ff1448",
            "value": 213450
          }
        },
        "ad397893a1774d9d8833c0439b063bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_639d36004ea34b6faa09c51971605c08",
            "placeholder": "​",
            "style": "IPY_MODEL_08b15d56fda945a8b72a0659df94cbab",
            "value": " 208k/208k [00:00&lt;00:00, 2.71MB/s]"
          }
        },
        "03e6fa6534514f0cb6661446fb0dfc96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9270773f3a44e84811f86f9847ef1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b408b14573441c684ba512541209a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee044a395dd449fba6fda4a54301a210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a233d73c60994c87b1062ca489ff1448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "639d36004ea34b6faa09c51971605c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b15d56fda945a8b72a0659df94cbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62f7da6e2ab34bb4b7c38958aa8a8032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d047457bbe074ec8a1f688c2e57180c5",
              "IPY_MODEL_e5308807c3eb4d1c9ec04c6dc3c9ad4a",
              "IPY_MODEL_9ae2d078bbe44cac9e9a92c39b19ef55"
            ],
            "layout": "IPY_MODEL_57683178d93e4a139127a658d246bd3c"
          }
        },
        "d047457bbe074ec8a1f688c2e57180c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e5a682cc32346e48fb84b7381c4c230",
            "placeholder": "​",
            "style": "IPY_MODEL_86e2fe0cbc744e018ef62f26cd0b4556",
            "value": "Downloading: 100%"
          }
        },
        "e5308807c3eb4d1c9ec04c6dc3c9ad4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0269b37e706f4d0eaf684549c79bda1c",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6afc3bd89e5e4c8b858f9491c16f6711",
            "value": 29
          }
        },
        "9ae2d078bbe44cac9e9a92c39b19ef55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b353054eca146458fe463b179d71db6",
            "placeholder": "​",
            "style": "IPY_MODEL_2654462d6f564373b0206197543ec645",
            "value": " 29.0/29.0 [00:00&lt;00:00, 895B/s]"
          }
        },
        "57683178d93e4a139127a658d246bd3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5a682cc32346e48fb84b7381c4c230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e2fe0cbc744e018ef62f26cd0b4556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0269b37e706f4d0eaf684549c79bda1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6afc3bd89e5e4c8b858f9491c16f6711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b353054eca146458fe463b179d71db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2654462d6f564373b0206197543ec645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de8223ee0c484d6e9bb5a2be10fcec3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6526a145f2b1457280d00788a38c102d",
              "IPY_MODEL_e8c3be8d108e4999b7ad1398d7e2fef8",
              "IPY_MODEL_6966618835ad49c6a8aa67e363afdc75"
            ],
            "layout": "IPY_MODEL_1f2718af44d44953a0791def82a3ed25"
          }
        },
        "6526a145f2b1457280d00788a38c102d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5038381f78d34f8e8485bb8f5b728271",
            "placeholder": "​",
            "style": "IPY_MODEL_3381fa257f0642ba907ba4d906ccde1f",
            "value": "Downloading: 100%"
          }
        },
        "e8c3be8d108e4999b7ad1398d7e2fef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f414cef0cab24698b7b87f9f38367ae7",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8fef0122cd94aa3bf4f3c219a5f70bc",
            "value": 570
          }
        },
        "6966618835ad49c6a8aa67e363afdc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0d7927150394dc0bb7da5015f21a043",
            "placeholder": "​",
            "style": "IPY_MODEL_4e6a086b288e4d2b84b842dc6eb33638",
            "value": " 570/570 [00:00&lt;00:00, 17.0kB/s]"
          }
        },
        "1f2718af44d44953a0791def82a3ed25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5038381f78d34f8e8485bb8f5b728271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3381fa257f0642ba907ba4d906ccde1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f414cef0cab24698b7b87f9f38367ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fef0122cd94aa3bf4f3c219a5f70bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0d7927150394dc0bb7da5015f21a043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6a086b288e4d2b84b842dc6eb33638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3035a5b0fa4d4772bfcd2063779f834c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_861c472b2c8445dd82884c7d45bbe471",
              "IPY_MODEL_daea055a3ed34a5da770d5421d8735ff",
              "IPY_MODEL_4eae44a431ea4fe79d67ac45d3984fba"
            ],
            "layout": "IPY_MODEL_fe390f30126e461f90444a74d4d6c38f"
          }
        },
        "861c472b2c8445dd82884c7d45bbe471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1839e5a6d21447c286d3a4a0c228942b",
            "placeholder": "​",
            "style": "IPY_MODEL_5fa9a3db6c4a4b1a9646c95699847527",
            "value": "Downloading: 100%"
          }
        },
        "daea055a3ed34a5da770d5421d8735ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d1a7b62503c4cccb3b40b29edf962cf",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ecafed900194d8dba0003001ce48542",
            "value": 435779157
          }
        },
        "4eae44a431ea4fe79d67ac45d3984fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ce9740fc0f4b5e8f4dd58425921d00",
            "placeholder": "​",
            "style": "IPY_MODEL_c6d2df16c5904c3983bef057f8c720d5",
            "value": " 416M/416M [00:10&lt;00:00, 43.4MB/s]"
          }
        },
        "fe390f30126e461f90444a74d4d6c38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1839e5a6d21447c286d3a4a0c228942b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa9a3db6c4a4b1a9646c95699847527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d1a7b62503c4cccb3b40b29edf962cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ecafed900194d8dba0003001ce48542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8ce9740fc0f4b5e8f4dd58425921d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d2df16c5904c3983bef057f8c720d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hou-jing/paper_record_public/blob/main/PRGC_model_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VcVt9pwLL2qB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/kj5f1vcomr21xyv/NYT11.zip?dl=0  -O NYT11.zip \n",
        "!unzip -q NYT11.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBtuv7jML23d",
        "outputId": "ccf2ebcf-995d-4935-e465-bbe2d6045c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-19 15:03:48--  https://www.dropbox.com/s/kj5f1vcomr21xyv/NYT11.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/kj5f1vcomr21xyv/NYT11.zip [following]\n",
            "--2022-03-19 15:03:49--  https://www.dropbox.com/s/raw/kj5f1vcomr21xyv/NYT11.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc7f408df8b200def925b7fad63a.dl.dropboxusercontent.com/cd/0/inline/BhzGRYrXavN89I_QTk8TysCrOE90kBHxSJl6tt4mDHl79uqUgg5dBGWVwImGPmqRvjElcCnOpHDlh_aIrtrCmjSNJY2PkAfzynh_AgXrE957_WAYA5KutfOcRFENMLW3Qm8QhRMCOotFq2YBjCjMt9RMCjWuB-97BBt8yXmvXk3vtQ/file# [following]\n",
            "--2022-03-19 15:03:49--  https://uc7f408df8b200def925b7fad63a.dl.dropboxusercontent.com/cd/0/inline/BhzGRYrXavN89I_QTk8TysCrOE90kBHxSJl6tt4mDHl79uqUgg5dBGWVwImGPmqRvjElcCnOpHDlh_aIrtrCmjSNJY2PkAfzynh_AgXrE957_WAYA5KutfOcRFENMLW3Qm8QhRMCOotFq2YBjCjMt9RMCjWuB-97BBt8yXmvXk3vtQ/file\n",
            "Resolving uc7f408df8b200def925b7fad63a.dl.dropboxusercontent.com (uc7f408df8b200def925b7fad63a.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc7f408df8b200def925b7fad63a.dl.dropboxusercontent.com (uc7f408df8b200def925b7fad63a.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BhwbHmGVEwg8isR0TpS3itipQswxCiSbkQKt4Fqs23KIzW-Rc8KXNc9atE3VHCna1qG71xwRHyUXDclRXpWeJ6Sa64qSZe-Eq4Qbx_nUY5mCI-odlzvlsboSqaZtW09LgclHPgnf1Ma6NJoLQjvUVyoOzhJ8cwrPzETAP6UxRQvUT92KKgSWr-qKgg-qlW025LemQ3c800nUl029MOWVdsR6v43zM6H-09AnDHN10ItthsGP4NRwrndq8NsaA5yoLM5VKtbowtCR0GG3uhwwTbbUPEKPd1tfAIr41KtkrIoFg4nF_RCaHP7Opck-kVd3JeaRxeyCilGV7PP4BIJqCzJFzYu0JF1XjSBR3rX8Zeoeu7NNj-sOz9r6h02_VYnCZxIDQUQJXdGyXS74Quf0AAjLGjpZyte4SeZT4dhl9c0Pqw/file [following]\n",
            "--2022-03-19 15:03:49--  https://uc7f408df8b200def925b7fad63a.dl.dropboxusercontent.com/cd/0/inline2/BhwbHmGVEwg8isR0TpS3itipQswxCiSbkQKt4Fqs23KIzW-Rc8KXNc9atE3VHCna1qG71xwRHyUXDclRXpWeJ6Sa64qSZe-Eq4Qbx_nUY5mCI-odlzvlsboSqaZtW09LgclHPgnf1Ma6NJoLQjvUVyoOzhJ8cwrPzETAP6UxRQvUT92KKgSWr-qKgg-qlW025LemQ3c800nUl029MOWVdsR6v43zM6H-09AnDHN10ItthsGP4NRwrndq8NsaA5yoLM5VKtbowtCR0GG3uhwwTbbUPEKPd1tfAIr41KtkrIoFg4nF_RCaHP7Opck-kVd3JeaRxeyCilGV7PP4BIJqCzJFzYu0JF1XjSBR3rX8Zeoeu7NNj-sOz9r6h02_VYnCZxIDQUQJXdGyXS74Quf0AAjLGjpZyte4SeZT4dhl9c0Pqw/file\n",
            "Reusing existing connection to uc7f408df8b200def925b7fad63a.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6640657 (6.3M) [application/zip]\n",
            "Saving to: ‘NYT11.zip’\n",
            "\n",
            "NYT11.zip           100%[===================>]   6.33M  29.2MB/s    in 0.2s    \n",
            "\n",
            "2022-03-19 15:03:50 (29.2 MB/s) - ‘NYT11.zip’ saved [6640657/6640657]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "yCf_5lzwPUba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f40543-cbc5-46c8-bd36-3a096471eedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 32.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/pm4hrky2hxvv2po/cased_L-12_H-768_A-12%20%281%29.zip?dl=0  -O pretrained_bert_models.zip\n",
        "!unzip -q pretrained_bert_models.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT01JOz2Sm1_",
        "outputId": "460c24c0-8216-4414-f424-0b0efd6e3449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-19 15:04:08--  https://www.dropbox.com/s/pm4hrky2hxvv2po/cased_L-12_H-768_A-12%20%281%29.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/pm4hrky2hxvv2po/cased_L-12_H-768_A-12%20%281%29.zip [following]\n",
            "--2022-03-19 15:04:08--  https://www.dropbox.com/s/raw/pm4hrky2hxvv2po/cased_L-12_H-768_A-12%20%281%29.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc13973f5a618d717d7222e0fe6.dl.dropboxusercontent.com/cd/0/inline/BhwFRuqBw0lIYN3CxhmCZ2vHV0OurvKPaRrYZTtoMzw426F6F9LOozGDvW-gpfirfBKEOtecwmAk3fwV68OloeNiDC1XDrNuvf18kzW9ROa9o5TLSYKsCNw6BGg0xKiBMdeMrSWD53p7MNTrFFTSZW_gdknHy-fR4LnnyZ5RWb5ipg/file# [following]\n",
            "--2022-03-19 15:04:08--  https://ucc13973f5a618d717d7222e0fe6.dl.dropboxusercontent.com/cd/0/inline/BhwFRuqBw0lIYN3CxhmCZ2vHV0OurvKPaRrYZTtoMzw426F6F9LOozGDvW-gpfirfBKEOtecwmAk3fwV68OloeNiDC1XDrNuvf18kzW9ROa9o5TLSYKsCNw6BGg0xKiBMdeMrSWD53p7MNTrFFTSZW_gdknHy-fR4LnnyZ5RWb5ipg/file\n",
            "Resolving ucc13973f5a618d717d7222e0fe6.dl.dropboxusercontent.com (ucc13973f5a618d717d7222e0fe6.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucc13973f5a618d717d7222e0fe6.dl.dropboxusercontent.com (ucc13973f5a618d717d7222e0fe6.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bhx_DBiLL8B8ff8YafvHHTIcwFkvld0L-mWPoSlAnlQtTlW61EzCspSfpaIaEzG0gH5hWNUnnOrpw28clZOXCJl-x7Oz8rfSXUqj5zxjj3GKAyGn8fVuxf6D_GGWXu54_XJ-IDGVGpb4iEysuxv-hY8XxJCoLpX9lHIFqXz_0MQgQ8LHDqRvrVirjsOt-kPQUDrUgHsYv454zNLqMWbWM7AzVidcLW5uOsvM4catpIDSJ0FnqozLk-YPPngKLIVbdhUPdXYOZc5iyBm0CtBFa5T7_W6jGYKHDzlI4Y_AombZI8y8bpTkD0mCm6vbXjMldTNVaggbrL3cuTDmofAWrItHBQv7wG3y8OI3Kjxadz_U34pfK9gjcZKvoDePhb2oVCSAiOCVX3hNXsPidRIyURxXZDVbDM7Zqx12roxSoxs4Zw/file [following]\n",
            "--2022-03-19 15:04:08--  https://ucc13973f5a618d717d7222e0fe6.dl.dropboxusercontent.com/cd/0/inline2/Bhx_DBiLL8B8ff8YafvHHTIcwFkvld0L-mWPoSlAnlQtTlW61EzCspSfpaIaEzG0gH5hWNUnnOrpw28clZOXCJl-x7Oz8rfSXUqj5zxjj3GKAyGn8fVuxf6D_GGWXu54_XJ-IDGVGpb4iEysuxv-hY8XxJCoLpX9lHIFqXz_0MQgQ8LHDqRvrVirjsOt-kPQUDrUgHsYv454zNLqMWbWM7AzVidcLW5uOsvM4catpIDSJ0FnqozLk-YPPngKLIVbdhUPdXYOZc5iyBm0CtBFa5T7_W6jGYKHDzlI4Y_AombZI8y8bpTkD0mCm6vbXjMldTNVaggbrL3cuTDmofAWrItHBQv7wG3y8OI3Kjxadz_U34pfK9gjcZKvoDePhb2oVCSAiOCVX3hNXsPidRIyURxXZDVbDM7Zqx12roxSoxs4Zw/file\n",
            "Reusing existing connection to ucc13973f5a618d717d7222e0fe6.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 404261442 (386M) [application/zip]\n",
            "Saving to: ‘pretrained_bert_models.zip’\n",
            "\n",
            "pretrained_bert_mod 100%[===================>] 385.53M   103MB/s    in 3.9s    \n",
            "\n",
            "2022-03-19 15:04:13 (98.9 MB/s) - ‘pretrained_bert_models.zip’ saved [404261442/404261442]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils"
      ],
      "metadata": {
        "id": "HaQfPjSOR3bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data/NYT'"
      ],
      "metadata": {
        "id": "en6QfIY3VdpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /usr/bin/env python\n",
        "# coding=utf-8\n",
        "\"\"\"utils\"\"\"\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "\n",
        "Label2IdxSub = {\"B-H\": 1, \"I-H\": 2, \"O\": 0}\n",
        "Label2IdxObj = {\"B-T\": 1, \"I-T\": 2, \"O\": 0}\n",
        "\n",
        "\n",
        "class Params:\n",
        "    \"\"\"参数定义\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ex_index=1, corpus_type='NYT'):\n",
        "        # self.root_path = Path(os.path.abspath(os.path.dirname(__file__)))\n",
        "        self.data_dir = f'data/{corpus_type}'\n",
        "        self.ex_dir = f'experiments/ex{ex_index}'\n",
        "        self.model_dir =f'model/ex{ex_index}'\n",
        "        self.bert_model_dir = 'cased_L-12_H-768_A-12'\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.n_gpu = torch.cuda.device_count()\n",
        "        self.max_seq_length = 100\n",
        "        self.data_cache = False\n",
        "        self.train_batch_size = 1 if 'WebNLG' in corpus_type else 1\n",
        "        self.val_batch_size = 1\n",
        "        self.test_batch_size = 1\n",
        "\n",
        "        # self.train_batch_size = 6 if 'WebNLG' in corpus_type else 64\n",
        "        # self.val_batch_size = 24\n",
        "        # self.test_batch_size = 64\n",
        "        # PRST parameters\n",
        "        self.seq_tag_size = len(Label2IdxSub)\n",
        "        # load label2id\n",
        "        self.rel2idx = json.load(open(self.data_dir+'/rel2id.json', 'r', encoding='utf-8'))[-1]\n",
        "        self.rel_num = len(self.rel2idx)\n",
        "\n",
        "        # early stop strategy\n",
        "        self.min_epoch_num = 20\n",
        "        self.patience = 0.00001\n",
        "        self.patience_num = 20\n",
        "\n",
        "        # learning rate\n",
        "        self.fin_tuning_lr = 1e-4\n",
        "        self.downs_en_lr = 1e-3\n",
        "        self.clip_grad = 2.\n",
        "        self.drop_prob = 0.3  # dropout\n",
        "        self.weight_decay_rate = 0.01\n",
        "        self.warmup_prop = 0.1\n",
        "        self.gradient_accumulation_steps = 2\n",
        "\n",
        "    def load(self, json_path):\n",
        "        \"\"\"Loads parameters from json file\"\"\"\n",
        "        with open(json_path) as f:\n",
        "            params = json.load(f)\n",
        "            self.__dict__.update(params)\n",
        "\n",
        "    def save(self, json_path):\n",
        "        \"\"\"保存配置到json文件\n",
        "        \"\"\"\n",
        "        params = {}\n",
        "        with open(json_path, 'w') as f:\n",
        "            for k, v in self.__dict__.items():\n",
        "                if isinstance(v, (str, int, float, bool)):\n",
        "                    params[k] = v\n",
        "            json.dump(params, f, indent=4)\n",
        "\n",
        "\n",
        "class RunningAverage:\n",
        "    \"\"\"A simple class that maintains the running average of a quantity\n",
        "\n",
        "    Example:\n",
        "    ```\n",
        "    loss_avg = RunningAverage()\n",
        "    loss_avg.update(2)\n",
        "    loss_avg.update(4)\n",
        "    loss_avg() = 3\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.steps = 0\n",
        "        self.total = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        self.total += val\n",
        "        self.steps += 1\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.total / float(self.steps)\n",
        "\n",
        "\n",
        "def set_logger(save=False, log_path=None):\n",
        "    \"\"\"Set the logger to log info in terminal and file `log_path`.\n",
        "\n",
        "    In general, it is useful to have a logger so that every output to the terminal is saved\n",
        "    in a permanent file. Here we save it to `model_dir/train.log`.\n",
        "\n",
        "    Example:\n",
        "    ```\n",
        "    logging.info(\"Starting training...\")\n",
        "    ```\n",
        "\n",
        "    Args:\n",
        "        log_path: (string) where to log\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    if save and not os.path.exists(os.path.dirname(log_path)):\n",
        "        os.makedirs(os.path.dirname(log_path))\n",
        "\n",
        "    if not logger.handlers:\n",
        "        if save:\n",
        "            # Logging to a file\n",
        "            file_handler = logging.FileHandler(log_path)\n",
        "            file_handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n",
        "            logger.addHandler(file_handler)\n",
        "\n",
        "        # Logging to console\n",
        "        stream_handler = logging.StreamHandler()\n",
        "        stream_handler.setFormatter(logging.Formatter('%(message)s'))\n",
        "        logger.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint):\n",
        "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
        "    checkpoint + 'best.pth.tar'\n",
        "\n",
        "    Args:\n",
        "        state: (dict) contains the entire model, may contain other keys such as epoch, optimizer\n",
        "        is_best: (bool) True if it is the best model seen till now\n",
        "        checkpoint: (string) folder where parameters are to be saved\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
        "    if not os.path.exists(checkpoint):\n",
        "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
        "        os.makedirs(checkpoint)\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, optimizer=True):\n",
        "    \"\"\"Loads entire model from file_path. If optimizer is True, loads\n",
        "    optimizer assuming it is present in checkpoint.\n",
        "\n",
        "    Args:\n",
        "        checkpoint: (string) filename which needs to be loaded\n",
        "        optimizer: (bool) resume optimizer from checkpoint\n",
        "    \"\"\"\n",
        "    if not os.path.exists(checkpoint):\n",
        "        raise ValueError(\"File doesn't exist {}\".format(checkpoint))\n",
        "    checkpoint = torch.load(checkpoint, map_location=torch.device('cpu'))\n",
        "\n",
        "    if optimizer:\n",
        "        return checkpoint['model'], checkpoint['optim']\n",
        "    return checkpoint['model']\n"
      ],
      "metadata": {
        "id": "-vztLjlwVWey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataloader_utils"
      ],
      "metadata": {
        "id": "fE0L8ZkmRvgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "import json\n",
        "import random\n",
        "from multiprocessing import Pool\n",
        "import functools\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from itertools import chain\n",
        "\n",
        "\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"a single set of samples of data\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, text, en_pair_list, re_list, rel2ens):\n",
        "        self.text = text\n",
        "        self.en_pair_list = en_pair_list\n",
        "        self.re_list = re_list\n",
        "        self.rel2ens = rel2ens\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"\n",
        "    Desc:\n",
        "        a single set of features of data\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_tokens,\n",
        "                 input_ids,\n",
        "                 attention_mask,\n",
        "                 seq_tag=None,\n",
        "                 corres_tag=None,#gloal matrix\n",
        "                 relation=None,\n",
        "                 triples=None,\n",
        "                 rel_tag=None\n",
        "                 ):\n",
        "        self.input_tokens = input_tokens\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.seq_tag = seq_tag\n",
        "        self.corres_tag = corres_tag\n",
        "        self.relation = relation\n",
        "        self.triples = triples\n",
        "        self.rel_tag = rel_tag\n",
        "\n",
        "\n",
        "def read_examples(data_dir, data_sign, rel2idx):\n",
        "    \"\"\"load data to InputExamples\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "\n",
        "    # read src data\n",
        "    with open(data_dir + f'/{data_sign}_triples.json', \"r\", encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "        for sample in data:\n",
        "            text = sample['text']\n",
        "            rel2ens = defaultdict(list)\n",
        "            en_pair_list = []\n",
        "            re_list = []\n",
        "\n",
        "            for triple in sample['triple_list']:\n",
        "                en_pair_list.append([triple[0], triple[-1]])\n",
        "                re_list.append(rel2idx[triple[1]])\n",
        "                rel2ens[rel2idx[triple[1]]].append((triple[0], triple[-1]))\n",
        "            example = InputExample(text=text, en_pair_list=en_pair_list, re_list=re_list, rel2ens=rel2ens)\n",
        "            examples.append(example)\n",
        "    print(\"InputExamples:\", len(examples))\n",
        "    return examples\n",
        "\n",
        "\n",
        "def find_head_idx(source, target):\n",
        "    target_len = len(target)\n",
        "    for i in range(len(source)):\n",
        "        if source[i: i + target_len] == target:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "#返回的是sub_head, obj_head, sub, obj\n",
        "def _get_so_head(en_pair, tokenizer, text_tokens):\n",
        "    sub = tokenizer.tokenize(en_pair[0])\n",
        "    obj = tokenizer.tokenize(en_pair[1])\n",
        "    sub_head = find_head_idx(source=text_tokens, target=sub)\n",
        "    if sub == obj:\n",
        "        obj_head = find_head_idx(source=text_tokens[sub_head + len(sub):], target=obj)\n",
        "        if obj_head != -1:\n",
        "            obj_head += sub_head + len(sub)\n",
        "        else:\n",
        "            obj_head = sub_head\n",
        "    else:\n",
        "        obj_head = find_head_idx(source=text_tokens, target=obj)\n",
        "    return sub_head, obj_head, sub, obj\n",
        "\n",
        "\n",
        "def convert(example, max_text_len, tokenizer, rel2idx, data_sign, ex_params):\n",
        "    \"\"\"convert function\n",
        "    \"\"\"\n",
        "    text_tokens = tokenizer.tokenize(example.text)\n",
        "    # cut off\n",
        "    if len(text_tokens) > max_text_len:\n",
        "        text_tokens = text_tokens[:max_text_len]\n",
        "\n",
        "    # token to id\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(text_tokens)\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "    # zero-padding up to the sequence length\n",
        "    if len(input_ids) < max_text_len:\n",
        "        pad_len = max_text_len - len(input_ids)\n",
        "        # token_pad_id=0\n",
        "        input_ids += [0] * pad_len\n",
        "        attention_mask += [0] * pad_len\n",
        "\n",
        "    # train data\n",
        "    if data_sign == 'train':\n",
        "        # construct tags of correspondence and relation\n",
        "        corres_tag = np.zeros((max_text_len, max_text_len))\n",
        "        rel_tag = len(rel2idx) * [0]\n",
        "        for en_pair, rel in zip(example.en_pair_list, example.re_list):\n",
        "            # get sub and obj head\n",
        "            sub_head, obj_head, _, _ = _get_so_head(en_pair, tokenizer, text_tokens)\n",
        "            # construct relation tag\n",
        "            rel_tag[rel] = 1\n",
        "            if sub_head != -1 and obj_head != -1:\n",
        "                corres_tag[sub_head][obj_head] = 1\n",
        "\n",
        "        sub_feats = []\n",
        "        # positive samples\n",
        "        #给头尾实体做tag标注（tags_sub，tags_obj）\n",
        "        for rel, en_ll in example.rel2ens.items():\n",
        "            # init\n",
        "            tags_sub = max_text_len * [Label2IdxSub['O']]\n",
        "            tags_obj = max_text_len * [Label2IdxSub['O']]\n",
        "            for en in en_ll:\n",
        "                # get sub and obj head\n",
        "                sub_head, obj_head, sub, obj = _get_so_head(en, tokenizer, text_tokens)\n",
        "                if sub_head != -1 and obj_head != -1:\n",
        "                    if sub_head + len(sub) <= max_text_len:\n",
        "                        tags_sub[sub_head] = Label2IdxSub['B-H']\n",
        "                        tags_sub[sub_head + 1:sub_head + len(sub)] = (len(sub) - 1) * [Label2IdxSub['I-H']]\n",
        "                    if obj_head + len(obj) <= max_text_len:\n",
        "                        tags_obj[obj_head] = Label2IdxObj['B-T']\n",
        "                        tags_obj[obj_head + 1:obj_head + len(obj)] = (len(obj) - 1) * [Label2IdxObj['I-T']]\n",
        "            seq_tag = [tags_sub, tags_obj]\n",
        "\n",
        "            # sanity check\n",
        "            assert len(input_ids) == len(tags_sub) == len(tags_obj) == len(\n",
        "                attention_mask) == max_text_len, f'length is not equal!!'\n",
        "            sub_feats.append(InputFeatures(\n",
        "                input_tokens=text_tokens,\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                corres_tag=corres_tag,\n",
        "                seq_tag=seq_tag,\n",
        "                relation=rel,\n",
        "                rel_tag=rel_tag\n",
        "            ))\n",
        "        # relation judgement ablation\n",
        "        if not ex_params['ensure_rel']:\n",
        "            # negative samples\n",
        "            neg_rels = set(rel2idx.values()).difference(set(example.re_list))\n",
        "            neg_rels = random.sample(neg_rels, k=ex_params['num_negs'])\n",
        "            for neg_rel in neg_rels:\n",
        "                # init\n",
        "                seq_tag = max_text_len * [Label2IdxSub['O']]\n",
        "                # sanity check\n",
        "                assert len(input_ids) == len(seq_tag) == len(attention_mask) == max_text_len, f'length is not equal!!'\n",
        "                seq_tag = [seq_tag, seq_tag]\n",
        "                sub_feats.append(InputFeatures(\n",
        "                    input_tokens=text_tokens,\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    corres_tag=corres_tag,\n",
        "                    seq_tag=seq_tag,\n",
        "                    relation=neg_rel,\n",
        "                    rel_tag=rel_tag\n",
        "                ))\n",
        "    # val and test data\n",
        "    else:\n",
        "        triples = []\n",
        "        for rel, en in zip(example.re_list, example.en_pair_list):\n",
        "            # get sub and obj head\n",
        "            sub_head, obj_head, sub, obj = _get_so_head(en, tokenizer, text_tokens)\n",
        "            if sub_head != -1 and obj_head != -1:\n",
        "                h_chunk = ('H', sub_head, sub_head + len(sub))\n",
        "                t_chunk = ('T', obj_head, obj_head + len(obj))\n",
        "                triples.append((h_chunk, t_chunk, rel))\n",
        "        sub_feats = [\n",
        "            InputFeatures(\n",
        "                input_tokens=text_tokens,\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                triples=triples\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    # get sub-feats\n",
        "    return sub_feats\n",
        "\n",
        "\n",
        "def convert_examples_to_features(params, examples, tokenizer, rel2idx, data_sign, ex_params):\n",
        "    \"\"\"convert examples to features.\n",
        "    :param examples (List[InputExamples])\n",
        "    \"\"\"\n",
        "    max_text_len = params.max_seq_length\n",
        "    # multi-process\n",
        "    with Pool(10) as p:\n",
        "        convert_func = functools.partial(convert, max_text_len=max_text_len, tokenizer=tokenizer, rel2idx=rel2idx,\n",
        "                                         data_sign=data_sign, ex_params=ex_params)\n",
        "        features = p.map(func=convert_func, iterable=examples)\n",
        "\n",
        "    return list(chain(*features))\n"
      ],
      "metadata": {
        "id": "Gk98vmXTVRG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataloader"
      ],
      "metadata": {
        "id": "ibAtUh1EPM_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /usr/bin/env python\n",
        "# coding=utf-8\n",
        "\"\"\"Dataloader\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# from dataloader_utils import read_examples, convert_examples_to_features\n",
        "\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "    \"\"\"Pytorch Dataset for InputFeatures\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.features[index]\n",
        "\n",
        "\n",
        "class CustomDataLoader(object):\n",
        "    def __init__(self, params):\n",
        "        self.params = params\n",
        "\n",
        "        self.train_batch_size = params.train_batch_size\n",
        "        self.val_batch_size = params.val_batch_size\n",
        "        self.test_batch_size = params.test_batch_size\n",
        "\n",
        "        self.data_dir = params.data_dir\n",
        "        self.max_seq_length = params.max_seq_length\n",
        "        # self.tokenizer = BertTokenizer(vocab_file=os.path.join(params.bert_model_dir, 'vocab.txt'),\n",
        "        #                                do_lower_case=\n",
        "        self.tokenizer=BertTokenizer.from_pretrained('bert-base-cased')\n",
        "        self.data_cache = params.data_cache\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn_train(features):\n",
        "        \"\"\"将InputFeatures转换为Tensor\n",
        "        Args:\n",
        "            features (List[InputFeatures])\n",
        "        Returns:\n",
        "            tensors (List[Tensors])\n",
        "        \"\"\"\n",
        "        input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "        attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
        "        seq_tags = torch.tensor([f.seq_tag for f in features], dtype=torch.long)\n",
        "        poten_relations = torch.tensor([f.relation for f in features], dtype=torch.long)\n",
        "        corres_tags = torch.tensor([f.corres_tag for f in features], dtype=torch.long)\n",
        "        rel_tags = torch.tensor([f.rel_tag for f in features], dtype=torch.long)\n",
        "        tensors = [input_ids, attention_mask, seq_tags, poten_relations, corres_tags, rel_tags]\n",
        "        return tensors\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn_test(features):\n",
        "        \"\"\"将InputFeatures转换为Tensor\n",
        "        Args:\n",
        "            features (List[InputFeatures])\n",
        "        Returns:\n",
        "            tensors (List[Tensors])\n",
        "        \"\"\"\n",
        "        input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "        attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
        "        triples = [f.triples for f in features]\n",
        "        input_tokens = [f.input_tokens for f in features]\n",
        "        tensors = [input_ids, attention_mask, triples, input_tokens]\n",
        "        return tensors\n",
        "\n",
        "    def get_features(self, data_sign, ex_params):\n",
        "        \"\"\"convert InputExamples to InputFeatures\n",
        "        :param data_sign: 'train', 'val' or 'test'\n",
        "        \"\"\"\n",
        "        print(\"=*=\" * 10)\n",
        "        print(\"Loading {} data...\".format(data_sign))\n",
        "        # get features\n",
        "        cache_path = os.path.join(self.data_dir, \"{}.cache.{}\".format(data_sign, str(self.max_seq_length)))\n",
        "        if os.path.exists(cache_path) and self.data_cache:\n",
        "            features = torch.load(cache_path)\n",
        "        else:\n",
        "            # get relation to idx\n",
        "            with open(self.data_dir +'/rel2id.json', 'r', encoding='utf-8') as f_re:\n",
        "                rel2idx = json.load(f_re)[-1]\n",
        "            # get examples\n",
        "            if data_sign in (\"train\", \"val\", \"test\", \"pseudo\", 'EPO', 'SEO', 'SOO', 'Normal', '1', '2', '3', '4', '5'):\n",
        "                examples = read_examples(self.data_dir, data_sign=data_sign, rel2idx=rel2idx)\n",
        "            else:\n",
        "                raise ValueError(\"please notice that the data can only be train/val/test!!\")\n",
        "            features = convert_examples_to_features(self.params, examples, self.tokenizer, rel2idx, data_sign,\n",
        "                                                    ex_params)\n",
        "            # save data\n",
        "            if self.data_cache:\n",
        "                torch.save(features, cache_path)\n",
        "        return features\n",
        "\n",
        "    def get_dataloader(self, data_sign=\"train\", ex_params=None):\n",
        "        \"\"\"construct dataloader\n",
        "        :param data_sign: 'train', 'val' or 'test'\n",
        "        \"\"\"\n",
        "        # InputExamples to InputFeatures\n",
        "        features = self.get_features(data_sign=data_sign, ex_params=ex_params)\n",
        "        dataset = FeatureDataset(features)\n",
        "        print(f\"{len(features)} {data_sign} data loaded!\")\n",
        "        print(\"=*=\" * 10)\n",
        "        # construct dataloader\n",
        "        # RandomSampler(dataset) or SequentialSampler(dataset)\n",
        "        if data_sign == \"train\":\n",
        "            datasampler = RandomSampler(dataset)\n",
        "            dataloader = DataLoader(dataset, sampler=datasampler, batch_size=self.train_batch_size,\n",
        "                                    collate_fn=self.collate_fn_train)\n",
        "        elif data_sign == \"val\":\n",
        "            datasampler = SequentialSampler(dataset)\n",
        "            dataloader = DataLoader(dataset, sampler=datasampler, batch_size=self.val_batch_size,\n",
        "                                    collate_fn=self.collate_fn_test)\n",
        "        elif data_sign in (\"test\", \"pseudo\", 'EPO', 'SEO', 'SOO', 'Normal', '1', '2', '3', '4', '5'):\n",
        "            datasampler = SequentialSampler(dataset)\n",
        "            dataloader = DataLoader(dataset, sampler=datasampler, batch_size=self.test_batch_size,\n",
        "                                    collate_fn=self.collate_fn_test)\n",
        "        else:\n",
        "            raise ValueError(\"please notice that the data can only be train/val/test !!\")\n",
        "        return dataloader\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # from utils import Params\n",
        "\n",
        "    params = Params(corpus_type='NYT')\n",
        "    ex_params = {\n",
        "        'ensure_relpre': True\n",
        "    }\n",
        "    dataloader = CustomDataLoader(params)\n",
        "    feats = dataloader.get_features(ex_params=ex_params, data_sign='test')\n",
        "    print(feats[7].input_tokens)\n"
      ],
      "metadata": {
        "id": "bBHZnN2QVNHG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "e96a70248dfc4fd1a223ec33f3df9983",
            "f1aa4776df7c420095bc3ed0caf02200",
            "df7d3fbda5cd4c83aa43df32f01ed93f",
            "ad397893a1774d9d8833c0439b063bde",
            "03e6fa6534514f0cb6661446fb0dfc96",
            "d9270773f3a44e84811f86f9847ef1bc",
            "0b408b14573441c684ba512541209a99",
            "ee044a395dd449fba6fda4a54301a210",
            "a233d73c60994c87b1062ca489ff1448",
            "639d36004ea34b6faa09c51971605c08",
            "08b15d56fda945a8b72a0659df94cbab",
            "62f7da6e2ab34bb4b7c38958aa8a8032",
            "d047457bbe074ec8a1f688c2e57180c5",
            "e5308807c3eb4d1c9ec04c6dc3c9ad4a",
            "9ae2d078bbe44cac9e9a92c39b19ef55",
            "57683178d93e4a139127a658d246bd3c",
            "9e5a682cc32346e48fb84b7381c4c230",
            "86e2fe0cbc744e018ef62f26cd0b4556",
            "0269b37e706f4d0eaf684549c79bda1c",
            "6afc3bd89e5e4c8b858f9491c16f6711",
            "5b353054eca146458fe463b179d71db6",
            "2654462d6f564373b0206197543ec645",
            "de8223ee0c484d6e9bb5a2be10fcec3b",
            "6526a145f2b1457280d00788a38c102d",
            "e8c3be8d108e4999b7ad1398d7e2fef8",
            "6966618835ad49c6a8aa67e363afdc75",
            "1f2718af44d44953a0791def82a3ed25",
            "5038381f78d34f8e8485bb8f5b728271",
            "3381fa257f0642ba907ba4d906ccde1f",
            "f414cef0cab24698b7b87f9f38367ae7",
            "f8fef0122cd94aa3bf4f3c219a5f70bc",
            "b0d7927150394dc0bb7da5015f21a043",
            "4e6a086b288e4d2b84b842dc6eb33638"
          ]
        },
        "outputId": "4a0de9f3-1d9a-4bd6-a8a2-79b55a2ef9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e96a70248dfc4fd1a223ec33f3df9983"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62f7da6e2ab34bb4b7c38958aa8a8032"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de8223ee0c484d6e9bb5a2be10fcec3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=*==*==*==*==*==*==*==*==*==*=\n",
            "Loading test data...\n",
            "InputExamples: 369\n",
            "['In', 'essence', 'this', 'can', 'start', 'to', 're', '##w', '##rite', 'the', 'history', 'of', 'photography', ',', \"'\", \"'\", 'said', 'Grant', 'Rome', '##r', ',', 'director', 'of', 'the', 'advanced', 'residency', 'program', 'in', 'photograph', 'conservation', 'at', 'the', 'George', 'Eastman', 'House', 'in', 'Rochester', '.', \"'\", \"'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# metrics"
      ],
      "metadata": {
        "id": "a-SEkMwYXWf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FAxKnIx7bM6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /usr/bin/env python\n",
        "# coding=utf-8\n",
        "\n",
        "\n",
        "def get_chunk_type(tok, idx_to_tag):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        tok: id of token, ex 4\n",
        "        idx_to_tag: dictionary {4: \"B-PER\", ...}\n",
        "    Returns:\n",
        "        tuple: \"B\", \"PER\"\n",
        "    \"\"\"\n",
        "    tag_name = idx_to_tag[tok]\n",
        "    content = tag_name.split('-')\n",
        "    tag_class = content[0]\n",
        "    if len(content) == 1:\n",
        "        return tag_class\n",
        "    ht = content[-1]\n",
        "    return tag_class, ht\n",
        "\n",
        "\n",
        "def get_chunks(seq, tags):\n",
        "    \"\"\"Given a sequence of tags, group entities and their position\n",
        "    Args:\n",
        "        seq: np.array[4, 4, 0, 0, ...] sequence of labels\n",
        "        tags: dict[\"O\"] = 4\n",
        "    Returns:\n",
        "        list of (chunk_type, chunk_start, chunk_end)\n",
        "    Example:\n",
        "        seq = [4, 5, 0, 3]\n",
        "        tags = {\"B-PER\": 4, \"I-PER\": 5, \"B-LOC\": 3}\n",
        "        result = [(\"PER\", 0, 2), (\"LOC\", 3, 4)]\n",
        "    \"\"\"\n",
        "    default1 = tags['O']\n",
        "    idx_to_tag = {idx: tag for tag, idx in tags.items()}\n",
        "    chunks = []\n",
        "    chunk_type, chunk_start = None, None\n",
        "    for i, tok in enumerate(seq):\n",
        "        # End of a chunk 1\n",
        "        if tok == default1 and chunk_type is not None:\n",
        "            # Add a chunk.\n",
        "            chunk = (chunk_type, chunk_start, i)\n",
        "            chunks.append(chunk)\n",
        "            chunk_type, chunk_start = None, None\n",
        "\n",
        "        # End of a chunk + start of a chunk!\n",
        "        elif tok != default1:\n",
        "            res = get_chunk_type(tok, idx_to_tag)\n",
        "            if len(res) == 1:\n",
        "                continue\n",
        "            tok_chunk_class, ht = get_chunk_type(tok, idx_to_tag)\n",
        "            tok_chunk_type = ht\n",
        "            if chunk_type is None:\n",
        "                chunk_type, chunk_start = tok_chunk_type, i\n",
        "            elif tok_chunk_type != chunk_type or tok_chunk_class == \"B\":\n",
        "                chunk = (chunk_type, chunk_start, i)\n",
        "                chunks.append(chunk)\n",
        "                chunk_type, chunk_start = tok_chunk_type, i\n",
        "        else:\n",
        "            pass\n",
        "    # end condition\n",
        "    if chunk_type is not None:\n",
        "        chunk = (chunk_type, chunk_start, len(seq))\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def tag_mapping_nearest(predict_tags, pre_rels=None, label2idx_sub=None, label2idx_obj=None):\n",
        "    \"\"\"\n",
        "    implement of the heuristic nearest principle\n",
        "    Args:\n",
        "        predict_tags: np.array, (xi, 2, max_sen_len)\n",
        "        pre_rels: (xi,)\n",
        "    \"\"\"\n",
        "    rel_num = predict_tags.shape[0]\n",
        "    pre_triples = []\n",
        "    for idx in range(rel_num):\n",
        "        heads, tails = [], []\n",
        "        pred_chunks_sub = get_chunks(predict_tags[idx][0], label2idx_sub)\n",
        "        pred_chunks_obj = get_chunks(predict_tags[idx][1], label2idx_obj)\n",
        "        pred_chunks = pred_chunks_sub + pred_chunks_obj\n",
        "        for ch in pred_chunks:\n",
        "            if ch[0] == 'H':\n",
        "                heads.append(ch)\n",
        "            elif ch[0] == 'T':\n",
        "                tails.append(ch)\n",
        "        # the heuristic nearest principle\n",
        "        if len(heads) != 0 and len(tails) != 0:\n",
        "            if len(heads) < len(tails):\n",
        "                heads += [heads[-1]] * (len(tails) - len(heads))\n",
        "            if len(heads) > len(tails):\n",
        "                tails += [tails[-1]] * (len(heads) - len(tails))\n",
        "\n",
        "        for h_t in zip(heads, tails):\n",
        "            if pre_rels is not None:\n",
        "                triple = list(h_t) + [pre_rels[idx]]\n",
        "            else:\n",
        "                triple = list(h_t) + [idx]\n",
        "            pre_triples.append(tuple(triple))\n",
        "    return pre_triples\n",
        "\n",
        "\n",
        "def tag_mapping_corres(predict_tags, pre_corres, pre_rels=None, label2idx_sub=None, label2idx_obj=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        predict_tags: np.array, (xi, 2, max_sen_len)\n",
        "        pre_corres: (seq_len, seq_len)\n",
        "        pre_rels: (xi,)\n",
        "    \"\"\"\n",
        "    rel_num = predict_tags.shape[0]\n",
        "    pre_triples = []\n",
        "    for idx in range(rel_num):\n",
        "        heads, tails = [], []\n",
        "        pred_chunks_sub = get_chunks(predict_tags[idx][0], label2idx_sub)\n",
        "        pred_chunks_obj = get_chunks(predict_tags[idx][1], label2idx_obj)\n",
        "        pred_chunks = pred_chunks_sub + pred_chunks_obj\n",
        "        for ch in pred_chunks:\n",
        "            if ch[0] == 'H':\n",
        "                heads.append(ch)\n",
        "            elif ch[0] == 'T':\n",
        "                tails.append(ch)\n",
        "        retain_hts = [(h, t) for h in heads for t in tails if pre_corres[h[1]][t[1]] == 1]\n",
        "        for h_t in retain_hts:\n",
        "            if pre_rels is not None:\n",
        "                triple = list(h_t) + [pre_rels[idx]]\n",
        "            else:\n",
        "                triple = list(h_t) + [idx]\n",
        "            pre_triples.append(tuple(triple))\n",
        "    return pre_triples\n"
      ],
      "metadata": {
        "id": "4Za_rcH6XR3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optimizer"
      ],
      "metadata": {
        "id": "ni9rwF2abNfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding=utf-8\n",
        "# This file is derived from the code at\n",
        "# https://github.com/huggingface/transformers/blob/master/transformers/optimization.py\n",
        "#\n",
        "# Original copyright notice:\n",
        "#\n",
        "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"PyTorch optimization for BERT model.\"\"\"\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import logging\n",
        "import abc\n",
        "import sys\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "if sys.version_info >= (3, 4):\n",
        "    ABC = abc.ABC\n",
        "else:\n",
        "    ABC = abc.ABCMeta('ABC', (), {})\n",
        "\n",
        "\n",
        "class _LRSchedule(ABC):\n",
        "    \"\"\" Parent of all LRSchedules here. \"\"\"\n",
        "    warn_t_total = False  # is set to True for schedules where progressing beyond t_total steps doesn't make sense\n",
        "\n",
        "    def __init__(self, warmup=0.002, t_total=-1, **kw):\n",
        "        \"\"\"\n",
        "        :param warmup:  what fraction of t_total steps will be used for linear warmup\n",
        "        :param t_total: how many training steps (updates) are planned\n",
        "        :param kw:\n",
        "        \"\"\"\n",
        "        super(_LRSchedule, self).__init__(**kw)\n",
        "        if t_total < 0:\n",
        "            logger.warning(\"t_total value of {} results in schedule not being applied\".format(t_total))\n",
        "        if not 0.0 <= warmup < 1.0 and not warmup == -1:\n",
        "            raise ValueError(\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\".format(warmup))\n",
        "        warmup = max(warmup, 0.)\n",
        "        self.warmup, self.t_total = float(warmup), float(t_total)\n",
        "        self.warned_for_t_total_at_progress = -1\n",
        "\n",
        "    def get_lr(self, step, nowarn=False):\n",
        "        \"\"\"\n",
        "        :param step:    which of t_total steps we're on\n",
        "        :param nowarn:  set to True to suppress warning regarding training beyond specified 't_total' steps\n",
        "        :return:        learning rate multiplier for current update\n",
        "        \"\"\"\n",
        "        if self.t_total < 0:\n",
        "            return 1.\n",
        "        progress = float(step) / self.t_total\n",
        "        ret = self.get_lr_(progress)\n",
        "        # warning for exceeding t_total (only active with warmup_linear\n",
        "        if not nowarn and self.warn_t_total and progress > 1. and progress > self.warned_for_t_total_at_progress:\n",
        "            logger.warning(\n",
        "                \"Training beyond specified 't_total'. Learning rate multiplier set to {}. Please set 't_total' of {} correctly.\"\n",
        "                    .format(ret, self.__class__.__name__))\n",
        "            self.warned_for_t_total_at_progress = progress\n",
        "        # end warning\n",
        "        return ret\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def get_lr_(self, progress):\n",
        "        \"\"\"\n",
        "        :param progress:    value between 0 and 1 (unless going beyond t_total steps) specifying training progress\n",
        "        :return:            learning rate multiplier for current update\n",
        "        \"\"\"\n",
        "        return 1.\n",
        "\n",
        "\n",
        "class ConstantLR(_LRSchedule):\n",
        "    def get_lr_(self, progress):\n",
        "        return 1.\n",
        "\n",
        "\n",
        "class WarmupCosineSchedule(_LRSchedule):\n",
        "    \"\"\"\n",
        "    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n",
        "    Decreases learning rate from 1. to 0. over remaining `1 - warmup` steps following a cosine curve.\n",
        "    If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n",
        "    \"\"\"\n",
        "    warn_t_total = True\n",
        "\n",
        "    def __init__(self, warmup=0.002, t_total=-1, cycles=.5, **kw):\n",
        "        \"\"\"\n",
        "        :param warmup:      see LRSchedule\n",
        "        :param t_total:     see LRSchedule\n",
        "        :param cycles:      number of cycles. Default: 0.5, corresponding to cosine decay from 1. at progress==warmup and 0 at progress==1.\n",
        "        :param kw:\n",
        "        \"\"\"\n",
        "        super(WarmupCosineSchedule, self).__init__(warmup=warmup, t_total=t_total, **kw)\n",
        "        self.cycles = cycles\n",
        "\n",
        "    def get_lr_(self, progress):\n",
        "        if progress < self.warmup:\n",
        "            return progress / self.warmup\n",
        "        else:\n",
        "            progress = (progress - self.warmup) / (1 - self.warmup)  # progress after warmup\n",
        "            return 0.5 * (1. + math.cos(math.pi * self.cycles * 2 * progress))\n",
        "\n",
        "\n",
        "class WarmupCosineWithHardRestartsSchedule(WarmupCosineSchedule):\n",
        "    \"\"\"\n",
        "    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n",
        "    If `cycles` (default=1.) is different from default, learning rate follows `cycles` times a cosine decaying\n",
        "    learning rate (with hard restarts).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n",
        "        super(WarmupCosineWithHardRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles, **kw)\n",
        "        assert (cycles >= 1.)\n",
        "\n",
        "    def get_lr_(self, progress):\n",
        "        if progress < self.warmup:\n",
        "            return progress / self.warmup\n",
        "        else:\n",
        "            progress = (progress - self.warmup) / (1 - self.warmup)  # progress after warmup\n",
        "            ret = 0.5 * (1. + math.cos(math.pi * ((self.cycles * progress) % 1)))\n",
        "            return ret\n",
        "\n",
        "\n",
        "class WarmupCosineWithWarmupRestartsSchedule(WarmupCosineWithHardRestartsSchedule):\n",
        "    \"\"\"\n",
        "    All training progress is divided in `cycles` (default=1.) parts of equal length.\n",
        "    Every part follows a schedule with the first `warmup` fraction of the training steps linearly increasing from 0. to 1.,\n",
        "    followed by a learning rate decreasing from 1. to 0. following a cosine curve.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, warmup=0.002, t_total=-1, cycles=1., **kw):\n",
        "        assert (warmup * cycles < 1.)\n",
        "        warmup = warmup * cycles if warmup >= 0 else warmup\n",
        "        super(WarmupCosineWithWarmupRestartsSchedule, self).__init__(warmup=warmup, t_total=t_total, cycles=cycles,\n",
        "                                                                     **kw)\n",
        "\n",
        "    def get_lr_(self, progress):\n",
        "        progress = progress * self.cycles % 1.\n",
        "        if progress < self.warmup:\n",
        "            return progress / self.warmup\n",
        "        else:\n",
        "            progress = (progress - self.warmup) / (1 - self.warmup)  # progress after warmup\n",
        "            ret = 0.5 * (1. + math.cos(math.pi * progress))\n",
        "            return ret\n",
        "\n",
        "\n",
        "class WarmupConstantSchedule(_LRSchedule):\n",
        "    \"\"\"\n",
        "    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n",
        "    Keeps learning rate equal to 1. after warmup.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_lr_(self, progress):\n",
        "        if progress < self.warmup:\n",
        "            return progress / self.warmup\n",
        "        return 1.\n",
        "\n",
        "\n",
        "class WarmupLinearSchedule(_LRSchedule):\n",
        "    \"\"\"\n",
        "    Linearly increases learning rate from 0 to 1 over `warmup` fraction of training steps.\n",
        "    Linearly decreases learning rate from 1. to 0. over remaining `1 - warmup` steps.\n",
        "    \"\"\"\n",
        "    warn_t_total = True\n",
        "\n",
        "    def get_lr_(self, progress):\n",
        "        if progress < self.warmup:\n",
        "            return progress / self.warmup\n",
        "        return max((progress - 1.) / (self.warmup - 1.), 0.)\n",
        "\n",
        "\n",
        "SCHEDULES = {\n",
        "    None: ConstantLR,\n",
        "    \"none\": ConstantLR,\n",
        "    \"warmup_cosine\": WarmupCosineSchedule,\n",
        "    \"warmup_constant\": WarmupConstantSchedule,\n",
        "    \"warmup_linear\": WarmupLinearSchedule\n",
        "}\n",
        "\n",
        "\n",
        "class BertAdam(Optimizer):\n",
        "    \"\"\"Implements BERT version of Adam algorithm with weight decay fix.\n",
        "    Params:\n",
        "        lr: learning rate\n",
        "        warmup: portion of t_total for the warmup, -1 means no warmup. Default: -1\n",
        "        t_total: total number of training steps for the learning\n",
        "            rate schedule, -1  means constant learning rate of 1. (no warmup regardless of warmup setting). Default: -1\n",
        "        schedule: schedule to use for the warmup (see above).\n",
        "            Can be `'warmup_linear'`, `'warmup_constant'`, `'warmup_cosine'`, `'none'`, `None` or a `_LRSchedule` object (see below).\n",
        "            If `None` or `'none'`, learning rate is always kept constant.\n",
        "            Default : `'warmup_linear'`\n",
        "        b1: Adams b1. Default: 0.9\n",
        "        b2: Adams b2. Default: 0.999\n",
        "        e: Adams epsilon. Default: 1e-6\n",
        "        weight_decay: Weight decay. Default: 0.01\n",
        "        max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-4, warmup=-1, t_total=-1, schedule='warmup_linear',\n",
        "                 b1=0.9, b2=0.999, e=1e-6, weight_decay=0.01, max_grad_norm=1.0, **kwargs):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
        "        if not isinstance(schedule, _LRSchedule) and schedule not in SCHEDULES:\n",
        "            raise ValueError(\"Invalid schedule parameter: {}\".format(schedule))\n",
        "        if not 0.0 <= b1 < 1.0:\n",
        "            raise ValueError(\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\".format(b1))\n",
        "        if not 0.0 <= b2 < 1.0:\n",
        "            raise ValueError(\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\".format(b2))\n",
        "        if not e >= 0.0:\n",
        "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(e))\n",
        "        # initialize schedule object\n",
        "        if not isinstance(schedule, _LRSchedule):\n",
        "            schedule_type = SCHEDULES[schedule]\n",
        "            schedule = schedule_type(warmup=warmup, t_total=t_total)\n",
        "        else:\n",
        "            if warmup != -1 or t_total != -1:\n",
        "                logger.warning(\n",
        "                    \"warmup and t_total on the optimizer are ineffective when _LRSchedule object is provided as schedule. \"\n",
        "                    \"Please specify custom warmup and t_total in _LRSchedule object.\")\n",
        "        defaults = dict(lr=lr, schedule=schedule,\n",
        "                        b1=b1, b2=b2, e=e, weight_decay=weight_decay,\n",
        "                        max_grad_norm=max_grad_norm)\n",
        "        super(BertAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def get_lr(self):\n",
        "        lr = []\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                if len(state) == 0:\n",
        "                    return [0]\n",
        "                lr_scheduled = group['lr']\n",
        "                lr_scheduled *= group['schedule'].get_lr(state['step'])\n",
        "                lr.append(lr_scheduled)\n",
        "        return lr\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['next_m'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['next_v'] = torch.zeros_like(p.data)\n",
        "\n",
        "                next_m, next_v = state['next_m'], state['next_v']\n",
        "                beta1, beta2 = group['b1'], group['b2']\n",
        "\n",
        "                # Add grad clipping\n",
        "                if group['max_grad_norm'] > 0:\n",
        "                    clip_grad_norm_(p, group['max_grad_norm'])\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # In-place operations to update the averages at the same time\n",
        "                next_m.mul_(beta1).add_(alpha=1 - beta1, other=grad)\n",
        "                next_v.mul_(beta2).addcmul_(value=1 - beta2, tensor1=grad, tensor2=grad)\n",
        "                update = next_m / (next_v.sqrt() + group['e'])\n",
        "\n",
        "                # Just adding the square of the weights to the loss function is *not*\n",
        "                # the correct way of using L2 regularization/weight decay with Adam,\n",
        "                # since that will interact with the m and v parameters in strange ways.\n",
        "                #\n",
        "                # Instead we want to decay the weights in a manner that doesn't interact\n",
        "                # with the m/v parameters. This is equivalent to adding the square\n",
        "                # of the weights to the loss with plain (non-momentum) SGD.\n",
        "                if group['weight_decay'] > 0.0:\n",
        "                    update += group['weight_decay'] * p.data\n",
        "\n",
        "                lr_scheduled = group['lr']\n",
        "                lr_scheduled *= group['schedule'].get_lr(state['step'])\n",
        "\n",
        "                update_with_lr = lr_scheduled * update\n",
        "                p.data.add_(-update_with_lr)\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                # step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1\n",
        "                # No bias correction\n",
        "                # bias_correction1 = 1 - beta1 ** state['step']\n",
        "                # bias_correction2 = 1 - beta2 ** state['step']\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "KQVDsF2YbPP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wgethttps://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json"
      ],
      "metadata": {
        "id": "rhpjhYzOb396"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "g-vn8tbTYYc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /usr/bin/env python\n",
        "# coding=utf-8\n",
        "\"\"\"model\"\"\"\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from transformers import BertPreTrainedModel, BertModel, BertTokenizer\n",
        "\n",
        "\n",
        "class MultiNonLinearClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size, tag_size, dropout_rate):\n",
        "        super(MultiNonLinearClassifier, self).__init__()\n",
        "        self.tag_size = tag_size\n",
        "        self.linear = nn.Linear(hidden_size, int(hidden_size / 2))\n",
        "        self.hidden2tag = nn.Linear(int(hidden_size / 2), self.tag_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input_features):\n",
        "        features_tmp = self.linear(input_features)\n",
        "        features_tmp = nn.ReLU()(features_tmp)\n",
        "        features_tmp = self.dropout(features_tmp)\n",
        "        features_output = self.hidden2tag(features_tmp)\n",
        "        return features_output\n",
        "\n",
        "\n",
        "class SequenceLabelForSO(nn.Module):\n",
        "    def __init__(self, hidden_size, tag_size, dropout_rate):\n",
        "        super(SequenceLabelForSO, self).__init__()\n",
        "        self.tag_size = tag_size\n",
        "        self.linear = nn.Linear(hidden_size, int(hidden_size / 2))\n",
        "        self.hidden2tag_sub = nn.Linear(int(hidden_size / 2), self.tag_size)\n",
        "        self.hidden2tag_obj = nn.Linear(int(hidden_size / 2), self.tag_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input_features):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_features: (bs, seq_len, h)\n",
        "        \"\"\"\n",
        "        features_tmp = self.linear(input_features)\n",
        "        features_tmp = nn.ReLU()(features_tmp)\n",
        "        features_tmp = self.dropout(features_tmp)\n",
        "        sub_output = self.hidden2tag_sub(features_tmp)\n",
        "        obj_output = self.hidden2tag_obj(features_tmp)\n",
        "        return sub_output, obj_output\n",
        "\n",
        "\n",
        "class BertForRE(BertPreTrainedModel):\n",
        "    def __init__(self, config, params):\n",
        "        super().__init__(config)\n",
        "        self.max_seq_len = params.max_seq_length\n",
        "        self.seq_tag_size = params.seq_tag_size\n",
        "        self.rel_num = params.rel_num\n",
        "\n",
        "        # pretrain model\n",
        "        # self.bert = BertModel(config)\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        # sequence tagging\n",
        "        self.sequence_tagging_sub = MultiNonLinearClassifier(config.hidden_size * 2, self.seq_tag_size, params.drop_prob)\n",
        "        self.sequence_tagging_obj = MultiNonLinearClassifier(config.hidden_size * 2, self.seq_tag_size, params.drop_prob)\n",
        "        self.sequence_tagging_sum = SequenceLabelForSO(config.hidden_size, self.seq_tag_size, params.drop_prob)\n",
        "        # global correspondence\n",
        "        self.global_corres = MultiNonLinearClassifier(config.hidden_size * 2, 1, params.drop_prob)\n",
        "        # relation judgement\n",
        "        self.rel_judgement = MultiNonLinearClassifier(config.hidden_size, params.rel_num, params.drop_prob)\n",
        "        self.rel_embedding = nn.Embedding(params.rel_num, config.hidden_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_avgpool(sent, mask):\n",
        "        mask_ = mask.masked_fill(mask == 0, -1e9).float()\n",
        "        score = torch.softmax(mask_, -1)#权重的平均\n",
        "        return torch.matmul(score.unsqueeze(1), sent).squeeze(1)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            input_ids=None,\n",
        "            attention_mask=None,\n",
        "            seq_tags=None,\n",
        "            potential_rels=None,\n",
        "            corres_tags=None,\n",
        "            rel_tags=None,\n",
        "            ex_params=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_ids: (batch_size, seq_len)\n",
        "            attention_mask: (batch_size, seq_len)\n",
        "            rel_tags: (bs, rel_num)\n",
        "            potential_rels: (bs,), only in train stage.\n",
        "            seq_tags: (bs, 2, seq_len)\n",
        "            corres_tags: (bs, seq_len, seq_len)\n",
        "            ex_params: experiment parameters\n",
        "        \"\"\"\n",
        "        # get params for experiments\n",
        "        corres_threshold, rel_threshold = ex_params.get('corres_threshold', 0.5), ex_params.get('rel_threshold', 0.1)\n",
        "        # ablation study\n",
        "        ensure_corres, ensure_rel = ex_params['ensure_corres'], ex_params['ensure_rel']\n",
        "        # pre-train model\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True\n",
        "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
        "        sequence_output = outputs[0]\n",
        "        bs, seq_len, h = sequence_output.size()\n",
        "\n",
        "        if ensure_rel:\n",
        "            # (bs, h)\n",
        "            h_k_avg = self.masked_avgpool(sequence_output, attention_mask)\n",
        "            # (bs, rel_num)\n",
        "            rel_pred = self.rel_judgement(h_k_avg)\n",
        "\n",
        "        # before fuse relation representation\n",
        "        if ensure_corres:\n",
        "            # for every position $i$ in sequence, should concate $j$ to predict.\n",
        "            sub_extend = sequence_output.unsqueeze(2).expand(-1, -1, seq_len, -1)  # (bs, s, s, h)\n",
        "            obj_extend = sequence_output.unsqueeze(1).expand(-1, seq_len, -1, -1)  # (bs, s, s, h)\n",
        "            # batch x seq_len x seq_len x 2*hidden\n",
        "            corres_pred = torch.cat([sub_extend, obj_extend], 3)\n",
        "            # (bs, seq_len, seq_len)\n",
        "            corres_pred = self.global_corres(corres_pred).squeeze(-1)\n",
        "            mask_tmp1 = attention_mask.unsqueeze(-1)#B*L*1\n",
        "            mask_tmp2 = attention_mask.unsqueeze(1)#B*1*L\n",
        "            corres_mask = mask_tmp1 * mask_tmp2#B*L*L\n",
        "\n",
        "        # relation predict and data construction in inference stage\n",
        "        xi, pred_rels = None, None\n",
        "        if ensure_rel and seq_tags is None:\n",
        "            # (bs, rel_num)\n",
        "            #这里乜有太理解\n",
        "            rel_pred_onehot = torch.where(torch.sigmoid(rel_pred) > rel_threshold,\n",
        "                                          torch.ones(rel_pred.size(), device=rel_pred.device),\n",
        "                                          torch.zeros(rel_pred.size(), device=rel_pred.device))\n",
        "\n",
        "            # if potential relation is null\n",
        "            for idx, sample in enumerate(rel_pred_onehot):\n",
        "                if 1 not in sample:\n",
        "                    # (rel_num,)\n",
        "                    max_index = torch.argmax(rel_pred[idx])\n",
        "                    sample[max_index] = 1\n",
        "                    rel_pred_onehot[idx] = sample\n",
        "\n",
        "            # 2*(sum(x_i),)\n",
        "            bs_idxs, pred_rels = torch.nonzero(rel_pred_onehot, as_tuple=True)\n",
        "            # get x_i\n",
        "            xi_dict = Counter(bs_idxs.tolist())\n",
        "            xi = [xi_dict[idx] for idx in range(bs)]\n",
        "\n",
        "            pos_seq_output = []\n",
        "            pos_potential_rel = []\n",
        "            pos_attention_mask = []\n",
        "            for bs_idx, rel_idx in zip(bs_idxs, pred_rels):\n",
        "                # (seq_len, h)\n",
        "                pos_seq_output.append(sequence_output[bs_idx])\n",
        "                pos_attention_mask.append(attention_mask[bs_idx])\n",
        "                pos_potential_rel.append(rel_idx)\n",
        "            # (sum(x_i), seq_len, h)\n",
        "            sequence_output = torch.stack(pos_seq_output, dim=0)\n",
        "            # (sum(x_i), seq_len)\n",
        "            attention_mask = torch.stack(pos_attention_mask, dim=0)\n",
        "            # (sum(x_i),)\n",
        "            potential_rels = torch.stack(pos_potential_rel, dim=0)\n",
        "        # ablation of relation judgement\n",
        "        elif not ensure_rel and seq_tags is None:\n",
        "            # construct test data\n",
        "            #当参数只有两个时，第一个参数表示的是复制后的列数，第二个参数表示复制后的行数。\n",
        "            # 当参数有三个时，第一个参数表示的是复制后的通道数，第二个参数表示的是复制后的列数，第三个参数表示复制后的行数。\n",
        "            sequence_output = sequence_output.repeat((1, self.rel_num, 1)).view(bs * self.rel_num, seq_len, h)\n",
        "            attention_mask = attention_mask.repeat((1, self.rel_num)).view(bs * self.rel_num, seq_len)\n",
        "            potential_rels = torch.arange(0, self.rel_num, device=input_ids.device).repeat(bs)\n",
        "\n",
        "        # (bs/sum(x_i), h)\n",
        "        rel_emb = self.rel_embedding(potential_rels)\n",
        "\n",
        "        # relation embedding vector fusion\n",
        "        rel_emb = rel_emb.unsqueeze(1).expand(-1, seq_len, h)\n",
        "        if ex_params['emb_fusion'] == 'concat':\n",
        "            # (bs/sum(x_i), seq_len, 2*h)\n",
        "            decode_input = torch.cat([sequence_output, rel_emb], dim=-1)\n",
        "            # (bs/sum(x_i), seq_len, tag_size)\n",
        "            output_sub = self.sequence_tagging_sub(decode_input)\n",
        "            output_obj = self.sequence_tagging_obj(decode_input)\n",
        "        elif ex_params['emb_fusion'] == 'sum':\n",
        "            # (bs/sum(x_i), seq_len, h)\n",
        "            decode_input = sequence_output + rel_emb\n",
        "            # (bs/sum(x_i), seq_len, tag_size)\n",
        "            output_sub, output_obj = self.sequence_tagging_sum(decode_input)\n",
        "\n",
        "        # train\n",
        "        if seq_tags is not None:\n",
        "            # calculate loss\n",
        "            attention_mask = attention_mask.view(-1)\n",
        "            # sequence label loss\n",
        "            loss_func = nn.CrossEntropyLoss(reduction='none')\n",
        "            loss_seq_sub = (loss_func(output_sub.view(-1, self.seq_tag_size),\n",
        "                                      seq_tags[:, 0, :].reshape(-1)) * attention_mask).sum() / attention_mask.sum()\n",
        "            loss_seq_obj = (loss_func(output_obj.view(-1, self.seq_tag_size),\n",
        "                                      seq_tags[:, 1, :].reshape(-1)) * attention_mask).sum() / attention_mask.sum()\n",
        "            loss_seq = (loss_seq_sub + loss_seq_obj) / 2\n",
        "            # init\n",
        "            loss_matrix, loss_rel = torch.tensor(0), torch.tensor(0)\n",
        "            if ensure_corres:\n",
        "                corres_pred = corres_pred.view(bs, -1)\n",
        "                corres_mask = corres_mask.view(bs, -1)\n",
        "                corres_tags = corres_tags.view(bs, -1)\n",
        "                loss_func = nn.BCEWithLogitsLoss(reduction='none')\n",
        "                loss_matrix = (loss_func(corres_pred,\n",
        "                                         corres_tags.float()) * corres_mask).sum() / corres_mask.sum()\n",
        "\n",
        "            if ensure_rel:\n",
        "                loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "                loss_rel = loss_func(rel_pred, rel_tags.float())\n",
        "\n",
        "            loss = loss_seq + loss_matrix + loss_rel\n",
        "            return loss, loss_seq, loss_matrix, loss_rel\n",
        "        # inference\n",
        "        else:\n",
        "            # (sum(x_i), seq_len)\n",
        "            pred_seq_sub = torch.argmax(torch.softmax(output_sub, dim=-1), dim=-1)\n",
        "            pred_seq_obj = torch.argmax(torch.softmax(output_obj, dim=-1), dim=-1)\n",
        "            # (sum(x_i), 2, seq_len)\n",
        "            pred_seqs = torch.cat([pred_seq_sub.unsqueeze(1), pred_seq_obj.unsqueeze(1)], dim=1)\n",
        "            if ensure_corres:\n",
        "                corres_pred = torch.sigmoid(corres_pred) * corres_mask\n",
        "                # (bs, seq_len, seq_len)\n",
        "                pred_corres_onehot = torch.where(corres_pred > corres_threshold,\n",
        "                                                 torch.ones(corres_pred.size(), device=corres_pred.device),\n",
        "                                                 torch.zeros(corres_pred.size(), device=corres_pred.device))\n",
        "                return pred_seqs, pred_corres_onehot, xi, pred_rels\n",
        "            return pred_seqs, xi, pred_rels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    from transformers import BertConfig\n",
        "\n",
        "    import os\n",
        "\n",
        "    params = Params()\n",
        "    # Prepare model\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "    bert_config = BertConfig.from_json_file(os.path.join(params.bert_model_dir, 'bert_config.json'))\n",
        "    model = BertForRE.from_pretrained(config=bert_config,\n",
        "                                      # pretrained_model_name_or_path=params.bert_model_dir,\n",
        "                                      pretrained_model_name_or_path='bert-base-cased',\n",
        "                                      params=params)\n",
        "    model.to(params.device)\n",
        "\n",
        "    for n, _ in model.named_parameters():\n",
        "        print(n)\n"
      ],
      "metadata": {
        "id": "I_kFhK2KYZux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3035a5b0fa4d4772bfcd2063779f834c",
            "861c472b2c8445dd82884c7d45bbe471",
            "daea055a3ed34a5da770d5421d8735ff",
            "4eae44a431ea4fe79d67ac45d3984fba",
            "fe390f30126e461f90444a74d4d6c38f",
            "1839e5a6d21447c286d3a4a0c228942b",
            "5fa9a3db6c4a4b1a9646c95699847527",
            "4d1a7b62503c4cccb3b40b29edf962cf",
            "4ecafed900194d8dba0003001ce48542",
            "b8ce9740fc0f4b5e8f4dd58425921d00",
            "c6d2df16c5904c3983bef057f8c720d5"
          ]
        },
        "outputId": "3c7c0aa4-f9e5-4145-872e-d5e45eb2af42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3035a5b0fa4d4772bfcd2063779f834c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForRE: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForRE from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForRE from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForRE were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['rel_judgement.linear.bias', 'sequence_tagging_sub.linear.weight', 'sequence_tagging_obj.linear.weight', 'sequence_tagging_sum.hidden2tag_obj.weight', 'sequence_tagging_obj.linear.bias', 'sequence_tagging_sub.linear.bias', 'rel_judgement.hidden2tag.bias', 'global_corres.linear.bias', 'sequence_tagging_obj.hidden2tag.bias', 'sequence_tagging_obj.hidden2tag.weight', 'sequence_tagging_sum.linear.bias', 'sequence_tagging_sum.hidden2tag_sub.weight', 'global_corres.hidden2tag.bias', 'global_corres.hidden2tag.weight', 'sequence_tagging_sum.hidden2tag_obj.bias', 'sequence_tagging_sum.linear.weight', 'rel_judgement.hidden2tag.weight', 'rel_embedding.weight', 'sequence_tagging_sum.hidden2tag_sub.bias', 'sequence_tagging_sub.hidden2tag.weight', 'global_corres.linear.weight', 'rel_judgement.linear.weight', 'sequence_tagging_sub.hidden2tag.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "sequence_tagging_sub.linear.weight\n",
            "sequence_tagging_sub.linear.bias\n",
            "sequence_tagging_sub.hidden2tag.weight\n",
            "sequence_tagging_sub.hidden2tag.bias\n",
            "sequence_tagging_obj.linear.weight\n",
            "sequence_tagging_obj.linear.bias\n",
            "sequence_tagging_obj.hidden2tag.weight\n",
            "sequence_tagging_obj.hidden2tag.bias\n",
            "sequence_tagging_sum.linear.weight\n",
            "sequence_tagging_sum.linear.bias\n",
            "sequence_tagging_sum.hidden2tag_sub.weight\n",
            "sequence_tagging_sum.hidden2tag_sub.bias\n",
            "sequence_tagging_sum.hidden2tag_obj.weight\n",
            "sequence_tagging_sum.hidden2tag_obj.bias\n",
            "global_corres.linear.weight\n",
            "global_corres.linear.bias\n",
            "global_corres.hidden2tag.weight\n",
            "global_corres.hidden2tag.bias\n",
            "rel_judgement.linear.weight\n",
            "rel_judgement.linear.bias\n",
            "rel_judgement.hidden2tag.weight\n",
            "rel_judgement.hidden2tag.bias\n",
            "rel_embedding.weight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "KnU5EZGNhc06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
        "\n",
        "import torch\n",
        "from transformers import BertConfig\n",
        "import random\n",
        "import logging\n",
        "from tqdm import trange\n",
        "import argparse\n",
        "import os\n"
      ],
      "metadata": {
        "id": "MwPHb4IWiQVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load args\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--seed', type=int, default=2020, help=\"random seed for initialization\")\n",
        "parser.add_argument('--ex_index', type=str, default=1)\n",
        "parser.add_argument('--corpus_type', type=str, default=\"NYT\", help=\"NYT, WebNLG, NYT*, WebNLG*\")\n",
        "parser.add_argument('--device_id', type=int, default=0, help=\"GPU index\")\n",
        "# parser.add_argument('--epoch_num', required=True, type=int, help=\"number of epochs\")\n",
        "parser.add_argument('--epoch_num', default=2, type=int, help=\"number of epochs\")\n",
        "# parser.add_argument('--multi_gpu', action='store_true', help=\"ensure multi-gpu training\")\n",
        "parser.add_argument('--restore_file', default=None, help=\"name of the file containing weights to reload\")\n",
        "\n",
        "parser.add_argument('--corres_threshold', type=float, default=0.5, help=\"threshold of global correspondence\")\n",
        "parser.add_argument('--rel_threshold', type=float, default=0.5, help=\"threshold of relation judgement\")\n",
        "parser.add_argument('--ensure_corres', action='store_true', help=\"correspondence ablation\")\n",
        "parser.add_argument('--ensure_rel', action='store_true', help=\"relation judgement ablation\")\n",
        "parser.add_argument('--emb_fusion', type=str, default=\"concat\", help=\"way to embedding\")\n",
        "\n",
        "parser.add_argument('--num_negs', type=int, default=4,\n",
        "                    help=\"number of negative sample when ablate relation judgement\")"
      ],
      "metadata": {
        "id": "2oIYoogxiUO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0573d7-f37e-40ff-d677-e7157f10b33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--num_negs'], dest='num_negs', nargs=None, const=None, default=4, type=<class 'int'>, choices=None, help='number of negative sample when ablate relation judgement', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-aUEeM9UiUW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "zO_Zma-wj2mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /usr/bin/env python\n",
        "# coding=utf-8\n",
        "\"\"\"train with valid\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# import utils\n",
        "# from optimization import BertAdam\n",
        "# from evaluate import evaluate\n",
        "# from dataloader import CustomDataLoader\n",
        "# from model import BertForRE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(model, data_iterator, optimizer, params, ex_params):\n",
        "    \"\"\"Train the model one epoch\n",
        "    \"\"\"\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    loss_avg = RunningAverage()\n",
        "    loss_avg_seq = RunningAverage()\n",
        "    loss_avg_mat = RunningAverage()\n",
        "    loss_avg_rel = RunningAverage()\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    # one epoch\n",
        "    t = trange(len(data_iterator), ascii=True)\n",
        "    for step, _ in enumerate(t):\n",
        "        # fetch the next training batch\n",
        "        batch = next(iter(data_iterator))\n",
        "        batch = tuple(t.to(params.device) for t in batch)\n",
        "        input_ids, attention_mask, seq_tags, relations, corres_tags, rel_tags = batch\n",
        "\n",
        "        # compute model output and loss\n",
        "        loss, loss_seq, loss_mat, loss_rel = model(input_ids, attention_mask=attention_mask, seq_tags=seq_tags,\n",
        "                                                   potential_rels=relations, corres_tags=corres_tags, rel_tags=rel_tags,\n",
        "                                                   ex_params=ex_params)\n",
        "\n",
        "        if params.n_gpu > 1 and args.multi_gpu:\n",
        "            loss = loss.mean()  # mean() to average on multi-gpu.\n",
        "        if params.gradient_accumulation_steps > 1:\n",
        "            loss = loss / params.gradient_accumulation_steps\n",
        "\n",
        "        # back-prop\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % params.gradient_accumulation_steps == 0:\n",
        "            # performs updates using calculated gradients\n",
        "            optimizer.step()\n",
        "            model.zero_grad()\n",
        "\n",
        "        # update the average loss\n",
        "        loss_avg.update(loss.item() * params.gradient_accumulation_steps)\n",
        "        loss_avg_seq.update(loss_seq.item())\n",
        "        loss_avg_mat.update(loss_mat.item())\n",
        "        loss_avg_rel.update(loss_rel.item())\n",
        "        # 右边第一个0为填充数，第二个5为数字个数为5位，第三个3为小数点有效数为3，最后一个f为数据类型为float类型。\n",
        "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()),\n",
        "                      loss_seq='{:05.3f}'.format(loss_avg_seq()),\n",
        "                      loss_mat='{:05.3f}'.format(loss_avg_mat()),\n",
        "                      loss_rel='{:05.3f}'.format(loss_avg_rel()))\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, params, ex_params, restore_file=None):\n",
        "    \"\"\"Train the model and evaluate every epoch.\"\"\"\n",
        "    # Load training data and val data\n",
        "    dataloader = CustomDataLoader(params)\n",
        "    train_loader = dataloader.get_dataloader(data_sign='train', ex_params=ex_params)\n",
        "    val_loader = dataloader.get_dataloader(data_sign='val', ex_params=ex_params)\n",
        "\n",
        "    # reload weights from restore_file if specified\n",
        "    if restore_file is not None:\n",
        "        restore_path = os.path.join(params.model_dir, args.restore_file + '.pth.tar')\n",
        "        logging.info(\"Restoring parameters from {}\".format(restore_path))\n",
        "        # 读取checkpoint\n",
        "        model, optimizer = load_checkpoint(restore_path)\n",
        "\n",
        "    model.to(params.device)\n",
        "    # parallel model\n",
        "    if params.n_gpu > 1 and args.multi_gpu:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Prepare optimizer\n",
        "    # fine-tuning\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    # pretrain model param\n",
        "    param_pre = [(n, p) for n, p in param_optimizer if 'bert' in n]\n",
        "    # downstream model param\n",
        "    param_downstream = [(n, p) for n, p in param_optimizer if 'bert' not in n]\n",
        "    no_decay = ['bias', 'LayerNorm', 'layer_norm']\n",
        "    optimizer_grouped_parameters = [\n",
        "        # pretrain model param\n",
        "        {'params': [p for n, p in param_pre if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': params.weight_decay_rate, 'lr': params.fin_tuning_lr\n",
        "         },\n",
        "        {'params': [p for n, p in param_pre if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': 0.0, 'lr': params.fin_tuning_lr\n",
        "         },\n",
        "        # downstream model\n",
        "        {'params': [p for n, p in param_downstream if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': params.weight_decay_rate, 'lr': params.downs_en_lr\n",
        "         },\n",
        "        {'params': [p for n, p in param_downstream if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': 0.0, 'lr': params.downs_en_lr\n",
        "         }\n",
        "    ]\n",
        "    num_train_optimization_steps = len(train_loader) // params.gradient_accumulation_steps * args.epoch_num\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters, warmup=params.warmup_prop, schedule=\"warmup_cosine\",\n",
        "                         t_total=num_train_optimization_steps, max_grad_norm=params.clip_grad)\n",
        "\n",
        "    # patience stage\n",
        "    best_val_f1 = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, args.epoch_num + 1):\n",
        "        # Run one epoch\n",
        "        logging.info(\"Epoch {}/{}\".format(epoch, args.epoch_num))\n",
        "\n",
        "        # Train for one epoch on training set\n",
        "        train(model, train_loader, optimizer, params, ex_params)\n",
        "\n",
        "        # Evaluate for one epoch on training set and validation set\n",
        "        # train_metrics = evaluate(args, model, train_loader, params, mark='Train',\n",
        "        #                          verbose=True)  # Dict['loss', 'f1']\n",
        "        val_metrics, _, _ = evaluate(model, val_loader, params, ex_params, mark='Val')\n",
        "        val_f1 = val_metrics['f1']\n",
        "        improve_f1 = val_f1 - best_val_f1\n",
        "\n",
        "        # Save weights of the network\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "        optimizer_to_save = optimizer\n",
        "        save_checkpoint({'epoch': epoch + 1,\n",
        "                               'model': model_to_save,\n",
        "                               'optim': optimizer_to_save},\n",
        "                              is_best=improve_f1 > 0,\n",
        "                              checkpoint=params.model_dir)\n",
        "        params.save(params.ex_dir / 'params.json')\n",
        "\n",
        "        # stop training based params.patience\n",
        "        if improve_f1 > 0:\n",
        "            logging.info(\"- Found new best F1\")\n",
        "            best_val_f1 = val_f1\n",
        "            if improve_f1 < params.patience:\n",
        "                patience_counter += 1\n",
        "            else:\n",
        "                patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping and logging best f1\n",
        "        if (patience_counter > params.patience_num and epoch > params.min_epoch_num) or epoch == args.epoch_num:\n",
        "            logging.info(\"Best val f1: {:05.2f}\".format(best_val_f1))\n",
        "            break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sQgpIAathelT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 主函数"
      ],
      "metadata": {
        "id": "jkhhcM89j6K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # args = parser.parse_args()\n",
        "    args =parser.parse_args(args=[])\n",
        "    params = Params(args.ex_index, args.corpus_type)\n",
        "    ex_params = {\n",
        "        'ensure_corres': args.ensure_corres,\n",
        "        'ensure_rel': args.ensure_rel,\n",
        "        'num_negs': args.num_negs,\n",
        "        'emb_fusion': args.emb_fusion\n",
        "    }\n",
        "\n",
        "    # if args.multi_gpu:\n",
        "    #     params.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #     n_gpu = torch.cuda.device_count()\n",
        "    #     params.n_gpu = n_gpu\n",
        "    # else:\n",
        "    #     torch.cuda.set_device(args.device_id)\n",
        "    #     print('current device:', torch.cuda.current_device())\n",
        "    #     params.n_gpu = n_gpu = 1\n",
        "    torch.cuda.set_device(args.device_id)\n",
        "    print('current device:', torch.cuda.current_device())\n",
        "    params.n_gpu = n_gpu = 1\n",
        "    # Set the random seed for reproducible experiments\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    params.seed = args.seed\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "    # Set the logger\n",
        "    set_logger(save=True, log_path=os.path.join(params.ex_dir, 'train.log'))\n",
        "    logging.info(f\"Model type:\")\n",
        "    logging.info(\"device: {}\".format(params.device))\n",
        "\n",
        "    logging.info('Load pre-train model weights...')\n",
        "    bert_config = BertConfig.from_json_file(os.path.join(params.bert_model_dir, 'bert_config.json'))\n",
        "    # model = BertForRE.from_pretrained(config=bert_config,\n",
        "    #                                   pretrained_model_name_or_path=params.bert_model_dir,\n",
        "    #                                   params=params)\n",
        "    model = BertForRE.from_pretrained(config=bert_config,\n",
        "                                      # pretrained_model_name_or_path=params.bert_model_dir,\n",
        "                                      pretrained_model_name_or_path='bert-base-cased',\n",
        "                                      params=params)\n",
        "    logging.info('-done')\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    logging.info(\"Starting training for {} epoch(s)\".format(args.epoch_num))\n",
        "    train_and_evaluate(model, params, ex_params, args.restore_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "sTM1VSHaicSR",
        "outputId": "5165e7fb-4991-42b5-b7ad-94afc79c7416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model type:\n",
            "device: cuda\n",
            "Load pre-train model weights...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current device: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForRE: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForRE from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForRE from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForRE were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['rel_judgement.linear.bias', 'sequence_tagging_sub.linear.weight', 'sequence_tagging_obj.linear.weight', 'sequence_tagging_sum.hidden2tag_obj.weight', 'sequence_tagging_obj.linear.bias', 'sequence_tagging_sub.linear.bias', 'rel_judgement.hidden2tag.bias', 'global_corres.linear.bias', 'sequence_tagging_obj.hidden2tag.bias', 'sequence_tagging_obj.hidden2tag.weight', 'sequence_tagging_sum.linear.bias', 'sequence_tagging_sum.hidden2tag_sub.weight', 'global_corres.hidden2tag.bias', 'global_corres.hidden2tag.weight', 'sequence_tagging_sum.hidden2tag_obj.bias', 'sequence_tagging_sum.linear.weight', 'rel_judgement.hidden2tag.weight', 'rel_embedding.weight', 'sequence_tagging_sum.hidden2tag_sub.bias', 'sequence_tagging_sub.hidden2tag.weight', 'global_corres.linear.weight', 'rel_judgement.linear.weight', 'sequence_tagging_sub.hidden2tag.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "-done\n",
            "Starting training for 2 epoch(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=*==*==*==*==*==*==*==*==*==*=\n",
            "Loading train data...\n",
            "InputExamples: 62335\n",
            "321394 train data loaded!\n",
            "=*==*==*==*==*==*==*==*==*==*=\n",
            "=*==*==*==*==*==*==*==*==*==*=\n",
            "Loading val data...\n",
            "InputExamples: 313\n",
            "313 val data loaded!\n",
            "=*==*==*==*==*==*==*==*==*==*=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2\n",
            "  0%|          | 296/321394 [00:30<9:07:26,  9.78it/s, loss=0.746, loss_mat=0.000, loss_rel=0.000, loss_seq=0.746]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-637282d0443b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Train and evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training for {} epoch(s)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-f88461e4d27d>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, params, ex_params, restore_file)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Train for one epoch on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Evaluate for one epoch on training set and validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-f88461e4d27d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_iterator, optimizer, params, ex_params)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# fetch the next training batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorres_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABL4AAAH4CAYAAABE2yTaAAAgAElEQVR4nOzdX2hbeX7//9f+2JtTdg0+3sLXqK2wVulscJNdloC2IQYNpLtl6aYxoQaxF9M0DL5oPHZhhniGmSlNiyPRXIRJlhJCyO7FVFjFhNQz7jQdOm7TGgmygWRqZlOdldGFCXTWJ7Az6Fye30U4ZyVZf47kY1mSnw8wJDpHn8/78zmf88dvn/M5X3Fd1xUAAAAAAAAwZP6/gw4AAAAAAAAA2A8kvgAAAAAAADCUSHwBAAAAAACELJfLKRaL+T+ZTMZflslkNDU1JcuyDjDCw4HE1yHjOI6ePHly0GEAOMQcx1Emk5Ft2wcdyi62beuTTz456DD6wrCcL/ayTXsxVnvZz47jaG1trSd1HWaDeBwZxJgHQb/1a7/FMyj6+bplUPRzH+73fvG1r31N9+/fV6lUUqlU0qVLl2qWb29v69GjR/tWf73Dui0GLvGVyWRqMqaxWEyFQuGgw+qZQqHQdZtzuZwmJyf1i1/8Yh8i643q7T89PR14h63PtHs/CwsLchxnn6MOHs9+xBSk7a3iqf6rBHprL/t7P5ZjWZampqY0OTmpfD6/r3V1ynEcLSws6MSJE/r888+7LqfbY1S/GYbzxV62aSdjdS962c9eXZ9++um+11Wt1/vyQcvlcns+jvTaIMbc78I6pwxrPIOiV+eCav1yzRZWOYfh2m8vLl26pNnZWUWj0X2va7/Gcy6X2/Nda73YFl/dl1L3SSaTUTKZ9LOkhUJBqVTqgKPqrbGxMUUika6+OzMz09H6lmWpUqno+PHjXdUXtlwuJ0kqlUpyHEdvvvmmPv7440Dt8tbZ2tryx49t27pw4YLee++9XZn3sDTrQy+ejY0NXblyRYZh+Ou/8cYb2t7eVjweDyWGmZkZRaNRZbNZvy6v/7y2N4unUCgom83KcRz/M7QX1r6zl/2903KCxLzXeOLxuB48eCDbtnX58uWW64bV9qAMw9C1a9c0Pj7edRl7OUYdlHbHqEG2l23ayVjdi172s3cuWF9f71mdUnj7ci+vSfZS10HtO4MY8zAL45wSpn6LZ1D06lxQjWu/wbr22yvvJoQjR47se137NZ7DSNr1YlsMTOLL+6t59Y6ZSCSUTqcPKqQD4Q3YXnj06FFPss9BOI6jTz/9VK+88oqk3+wce2GaphYXF/c1sdNpH8bjcf393/+9KpVK6LFUMwxDqVRK6XRatm3LNM2G6yUSCRmGEWoi7jAIa98Ja38PUk6QmHt5/OllXdUmJia6+t5+HKN6oZ+O8/ul222KcIS1L/dyrA7ifjGIMR8G/Xb86bd4sBvXfoNz7bdXjuNoaWlJr7zyStPfxQZBIpEIbbvt57YYqEcdnz17tusRsNOnT+97kuAwsm1b2Wz2oMPYd+VyWePj4/uS9Oq0D725V+LxeM/usotGo03b7j1jffz4cZJeHRjEfWcQY8besd0xKHo5VgdxvxjEmAEcLI4b7XlTwezXo5eGYehv//Zv+T2rRwYm8WWapsbHx/Wnf/qnNc+Pmqapl19+uWZd7/ng+jnAvGdHFxYW9M477/jzF3mDun4+Fu85WK8c7zGWIGzb1vT0tGKxmN555x0tLCy0rK9dXdXLW80bUz1X09TUlN/O+vKq+6h6rqfq52sfP36sVCrVtM76fu72wNBse1X34+TkpN5//319//vf99u217dfWJalbDarc+fO7fq82baojtWb+8qb08fro076sJrjOA2faW7VP0HiacS2baXTaZ08ebJl4quTucbCHPOdtGsv+2l1Xblcrul+0Siu+m3R7XZvpN3+HjTmduUEjTnI8ad6+3e7LYLW1WxOuvrjT5CxUd9/nf4hJcgxqpPxHNb5q5VOx2q7/WIv+2Cn7Wq1DzaLt9E23etxoxNB6wqjnztpV/U+69Xn9Xsul6vZzxrN9dhuW4RxHAvzuNruGBVmXZ7qPux0m+7n9Ua3MQc9zge5PgxrH2xXTq9j3us5JUjM3V637Hc8/XbN1qyuTq9XW6muo/442uwcFaQsrv3659ovEolobGys4zaFpZf7V6eabbfqawmPF3P99gqyLYLkN5q1vfo6U+6Ayefz7sTEhDsxMeHm8/mGy0+dOuUWi0XXdV13Z2fHPXv2rL9usVh0T5065ebzeX/Z8vKyW6lU3Lffftv/XrFYdM+fP+/u7Oy4ruu6lUrFnZ+fd5eXlwPHWl3Gzs6OOz8/75f305/+1P93J3XVl1Pf9vn5ebdSqTQs13Vdd3l52X3llVfcdDpdU1d9Xzb7vLptb7/9tl+XV38n/eN9p9X2qo6nevt0Y3l52R87ExMTNfV6gm6LfD7vptNpN51Ou/l83i0Wi+7Zs2drymvXh/XxTExM+Nulup4g/dMunur9ptn+0yieTrdn2GO+XbvC2E+9trfbLzoZq622eyda7e9B9+V25XQSc6ty0ul0Tb/v7Oy458+fb7jPtosnSF3126b62Oe6wcZG/Tb1zg+djh+v/HbHqCD7aRjnr05ibneMajfGwjpXBmlXkH0wyDYN65zbadu88ur3i7D6OUhd3hisrrvRueCVV17xy/bqqv5e0OOht2yvx7EwjqtBj1Fh1NWsD7sZh3u93mh0bm90LRAk5iB9GOT6sF3bg8YcZMz3KmbvO2GcU4LE3M11y37G49XXL9ds7eoKer1a3eZmx7FKpeKm0+maZY3KCIprv8G59gvqww8/3NPvsK4b7v6112ubIOUtLy/vqrvRNmy3LYLkN4Ls76dOnXIH5o4vTyKRUKlUUjabVSqV2vWXwWw2q6tXr/q3DNbP4yRJyWTSf5QsGo3q9OnTkqQvvvhCOzs7kqSVlRXNzs76z9t6cyJtbGwEvgsmEokoEonItm3/rppisehnQ72yw6hLevHYXvUdPNX1Vzt69Kg/mbthGDp58qTK5XLgeppJJBIdTZAadHuFaXZ21n+V7P3793Xjxo2av2R3si1u3rypZDKpRCKheDyuu3fvdnyr6pkzZ7S5ualSqaSHDx/q//2//+cv67R/2sXj1ZXNZjU7O6tEItEynm5uf96PMd+qXWHtO1Lr/eIgxupeY+616pckePHs1wSlx44d84/hlmXp5s2bevfdd2vuXgwyNtbX1zU3N+dv03g8rrm5uX2J2dNsPId5/gpTuzEW1j7Yrl1B+yfINg3zuNHOysqK5ubmao63z58/37WtwujnoHV5vL+GNjoXHD161N+fDcPQxYsX9fTpU/8uozCPh706jvXyGCXt7sNG26sX1xszMzP+dU+jn+rt3y7mbvuw/vqwXduDxhxkzPcqZim8c0rQmNvtO72OR+qPa7YgdQW9Xg3CMAxNTEyoWCxKUldldIJrv8G79gtLr/avXgmyLYLkN4K0PZlMDs7k9vW8BFgmk/HfTLe9va1yubzrdsSxsTGVy2Vtb28HKttxHD179qzhGyO//e1vB54I3TAMHTt2zD8B//znP/ffVPCtb30r1Lok+W/u+9GPfuRPSL69vb3rwBvGpHHxeFzHjh3T5OSkIpGI7ty503HSJ8j22s9nnr2L+TfeeEOWZSkSiXS0LZolj/YSz2//9m/7/++0f4LGc+TIEd28eVOWZbXs3yNHjnR8S/x+jPlm7Qpz35Fa7xcHPVab6bdJai3L0vnz5/1jbSQS8Sd7D9MPf/hDSS8uLt944w0tLi7WHOeCjA3HcZTP55VMJkOPr5Vm4zms81fYWo2xsPfBVoL0j2mabbdpL2P26qqOxzRN3b17d9e6e+1nSYHrkl48cpDP53X79u2Gy+vj8fYv70IzzONhL49jvTpGSbvbNTY2pl//+tc12+ugrjeaaRVz9dunW/Vhu+vDsPbBTvavXsQc9jklyFhtte/Ytt3zeKT+uGYLUpdpmm2vVztx+vRpra6uKpFIqFgsdlVGUFz7Dd61X1h6tX/1QtBjVLv8RtBrJGmA3urY7HWr586d09LSkn8xNjo6uivRY5qmRkdHO64zm83u+ULDe3X4xMSELly4oP/8z//Ul19+ueuAEEZdiURC5XJZk5OTkuSfvPfrLw4zMzOamZmRbdu6cOGCJOn27dsd1Rfm9uqGV/fOzo7/F4owtkU3DMPwD+qe/egf0zT10ksvaWVlxf+LUbP16ufPC6KXYz7Mcto56LHa77xfpO/duyfTNP031ewXx3F0+fJlpVKpptu/1djodv6b/TSoY2wQ98FexOw4Tqh/hW83noPWdfPmTWWzWSWTSV2+fFlXrlxpe0Fs27aeP3/u/38Qx2qvj1FBHNT1RreC9mGQ68O9tj3o/tWrmMM8p/TbWA0znl6O+XZ1Bb1eDcI0TX355ZeyLEs7OztdXT8PIq79+sugnVOCCJrfCLLdB+ZRR9M09S//8i8Nb9WLRCL+rZUjIyP+raaeYrGokZGRwLdeGoah8fHxhifUTidvP3LkiJ4+faqNjQ390R/9kUZGRvTFF1/4sYRZl/fYgncr+IMHD3pyF4r3F7bFxUXdunUr8PfC2l57Ydu2fvWrX0kKd1uEYT/7J5lMKp/PB56488mTJ4HL7tWY7+X26oex2s8sy9LTp087TnzvxXvvvafx8XH/FnvvrahSsLFhGEbDV3hvbW3tY9TNDeIY67d9MMg27WXMXjyN6lpbWwv86EEn4zlIXd5fjBOJhMbHx7W6uto2Bu+uCNM0B3KsHsQxqt7Ozo5GRkZkGEbfXW80Ux1zN33Y6PowzGuAdmO+lzGHdU4Ja6z2Yzy9PPYGqavd9WqnTpw4oZ/97Gd+DMOOa7/+MSjnlGpBt0W7/EYnbR+YxJdhGHr27JnefPPNmgu4lZUVHTt2zL+QSKVSSqfT/i/03tvrUqlURwehc+fO6fr16zUd1s2bEby7a8bHxxWJRDQ+Pr7rTXph1XX69Glls9maN110+/bD+kFkWZZ/YPHiqx9M5XK5o9tvw9xe3XAcRzdu3NA3vvENHTlyRFJ420Jq34dBvr9f/XP8+HFFo1F9/PHHLdezbVs3btzQ7/zO7wQuu5djPszt1Uon22Kv2/0ghBFzsVis+UV4dXVV6+vrqlQqobe/UCjo2bNneu2112rq+/LLL/3/txsbjbZpoVDQZ599FmqsQR3E8TCM7d5P+2DQbdrrmK9fv15zHs7lchobGwv1mqTbul577TVtbGzsOp9Xl1Pdz6ZpDuxYDXqMCusYns1md/VP9bmwn643gsYcpA+DXB+G0fagY75XMYd5TgnjfNpv8Ui9O/YGrSvI9WonvKeSfv/3f7/7wHuIa7/2+4X3NsF+TR5V6+X+FUQ0Gq2ZYyuXy+nmzZv+8qDbIkh+I3DbQ5nKv0fS6XSgt87Vv8HOe3uAN8O/9z2vvPn5effOnTvuxMSEe/bs2Zo3z506darrN9x5qt+alM/nG749o11d9cvr30rY6I0irvviLQvpdNqtVCo1b8lp9OacVnXWvzWj0VsC69cJqtn28gTd7q00KqNZzK22RaM3DbVqd7M+rC6nXb+16p8g8TSry/vceyNLs7cndbNd9zrmO+nnve6nnewX7cZqo5i66b92+3vQmNuVEzTmIOXU9433Npfqfmp03KjvxyDHOu843qqcRmU1GhvV/Va9L3QyjtodozoZz2Gdv4IKcoxqt1/sZR/stF1B9sEg27RdzEHGalCN9o1GsYbRz63qql7mvRGsWf137typ2c86udZqFm+3x7FG5XVzXA1yjAqrrn//9393Lctyz54927IPe3G9EWbM3R7nO73W6kSrMX8QMYdxTmkXcyf7Tq/jaTdWe3nNFnR7tbpe7eRcUKlU3A8//LCj9lTj2q//rv2Wl5eb9l0n9vJWxzD3rzCvberrrX8zbv02q77GC3qMCpLfaNf26ji+4rquG2Z2DwfDm5NgcXGx5vnWQqGgbDYbaA4PAABwuHl/Je3kLc0AcNh5d5sM2xxL2LtcLqfFxUX//7Ozsy3nWe53uVxOGxsbfn4hl8tpa2sr9DaFnd8g8TVEvMHx+PFj/7MzZ86Q9AIAAG1VX5xz/QAA7WUyGd28eXPgkxk43BrlEep9+9vf1u3bt2Xbds2bPNPp9L79sSzM/AaJLwAAAAAAAAylgZncHgAAAAAAAOgEiS8AAAAAAAAMJRJfAAAAAAAAGEokvgAAAAAAADCUSHwBAAAAAABgKJH4AgAAAAAAwFAi8bXPHMfRkydPel5nJpORbduB1rdtW5988sk+R9W9sOLrpJxO+xCdOYj94qDsZfwyDl/o92MUesNxHK2trR10GB3pt7HLeRDov/3yMGNbAOiVgUl85XI5xWIxxWIx5XI5SZJlWZqamqr5rJ/kcjlNTk7qF7/4RU/q8/pjcnJS+Xy+7fqO42hhYUEnTpzQ559/3oMIO5fL5UKJL2g5nfZht2zb1vT0tD+mq3+mp6dl23bNmK/+WVhYkOM4u8osFAr+dxsta1RWoVCQJGUyGcViMWUymYYxNquzG53uF17sXqyDYi/7V6/GYb8bhGMUesM7bnz66acHHUpgYZ2/wtJv50G80OtznHe+r77eOCzanVN6uS0G9domLGGc38Psw8O8XwCHxVcPOoCgZmZmtLW15f9bkuLxuO7cuaP//d//1Q9/+MODDK8hL85eicfjevDggWzb1uXLl9uubxiGrl27pvHx8R5E152w+jBoOZ32Ybds29bp06d19+5dWZalpaUlXb16VaZp6ic/+Yls29bMzIyi0aiy2ayuXLkiwzDkOI7efPNNvffee7p06VJNmZVKRdFoVMViUYlEomZZIpFQqVSSbdt6/fXX9dZbbykej/vLvbI++OADnTt3TvF4XKZp6h//8R/1ySefdLV/WZalSqWi48eP13ze6TYdGxtTJBLpuP6Dtpf9q1fjsN8NwjGqU832i0G33+3yjofr6+uhldmLmPtJv50Hqw3rfhFEkHNcWP3j/ZG4VCr51xMff/xx343V/dLunBLW9UaQ7TWo1zZhCeP8HlYfHvb9AjgsBuaOL0k6d+6cnj59WpOF/+///m9973vfO8CoBt/ExMRBh3DoVCoV/eAHP2i47Ac/+IEqlUrDZYZhKJVKKZ/P1+wHjuOoXC7rO9/5jsrlclcxHTt2TMlkUisrK119v96jR49CuUvM+yWsPpk3KNi/9m6Y+jCs/aLfDGK7BjHmYXWYt0WQc1wY/eM4jj799FOdO3dO0m8SD4fxl/tm55SwrjeCbK9Bv7YJy17O72H0IfsFcHgMVOIrHo/rpZde0scffyzpxV0zv/d7vyfTNA84MqAzx48fr7njqlo8Hm/7V91oNCrDMPz/O46jaDSqU6dO6dNPP+36AvnP/uzPlM/nZVlWV9/32LatbDa7pzKAYTOs+8UgtmsQYx5WbIvW6J/BwvYCgP40UIkvSUomk9rY2JDjOMrn8/rd3/3dXevUz2dU/ey3N29S9Zxg3nPd3Twj3mjupEblVK/XaL6kg4p5YWGh6d1FzVTHUz0PVfX8UNV1eJ97Mdc/O9+q7Y3qbdSHjebMajbvW6ty2qmeV877bnV5+z1Xg23bSqfTOnnyZE3iq1gs6rd+67dkmqa++OKLrhNfR44c0fe+972u7/qqnrPh8ePHSqVSLedLaLVfVPd1q/kWgu6DreJdWFjQO++8449Xb5t2M1aD7F/VbdvvOQpbxewty+VybY9R7XSyD3YSc7M+bNau6jjeeecdLSwsNNyu//Zv/xZa2xvFUx1TkP2ik2Nmu/HTalt0OuZbCbq/Bx0bnezL3c5B2MkxKui5KYh2550wjgm9Og+GFXMvt0Un11FBxmEY26vdOa7T82kz3riYnJzU+++/r+9///uKxWKampra9UeuIOeLIMeoVsK+hgyyLdqdU4Jeb7SqK+j26vbapttz916ukTztji3dxtPN7yBS+z4MEk8n+0Wr7R7WWO2kD4OM+V5eZwIDwx0wlUrFnZ+fdz/88EP3pz/96a7l+XzePXXqlFssFl3Xdd2dnR337Nmzbj6f99dZXl52l5eXa76XTqdr1gmiWCy6b7/9tlupVGrqry57eXnZfeWVV9x0Ol0Tf3VdYce8s7Pjzs/Puzs7O7uW1ddVLBbdU6dO7Sq7Ha9d3ve8dnntrK4vnU77sRaLRffs2bN+/UHb3qiu6pjT6XTN/3d2dtzz58/75QYtp/r7zfqwUqm46XS6ZtlPf/rThusGUSwW3fPnzzfdXhMTEzU/jba5V3+j8VXfrvp+8Xz44YdupVKp2UaVSsX98MMPO25TuziC7BfVMTfbFkH2wXa8fSCfz/vjb3l52a1UKu7bb7/d0VgNsn/Vb+9ux2EQnexfQbZFK0H2wW5ibtSH7dpV3cf1fVi9r7Zr+/Ly8q79r9G+GHQcBunbdsfMIOOn3bYIOuaDateuIGMjSB96feNZXl7ueJwGjTnIvhNEkPNOJ8eEVnp5Hgwr5urv9mJbtLuOCjIOw2y767Y/znd7TG5UTqv9O2g/tztGBRHWNWSQbdHJdW+7Me8dN711G53jgm6vTq7Vuz13h3GN5LqdHVs6+X2n299BquNo1odBr23a7RdB9/cwxmrQbdpuHIZ9jAKGxcDd8WUYhk6ePKmLFy/qW9/6Vs0yx3GUzWZ19epV/zEy0zS1uLiobDbbk/kjEonErufCjx496k8e7sXvzcPU65jX19c1Nzfn1xWPxzU3N9dVWUePHvXbahiGLl68uGsONkm6efOmksmkEomE4vG47t69q3g83lHb6+tKpVL+nX/Si8nZq/vdMIyGE162KycIwzA0MTGhYrEoSX579+uR2zNnzmhzc1PZbFazs7O75jJwHEeu68owDH987WUC6Hg8vqe7voJqtV/sRaN9sJ1kMuk/XhqNRnX69GlJ0hdffKGdnZ3AYzXI/rWysqLZ2Vl/vHQ7DtvpdP/a67YIug+2064Pg7QrEokoEonItm3/zshisdhwX23V9pmZGZVKpaY/reYV6WYcepodM6Vg4yfItmg35sPU7dho1YfeX6/3Y36csM/L7c47YR0Tenke7Mfj2H6pH4e9ansvddrPrY5RQe31GlIKti3Cuu5dWVnR3NxczTHn+fPnoR8v9/vc3c25qZNjS6t4wvwdJIgwrm062d/3OlaDxBxkHA7jMQoIw8C81bHad7/7XSWTSR05cqTm8+3tbZXLZY2NjdV8PjY2pnK5rO3t7Y5PzK3E43EdO3ZMk5OTikQiunPnTsPyW03c2MuYbdtWPp9XMpkMpbz6dnkHWNu2a36xbJSskTpre31dY2Nj+vWvfy3HcfxfbC3L0vnz57W9vS1JikQieuWVV1rG3KicIE6fPq3V1VUlEgkVi8VdSdj9cOTIEd28eVOWZdWMie3tbd2+fbvm7VtnzpzpuE3VXn31Vb3++ut+cm8/hDFhedB9cK+CjFXTNNvuX47j6NmzZ0qlUruWffvb397TNusm5mb7V7eC7IOtBDlGBW3XsWPH/AvBn//85/6bo+r31X4ch82OmZ2Mn71ui7C1i6eTPsxkMsrn87p9+/a+xBr2ebnVeUdSqMeEXpwH+/U4FoZ247CXbe+lTvu52TGqE3u9hgyyLbxpUfZ63evVVV2OaZq6e/funsptJMxzd5jnpm6OLdXC/h0kiL2e3zvd38M4d7eKOcg4HNZjFBCGgUx8tTI6OrrrzhvTNDU6Orov9c3MzGhmZka2bevChQuSpNu3b3d090+vY94vtm3r+fPnHX0nrLZ7vwjdu3dPpmnKcRwtLS11VEYnTNPUl19+KcuytLOzo5dffnnf6qqu86WXXtLKyor/1yBJ2tnZ0dWrV/2TrWVZeuONN/b0C4FpmvrjP/5j/dM//ZP+8A//MJT490sY+2AQYe6n2Wy2J29y6uWxpZf7YJB2RaNRra+va2JiQhcuXNB//ud/6ssvv9y35E+vxqHUfvz0+njYTtB4gvThzZs3lc1mlUwmdfnyZV25cmVfLuJ7fV4O45jQ6+0+jMcxKdg47FXbe+mgr0W7uYaUWm+LTuZCa8V7c3avhLktwjg39ds5pdfC2t/3Wk4n43AYj1HAXg3co46tRCIRjYyM7LpLpVgsamRkpKvHboLyMu6Li4u6detW4O/1MmbDMBSNRnd9vrW1FUr53t0VQU+me2n7zs6ORkZGZBiGLMvS06dPu/ols7qcTp04cUI/+9nPJKlnfz1JJpPK5/M1F3O/+MUvau5+jEQiikaje779/vTp0/qf//kfffrpp3sqp1e63QeDCDJWg+xfhmFofHy84YVL2C9G6OWxZS/7YLUgfRi0XUeOHNHTp0+1sbGhP/qjP9LIyIi++OKLfT0PSPs7DoOMn7C2RVi6iadVH3p/UU8kEhofH9fq6mroMe/3vlN93gnrmNDL8+CwHsfqNRqHvWx7Lx1kP3s6vYYMsi3Cuu71ymlU19raWqiPj+3Xtuj23NTL83u/CWt/D7OcduNwWI9RQBiGKvHlPcOcTqf9xID3FrxUKuVf1EWj0ZrnnHO5nG7evNlxfd6bN6qVy+WObq3tZcyN6ioUCvrss886Ksdz/fp1/80n1TF3ctESpO3Si79c1K9T/WbDYrFYc5Gwurqq9fV1VSoVra2tBS6nE978OL//+7/f8Xe7dfz4cUWjUX388ceSauf38oQxz5f04iKp0a3SQdSfeC3LqtkOYQljHwwiyFgNun+dO3dO169f3/Xm1rB1sn+FIeg+2GnM9X0YtF3eHZLj4+OKRCIaHx/vel9vJ+g4DGO/CDJ+wtgWnWjXriDxdLMvv/baa9rY2OjqYr5VzGHvO+3OO2EdE3p5HgzzONarbRHkOirIOOzVMdzTi/Npr88X0t6vIaX22yKs616vnOqYvbrGxsZ2XYPtZXuFuS3Cukbq1fm9H4W1v4dRTtBxGKSuTCbT8A2WwFA76Nn1O1X/lrtGb01pt473dgtv+fLysptOp/1/dxvLxMSEOz8/7789pfqNYF65jT4LK+ZG8TQqqzoG700tnbZ9eXnZvXPnznIRRGEAACAASURBVK6YGtXRqG9a9WN9vP/+7//uWpblnj17tmFdjcrw3t5UXV435bQaZ92+8TBo26v7sNG4+ru/+zu//6vfhFRdpvd5q3ZVj62zZ8/WvB1nZ2en4dtTg/DePNPtflH9fe+n+m1AzdrVbJw1Ut326n1qfn7evXPnzq4+CXL8CbJ/1bdtL+OwnaBjrN0xqtN6Gu2DQQXpw6Dbwvs8n8/3rO2txmGQ/aKTMjo9Hv7Hf/xHR2M+qGbtahdP9fZp1f5Gx7Vut1eQmBvF1M3+F+S8Ux9Lt+3p9XkwjJgblbVf26Lb66hG8YTR9iDnuEbrdnKO83jtrB8f9YKeL7o531YL8xoyyLZod04Jui0a7WONtNpe3dbVzflrr9dIrdpdfWzp5Hwaxu8g7fowaDxB94tWYyyssbqX3xm7Oaek0+mmxxtgWH3FdV33oJNvGDzeXw66fWvZMPD+ksIz9AAAAMFwDQkA6LWhetQRvZHL5bS4uKjFxUUtLCwculfjZjIZxWIxra+vk/QCAAAI6LBfQwIADgZ3fAEAAAAAAGAocccXAAAAAAAAhhKJLwAAAAAAAAwlEl8AAAAAAAAYSiS+AAAAAAAAMJRIfAEAAAAAAGAokfgCAAAAAADAUDoUiS/btvXJJ58cdBgAAAAAAADooaFOfDmOo4WFBZ04cUKff/75QYcDAAAAAACAHvrqQQewnwzD0LVr1zQ+Pn7QoQAAAAAAAKDHhvqOL8/ExMRBhwAAAAAAAIAeOxSJLwAAAAAAABw+Q5n4KhQKisViisViWlhYUKVSablOLBZToVDYtSyXy+0qy3GcmnIsy9LU1JS/Ti6X2/f2AQAAAAAAoL2BSXzlcrmaRFX9j5e4KhQKev3113X//n2VSiVdvHhRt2/frimrfp2HDx8qnU77ZSQSCaXTaa2trWl9fV2lUkmbm5uSpCdPnvjlWJalpaUl3bt3z19nY2OD5BcAAAAAAEAfGJjE18zMjEqlUtOfRCIhSVpfX9fc3Jzi8bgkKR6Pa25uzi/HcRxls1ldvXrVX8c0TS0uLiqbzdbc0XX06FFdunRJ0ouJ8k+ePKlyuewvX1lZ0ezsrEzT9NdJpVLa2NjYdWcYAAAAAAAAemuo3upo27by+bySyWTTdba3t1UulzU2Nlbz+djYmMrlsra3t/2EWKtJ8R3H0bNnz5RKpXYt+/a3vy3HcWQYRpctAQAAAAAAwF4NVeIrqNHRUf8uLY9pmhodHe24rGw2699tBgAAAAAAgP4xMI86BmEYhqLR6K7Pt7a2/H9HIhGNjIyoWCzWrFMsFjUyMqJIJBK4rvHx8ZpHHz3VE+UDAAAAAADgYAxd4iuVSimdTsu2bUkvklCfffZZy3Vs21Y6nVYqlero8cRz587p+vXrNYkuJrYHAAAAAADoD0P3qGMikVAqldKJEyckSbOzs/rhD3+oxcVFSS8myU8kElpcXPTXkWofWczlcv763ncafRaPx3Xnzh2dP39e29vbkqR0Os2jjwAAAAAAAH3gK67rugcdBAAAAAAAABC2oXrUEQAAAAAAAPCQ+AIAAAAAAMBQIvEFAAAAAACAoUTiCwAAAAAAAEOJxBcAAAAAAACGEokvAAAAAAAADCUSXwCGzs9+9jPZth1oXcuy9JOf/GSfIwIAAAAAHAQSXwD6kuM4evLkScffy2Qy+ta3viXTNAOtH4/HdeLECeVyuY7rAgAAAAD0t4FLfGUyGcVisZqfQqFw0GG1VSgUBibWsIXV9n7sw+rxOD09Hfguo7DlcrmafWLQkzi5XE6Tk5P6xS9+0dH3CoWCJiYmlEgkOvqet34/jS0AAAAAwN4NVOIrk8komUyqVCqpVCopm802XdeyrK7uFulGkLrGxsYUiUR6Ek8QveyfsNreb33oJZdKpZI2NzcVjUb18ccfH0gcW1tb/n5x//59Xb9+faCTXzMzM0qn0x19x7ZtZbNZnT59uqs6T58+rfX1dTmO09X3AQAAAAD956sHHUBQ3p00x48f9z9LJBJNfzl+9OiRotFoT2ILUlc8HteDBw96Ek8QveyfsNreT33oOI4+/fRTvfLKK5IkwzB07dq1A4ljY2NDqVTK/ywej2tubk5bW1s9j+cgffzxxzp58mTgRxzred978uRJx3eMAQAAAAD600Dd8fXs2bNdd2OcPn1alUql5jPvzo9e6GVdYRnEmNHa+vr6QYdwoLxE5He/+909lZNMJg99XwIAAADAMBmYxJdpmhofH9ef/umfyrKsms9ffvllSS9++V1YWNCJEyf0+PFjpVKphnMv2bat6enppnMieXNJxWIxZTIZSb+Zy8krK2hdlmVpamqq6RxQXl25XK6m3oWFhV1Jvup5nKampvTOO+90NJ9TkJiDtD1IH4bZ9n7qQ6/dk5OTev/99/X973/fL6t6XNb3Zf3cZEH7uR3vTrNLly7VfL61taVkMhmojGrVfV3fL17f5XK5mn704g/a9iB1NSur0TaVXoztL774oundXvXxNItpbGxMT58+PbC52gAAAAAAIXMHTD6fdycmJtyJiQk3n883XKdSqbjz8/NNl6fTaXd5edn//87Ojnv+/Hm3WCzuqiudTrvpdNrN5/NusVh0z549W7Neu7qq65ifn3d3dnZ2LVteXnZfeeUVN51ONy0zn8+78/PzbqVScV3XdYvFonv+/PmG5bUTJOZ2bQ/ah2G0Paxywu7Dt99+u2F7vbpOnTrlL9/Z2XHPnj27q11BxlinisWi+/bbb/vt7OR71f3h9WH1dvb62fvMW8frd69N7dpeLBbdU6dO+Z81Gj+djI1W27JRf+Tz+Zp2eVqNMQAAAADA4BmYO748iUTCn9g+lUo1vQOklUuXLmlmZsb/v2EYTSdNv3nzppLJpBKJhOLxuO7evat4PL6nNjRy9OhR/64dwzB08uRJlctlf3m5XNbJkydlGIYkKRKJKBKJ7OudKa3a3kkfttOu7WGV06s+dBxH2WxWV69e9fvLNE0tLi4qm83uGq9hjjHbtrWysqK33nrLb2dQKysrmp2d9e+aMgxDqVRKGxsbNTEfPXrU3/aGYejixYv+XVJB276ysqK5ubmaubSeP3+unZ2dmpjCGhv1EolEzfgFAAAAAAyngUt8ebwE2Pj4uN57772Ov1/9mNXk5GTTeX1mZ2d7MtH1xMREy+XRaLQmAbG9va3t7e2uJ/IOol3bg/ZhO+3aHlY5verD7e1tlctljY2N1Xw+Njamcrms7e3tms/DGmO2bevy5ct69dVXO056OY6jZ8+e+Y+/ej+pVErlcrkm8VXfz17/2bYdqO1eXdUvVzBNU3fv3t3VD0HHhmmaGhkZabgsHo/r2LFjmpycbPhIajXbtvXrX/86UJ0AAAAAgP43MG91tCxLlUql5q2OknTu3DktLS3Jtu3ACYxMJqN8Pq979+7JNE05jqOlpaX9CDs0iURC5XJZk5OTkl7crXTnzp19TXy1Qh+2Njo6uqtc0zQ1Ojoael3Sb5Je77777p7ak81mO07C2bat58+f+/9v13bHcUK5a6uaYRj6+te/3vQ4MDMzo5mZGdm2rQsXLkiSbt++vWvdnZ0dvfTSSwe2XwEAAAAAwjUwd3yZpql/+Zd/afhYYyQSCXyHi2VZevr0acNfevuZN/F3qVRSqVTSgwcP9uWRyyDow9YikYhGRkZULBZrPi8WixoZGen6kdBmmiW91tbWAj8GbBiGxsfHGyakGk0CX817PNE0zUBtNwxD0Wi0YV2dxFwf/7Fjx/To0aOW63l3li0uLurWrVu7lq+vr3f1UgAAAAAAQH8amMSXYRh69uyZ3nzzzZpfjFdWVnTs2LGaxFf9L/GWZWltbc1fXiwWa34xX11d1fr6uiqVSs16QeNqVVdYTp8+rWw2W/MYWrvHtpoJI+Yw+7BXwuzDVry5sdLpdM1bMNPptFKpVMePIbazurq6K+llWZa2trY6quvcuXO6fv16TaKr0ZsWr1+/7vdZdbtM0wzUdm+d6nK8usbGxrrun9OnT2tjY2PXnG3e2z6rlcvlXY9R2ratZ8+e6ciRI13VDwAAAADoQwc9u34n0um0/0ZH76fRm9lc9zdvjZuYmKh5k5/r1r4Z0itjeXnZf1Ok9+/qn/oygtZVvcz7qX7jXXVdXlvqP6tUKm46nd71prmdnR03nU53/Pa+VjEHbXu7Pgyr7f3Yh0HHYX0fVb+NsNMx1oz3xsT6slrtG63U93V9GcvLy+6dO3fc+fn5rtvebJ36t0cGGRuNyqxfVl9Ps75eXl5u+3ZWAAAAAMBg+Yrruu5BJ9/Qmjcv0eLiYs38S4VCQdlsVleuXAn9LqJhQx+Gw7sDrJ/fiPiTn/xEP/jBDzp6jLVQKKhcLvd1uwAAAAAAnSPxNSC8xM3jx4/9z86cOUPCpgP04d7kcjktLi5K6u9+cxxH7733nl599dVAc9BZlqV//dd/1V/+5V/2IDoAAAAAQC+R+AIAAAAAAMBQGpjJ7QEAAAAAAIBOkPgCAAAAAADAUCLxBQAAAAAAgKFE4gsAAAAAAABDicQXAAAAAAAAhhKJLwAAAAAAAAwlEl8AAAAAAAAYSiS+AAAAAAAAMJSGNvFlWZamp6dlWRZ1URd1URcAAAAA4BAa2sSXaZoaHR2lLuqiLuoCAAAAABxSXz3oAILK5XJaXFxsujybzUqSUqmUstmsjhw5opGREZmmqUKh4H9eLpfblhNkHeqiLurq/7oSiUTT5QAAAACA4fcV13Xdgw4iTF6C7Mc//rG++c1v6pe//KXef/99pdNpzczMUBd1URd1AQAAAAAOiaFLfHmq7wzZ77s+qIu6qGs46gIAAAAADJehm+Mrl8spFovpgw8+0I0bN7S+vq5YLKZcLkdd1EVd1AUAAAAAOESGbo6vxcVFf16gW7du6bXXXlMymVQqlVI0Gg11DiLqoi7q6u+6uEMMAAAAAA63oX3U0bIsLS0t6erVqzJNk7qoi7qoCwAAAABwyAzdo47Vnj9/Ltu2qYu6qIu6AAAAAACH0NDe8QUAAAAAAIDDbajv+AIAAAAAAMDhReILAAAAAAAAQ4nEFwAAAAAAAIYSiS8AAAAAAAAMJRJfAAAAAAAAGEokvgAAAAAAADCUSHwBAAAAAABgKJH4AgAAAAAAwFAi8QUAAAAAAIChROILAAAAAAAAQ4nEVwds29Ynn3xy0GFAbAsAAAAAANDewCS+CoWCYrGYYrGYpqenZdt2z+p2HEcLCws6ceKEPv/886axFQqFnsXUL3rd9nbbAgAAAAAAwPPVgw4gqEQioWw2q2w2qytXrsgwjJ7VbRiGrl27pvHx8YbLx8bGFIlEehZPO5ZlqVKp6Pjx4/teV6/b3m5bBNHL/gEAAAAAAAdnYBJf/WBiYqLh5/F4XA8ePOhxNM09evRI0Wi0J3UdVNubbYsgetk/AAAAAADg4AzMo44IxrZtZbPZgw6jb9E/AAAAAAAcHkOZ+KqeD6zR/FO2bWt6erpmnVwu17KchYUFVSqVmuWWZWlqaqrpvGPe93O53K6yHMepWTeXy/nLp6am9M477zSNq5Hqua8eP36sVCq1K67qGDKZjCQpk8nsWi9I/4TZ9iDabYt2MQfpn6BtBwAAAAAAg2HoEl+FQkGvv/667t+/r1KppIcPHyqdTtckv27duqVUKqVSqeSv89FHH8myrKblXLx4Ubdv366py3vM7+HDhw0fnUskEkqn01pbW9P6+rpKpZI2NzclSU+ePKmpa2NjQ5ubmyqVSrpz5462t7f18OFDzczMBGq3N/fV5uamzpw5o2w2q1KppLt378o0TT+eUqnk3/GUyWSUTCZ1//59SfITQEH6J6y2BxFkW7SLOUj/BG07AAAAAAAYDEM1x5fjOMpms7p69ari8bgkyTRNLS4uKpvN6vjx4zIMQ5cuXar5nmEYuyZoX19f19zcnF9OPB7X3NxcV3EdPXrUr9MwDJ08eVLlclmJREKSVC6XdfLkSX/C/kgkokgkItu2a5IyYbp586ay2awfw927d/1lQfonqHZtDyLItggr5jDbDgAAAAAADtZQ3fG1vb2tcrmssbGxms/HxsZULpe1vb3tf1b9qN7k5KTW19f9ZbZtK5/PhzYBeruJ2KPRqDY2NvxHALe3t7W9vb1vSS9Jmp2dbZl8atU/ndjLJPRSZ9sirJjDKgcAAAAAABysobrjS5JGR0d3JYxM09To6Kj//0wmo3w+r3v37sk0TTmOo6WlpV6H6kskEiqXy5qcnJT04o6vO3fu7Gviq5V+658gwop5ENsOAAAAAAAaG4rEl2VZqlQqOnLkiEZGRlQsFmvuZioWixoZGVEkEpFlWXr69Klu377dNLFkGEbDO4y2trb2fAdTI97k6aVSKfSyOxWkf3opyLYIK+Z+azsAAAAAANibgX/U0bZtLS0t6bd+67dkGIZSqZTS6XTNGwrT6bRSqZQ/h1axWFSxWPTLWF1d1fr6uiqVitbW1hqWUygU9Nlnn+1LG06fPq1sNlvzJsGpqamuJlQ3DEPj4+Mql8uSXiRz1tbWOiqjXf/0UtBtETTmdv0TpJxMJtN2+4S1DgAAAAAA2AN3QCwvL7sTExMNf86ePevu7Oz46+bz+Zrl+Xy+pqz65cvLy3751etW15lOp/3/Ly8vu67rusVi0T116lRNWadOnXKLxeKu73vfqf+sUqm46XS6Jn7Xdd2dnR03nU67lUql476qjmt+ft4vo1EfVi/vpH/CaHsn2m2LoNu0Vf8ELSedTte0tZGw1gEAAAAAAN37iuu67kEn3w4z27Z14cIFLS4u1jyeWSgUlM1mdeXKFf9ONQAAAAAAAARH4qsPeMmvx48f+5+dOXOGpBcAAAAAAMAekPgCAAAAAADAUBr4ye0BAAAAAACARkh8AQAAAAAAYCiR+AIAAAAAAMBQIvEFAAAAAACAoUTiCwAAAAAAAEOJxBeachxHmUxGtm0fdCgAAAAAAAAdG6jEV6FQUCwW2/VTKBQOOrSGcrlcw3hjsZgymcxBh9eUZVmamprS5OSk8vn8QYfTkUwm4/fxwsKCHMepWV6/TXK5XMsypqamZFlWx+t4fVi/3RvVBwAAAAAA9sdXDzqATiQSCZVKJdm2rddff11vvfWW4vH4QYcly7JUqVR0/Pjxms9nZmYkSRsbG7py5YoMw5D0IoGXzWblOI7/WT+Jx+N68OCBbNvW5cuXDzqcQBzH0ZtvvqmTJ0/6Y+TChQtaXV31t0Mul9PW1pZKpZKkF9vt/Pnzkn6zrTKZjCYmJvx1crmc3njjDd2+fVumaQZeR5J+8pOf7BoTAAAAAACgdwbqjq9+9ejRo113FrWSSCT0F3/xF9re3t7HqA6XJ0+eaHx83E9gmaapu3fv+v93HEcbGxtKJpP+d+LxuObm5rS1tVVTVvX/f/SjHykajapYLHa8DgAAAAAAOFgkvvbItm1ls9mO1v/kk090/PjxvrhbrV94jyB289iq4zjKZrOamJhou+76+nrL5ZcuXdKlS5dqPvv617+usbGxjtbZ2dnpKBkKAAAAAADCN1SJL28OsFwuVzMfWPVcT16CJZfL1cz3VD3nVvU6Hm9OJy8x4ziOFhYWdOLECT1+/FipVEqxWEzT09MtJ4O3bbsmIWLbtqanp/25op48eaKFhYVdZVWvVz9flBfLwsKC3nnnHb89Xju8coK0vRP181g1mr+q0bxszZJbkUikJnkUlOM4KpfLikajNXNvVbfLMAxdu3ZtV8Jqa2ur5i6wequrq/ra177WMknZaB3vEdbqbcb8XgAAAAAA9NZQJb4SiYTS6bTW1ta0vr6uUqmkzc1NSS8ehZNezOXkrSPJX+fZs2d+osRbp9qlS5c0Ozvr/99LpGxuburMmTPKZrMqlUq6e/duzTxPkvTP//zPmpycVCwW0/e//319+eWX/jLvkbzZ2VnNzc3p+PHjevfdd/XXf/3XNWXdunVLqVRKpVJJpVJJDx8+1EcffSTLsmQYhi5evKif//zn+pM/+RM9fPjQn5R+c3NTf/AHfyDbtgO1PSjLsrS0tKR79+755WxsbNQkdyzL0gcffKDNzU0/7mw2q3K5vKu8mZkZPXjwoKu74Gzb1q9+9Sv9wz/8g5LJZE27WiWbLMvSl19+2XAeLi8xuLW1tStZFmQdx3GUTqd1+/Ztf3tls9m+fREDAAAAAADDaKgSX56jR4/6iQjDMHTy5MldyZajR4/68z95iaOnT5+2vFurW2fOnPGTP80ei3z11Vf10Ucf6cmTJ7p165Z+9KMf1Sy/dOmSH68XcyQSqVknmUz6SZxoNKrTp09Lkr744gvt7Oz464XR9pWVFc3OzvqJOcMwlEqltLGx0fIRv0QiUdOOMP3whz9UIpEIFI9t21pZWdFbb73V8AUDMzMzKpVKSiaTTd/s2GqdRCJRk7g0TVOpVKrto5YAAAAAACA8Q5n4CjLXU/06XoJiPxJf1Y4cOaLf/u3f3vW5aZqanZ3VX/7lX+rcuXO77hqTah8tnJyc7DqJste2O46jZ8+e+Y93ej+pVErlctlPNMXjcR07dkyTk5NNk0dhikajNf8fGxvTr3/9612JL+9tla+++mrbt2omEgnNzc1pZWVlT+t48T179oy5vwAAAAAA6JGvHnQA/cK2bT1//nzf6zFNUy+//HLT5d/85je1srKy69G5TCajfD6ve/fuyTRNOY6jpaWlUGLqtu3ZbNa/w6qZmZkZzczMyLZtXbhwQZJ0+/bthom9bpmmqW984xuB1vWSXu+++27gGKLRqH/nWLNEWfU6kvTmm29qfHy86WOSAAAAAABg/w3lHV/d8B4FDDMh04plWf68Y97/Hz58qJ/+9KeSVDMXlGVZevr0aegJI0+nbTcMQ+Pj4w3n6mo2h5U3l9ni4qJu3brVfbBNyv7e97636w64nZ0djYyM+MmqZkmvtbU1OY7jvySgfr6z6nYGXadcLu+aNL9cLmt8fLztXWYAAAAAACAchzbxdf36df/RO9u2lU6nlUql/IRI/R08uVxON2/e3FVOfRLIsix/8vhmbNvWjRs39Du/8zuSXiRK/uu//kt/8Rd/IenFfF/ZbLbm0cNisahisej/f3V1Vevr66pUKm3r67TtQZw7d07Xr1+vSXTVTyTvvV2zWrlcbvgoqjdRfLeTv587d04ffPBBzZsus9msUqmUn2haXV3dlfSyLEtbW1s1yajq+CzL0vXr12vKabeON59XdTLMsixls1mdO3euq/YBAAAAAIAuuAMkn8+7ExMTu37y+bzruq67vLzsf7a8vNzyszt37rjz8/O7lnkqlcqu5el0uuG6xWLRPXXqlDsxMeHOz8+7lUplV931P9561W3K5/O76vXaVt/25eVlv/z/+I//8L9THef8/Lx7584dd2Jiwj179qy7s7MTqO3t+rlRu4OWU90/1ZaXl91Tp065xWKxozHRKp7qeHd2dtyzZ882bFd13PX93yimIOt4bWrVfwAAAAAAYH99xXVd96CTb73m3RW0X28X7GeHue0AAAAAAOBwOXST2+dyOS0uLkqSNjY2dOXKlUMz59JhbjsAAAAAADh8DuUdXwAAAAAAABh+h3ZyewAAAAAAAAw3El8AAAAAAAAYSiS+AAAAAAAAMJRIfAEAAAAAAGAokfgCAAAAAADAUCLxBQAAAAAAgKFE4gt9x7ZtffLJJwcdRluO4yiTyci27Z7WG1b/NCvHsixNT0/Lsqw91wEAAAAAwEEauMRXJpNRLBZTLBbT1NRUw1/Oc7mcv04sFlMul2ta3traWtNf8Dutq9k69WW2iqefFAoFxWIxFQqFntTnOI4WFhZ04sQJff755z2psxuWZWlqakqTk5PK5/M9qzes/mlXzs7Ojn71q1/tJVQAAAAAAPrCQCW+MpmMJiYmVCqVVCqVNDc3pzfeeKPmjptcLqetrS1/nfv37+v69es1ySbbtjU9Pa1YLKYrV67sqa6NjQ1tbm6qVCrpzp07euONN5omvwqFgm7evLmnPrAsS0+ePNlTGUGNjY0pEon0pC5JMgxD165d0+zsbNdl9KJ/4vG4Hjx4oIcPHyoaje5rXdXC6J8g5YyNjekb3/jGnuoAAAAAAKAfDFTiS5K2trb8f//oRz9SNBpVsViU9OJOlo2NDSWTSX+deDyuubm5mu+Zpqm7d+/q4cOHOnLkSFd12batjz76SBcvXpRhGH5d3/ve97SysrKrLMdxlM1mu2z1bzx69EiO4+y5nCC8BE8ikehJfZ6JiYmuv9vL/jkoe+mf/SgHAAAAAIB+NVCJr0uXLunSpUs1n33961/X2NhYzWfr6+v7Xpd355dpmjXrJJNJPXv2bFfyZXV1Vd/5znd05syZrmOybTuU5Nmwon/CYZqmotHorrENAAAAAMCgGajEV73V1VV97WtfUzwel/SbR7jqE1ZbW1s1d4GFUVcr5XK5JvFlWZY+/fTTrpNe1XMyPX78WKlUSrFYTNPT034CzpuPKxaLKZPJSPrNHGXV61U/5tlsDjRvDqv673q8unK5XE29CwsLXd1tVV9GpVKpWd4u5iD9E7TtYapuV6O50oLG065/pNpttpdypBf70Xe+8x3/TkYAAAAAAAbVQCa+vAnlt7a2diW56lmWpS+//FLHjx8PtS7vbpj6pFD93WaO42hlZUV/9Vd/1XUiwUvobW5u6syZM8pmsyqVSrp7964fRyKRUKlU8u94ymQySiaTun//fk2ct27dUiqV8ucue/jwoT766KOaecnazWGVSCSUTqe1tram9fV1lUolbW5uSlLH82sVCgW9/vrrun//vkqlki5evKjbt2/XrNMu5iD9E7TtYalv18OHD5VOp2uSX0HiCdI/lmVpaWlJ9+7d87fFxsZGTfIrSDkAAAAAAAybgUx8zczMqFQqKZlMtnyTom3bWllZ0VtvvdV1TJsSQwAAIABJREFU0qlZXaZp6qWXXtKNGzf8u5wa3WWzurqqZDLZ08fGbt68qWQyqUQioXg8rrt37/p3ql26dEkzMzP+uoZhdD2B/dGjR/1koGEYOnnypMrlckdlrK+va25uzo/Pm5OtWlgxh9n2Vrz53K5eveq3yzRNLS4uKpvN+uMlSDxB+mdlZUWzs7P+GDMMQ6lUShsbG35dQcoBAAAAAGDYDGTiy5NIJDQ3N9dwMnnbtnX58mW9+uqroTyy1aiu1157TZI0OTmpWCwm6cWE4dFoVIZhyLZtOY7T88nhZ2dnW9ZZ/Vjc5ORk13Oi7XVydNu2lc/nA70ZMayYwyqnle3tbZXL5V1zz42NjalcLmt7eztQPEH6x3EcPXv2zH+80/tJpVL+I7ed9DMAAAAAAMPkqwcdwF5Fo1H/zhYvweUlvd59991Q77Sqr8t7xO7atWv+OplMRidPnpRhGHry5In+5m/+Rn/zN39TU84///M/+3f/9DoplslklM/nde/ePZmmKcdxtLS01NMYOhVWzL1s++jo6K6xZ5qmRkdH9yWeVmOp/nHcdgzD0J//+Z93FQcAAAAAAP1kYO748iYw9yZu99Q/Wtcs6bW2thZ44vWgddWzbVtPnz7Vd7/7XUm/mXfL+/HmoEqn0yqVSj1PelmWpadPn+r27dt98cY+wzAa3oW0tbXl/zusmHvZ9kgkopGRERWLxZrPi8WiRkZGFIlEAsUTpH8Mw9D4+HjDsenNJxakHAAAAAAAhtHAJL481Y/XWZal69evK5VK+Xd7ra6u7kp6WZalra2tXY882ratYrGonZ2drurK5XL+mwMdx9Hly5f10ksvBXrzYzfqkxyWZWltba2jMorFYk1CZnV1Vevr66pUKh2XtVfeXFTpdLrm7ZSfffZZVzG3659etb1Ru2zbVjqdrhk/7eIJ2j/nzp3T9evXaybOr55vLmg51d9t9BZKAAAAAAAGjjtAKpWKOz8/705MTLgTExPuqVOn3GKx6C/f2dlxz5496y+v/lleXm65Xn1Z7epyXdctFovuqVOnGtZRb3l5uWV9QVXXOT8/71YqlYbl1y/35PP5Xf3ifTefzzdsV3281XV5bW70WVDV302n0/7/vXKCxNyufzotp5X6cryf+jLq12u3vFk87fqnvt3NtkGQcqrX66RPAAAAAADoR19xXdc96OQbAAAAAAAAELaBe9QRAAAAAAAACILEFwAAAAAAAIYSiS8AAAAAAAAMJRJfAAAAAAAAGEokvgAAAAAAADCUSHwBAAAAAABgKJH4AgAAAAAAwFAi8QUAAAAAAIChROILAAAAAAAAQ4nEFwAAAAAAAIbS0Ca+LMvS9PS0LMuiLuqiLuoCAAAAABxCQ5v4Mk1To6Oj1EVd1EVdAAAAAIBD6qsHHUBQuVxOi4uLTZdns1lJUiqVUjab1ZEjRzQyMiLTNFUoFPzPy+Vy23KCrENd1EVd/V9XIpFouhwAAAAAMPy+4rque9BBhMlLkP34xz/WN7/5Tf3yl7/U+++/r3Q6rZmZGeqiLuqiLgAAAADAITF0iS9P9Z0h+33XB3VRF3UNR10AAAAAgOEydHN85XI5xWIxffDBB7px44bW19cVi8WUy+Woi7qoi7oAAAAAAIfI0M3xtbi46M8LdOvWLb322mtKJpNKpVKKRqOhzkFEXdRFXf1dF3eIAQAAAMDhNrSPOlqWpaWlJV29elWmaVIXdVEXdQEAAAAADpmhe9Sx2vPnz2XbNnVRF3VRFwAAAADgEBraO74AAAAAAABwuA31HV8AAAAAAAA4vEh8AQAAAAAAYCiR+AIAAAAAAMBQIvEFAAAAAACAoUTiCwAAAAAAAEOJxBcAAAAAAACGEokvAAAAAAAADCUSXwAAAAAAABhKJL4AAAAAAAAwlEh8AQAAAAAAYCiR+AIAAAAAAMBQGtrEl2VZmp6elmVZ1EVd1EVdAAAAAIBDaGgTX6ZpanR0lLqoi7qoCwAAAABwSH31oAMIKpfLaXFxsenybDYrSUqlUspmszpy5IhGRkZkmqYKhYL/eblcbltOkHWoi7qoq//rSiQSTZcDAAAAAIbfV1zXdQ86iDB5CbIf//jH+uY3v6lf/vKXev/995VOpzUzM0Nd1EVd1AUAAAAAOCSGLvHlqb4zZL/v+qAu6qKu4agLAAAAADBchm6Or1wup1gspg8++EA3btzQ+vq6YrGYcrkcdVEXdVEXAAAAAOAQGbo5vhYXF/15gW7duqXXXntNyWRSqVRK0Wg01DmIqIu6qKu/6+IOMQAAAAA43Ib2UUfLsrS0tKSrV6/KNE3qoi7qoi4AAAAAwCEzdI86Vnv+/Lls26Yu6qIu6gIAAAAAHEJDe8cXAAAAAAAADrehvuMLAAAAAAAAhxeJLwAAAAAAAAwlEl8AAAAAAAAYSiS+AAAAAAAAMJRIfAEAAAAAAGAokfgCAAAAAADAUCLxBQAAAAAAgKFE4gsAAAAAAABDicQXAAAAAAAAhhKJLwAAAAAAAAwlEl8dsG1bn3zyyUGH0TOO4yiTyci27dDKPGx9CAAAAAAADs7AJL4KhYJisZhisZimp6dDTca04ziOFhYWdOLECX3++edNYysUCj2LaT9ZlqWpqSlNTk4qn8+HUma7PgQAAAAAAAjbVw86gKASiYSy2ayy2ayuXLkiwzB6VrdhGLp27ZrGx8cbLh8bG1MkEulZPPstHo/rwYMHsm1bly9fDqXMdn0YhGVZqlQqOn78eCgxAQAAAACA4TYwia9+MDEx0fBzL1GE9pr1YRCPHj1SNBoNMRoAAAAAADDMBuZRRxxutm0rm80edBgAAAAAAGCADGXiq3o+sEZzb9m2renp6Zp1crlcy3IWFhZUqVRqlntzYTWbd8z7fi6X21WW4zg16+ZyOX/51NSU3nnnnaZxtWtzJpPZ9ZnXB0HbHpZ2fdgunuq5wR4/fqxUKtWwv3vdLgAAAAAA0P+GLvFVKBT0+uuv6/79+yqVSnr48KHS6XRN8uvWrVtKpVIqlUr+Oh999JEsy2pazsWLF3X79u2aurxHHB8+fNjwEbxEIqF0Oq21tTWtr6+rVCppc3NTkvTkyZOaujY2NrS5ualSqaQ7d+5oe3tbDx8+1MzMTKB2e3OgnTlzRq+99pr/2Y0bN3T//n0lEonAbQ9LkD5sF483N9jm5qbOnDmjbDarUqmku3fvyjTNwOUAAAAAAIDDZ6jm+HIcR9lsVlevXlU8HpckmaapxcVFZbNZHT9+XIZh6NKlSzXfMwxj1+T06+vrmpub88uJx+Oam5vrKq6jR4/6dRqGoZMnT6pcLvvJqHK5rJMnT/oT9kciEUUiEdm2XZPcaef48eP64IMPtL29rXg8Lsdx9H//9396+eWX/XWCtD0sQfowrHh62S4AAAAAADAYhuqOr+3tbZXLZY2NjdV8PjY2pnK5rO3tbf+z6scUJycntb6+7i+zbVv5fD60idTbTegejUa1sbHhP/64vb2t7e3tjpJe0otkz7Fjx7SysiLpxV1lR48e3fUGzFZtD0snfRhWPL1oFwAAAAAAGBxDdceXJI2Oju5KGJmmqdHRUf//mUxG+Xxe9+7dk2machxHS0tL/3979xfa1pnnf/wzMDcqiSFyu/yCpwi5znaDp2kJAZVOAh4IGSgTkxDwIPai2ynFFxs3GWiJp8x0aC4SGXIRJhmGEEKaix1hgTebuDUhlNZsFmODJ4zdMW1WWhlBTJbN6ASa4HN5fhfhnNF/PbKO9efo/QJDIh2d5/9zpK+e86jVWfXEYjHlcjkNDw9Ler7i6/r16w0HviRp//79SiaTWl1d1fz8vN5///2i5zut7H7lp9PKBQAAAAAA2i8QK74ymYxWV1c1MDCgvr4+pdPpoufT6bT6+vo0MDCgTCajBw8e6Nq1a1UDS6FQqOJKpfX19W3Jv7sJu7s/1b1797zbAxs1MDCgSCSiY8eOKRqNFpXRpOx+MalDv/LTynIBAAAAAIDu0fWBL8uydO7cOb3wwgsKhUKKx+NKJBLeL/5ZlqVEIqF4PO7d8pdOp4uCY7Ozs5qfn9fm5qbm5uYqnmdpaUnffvvttpTh8OHDSiaTRb9IeOjQoS1tzO7mfWBgQPv37y97vl7Z/WJah6b5CYVC2r17t3K5nKTnwa7C503OMzU1Vbde/ToGAAAAAAC0X9cEvlKplOLxuG7fvq3h4WEvQHTgwAE9efLEW+kTi8U0OTmpAwcOeM9PTk56G8kPDQ3pwoULisfj3jkkaWJiQseOHfP2B4vFYorH49555ufn9fbbb2tyctJboeXuKXXgwAHdvn1bBw4cKAqIpFIpTU5OFr2m9DHbtnX16lVdu3bNW/GVzWZ169YtzczMePt+NWLPnj36+c9/Xra5u2nZl5aWvLpzyzU4OFj0y5gm6tWhaX5cJ06c0KVLlzQ4OKjLly97m/Y3eh4AAAAAANAbfuA4jtPuTPQyy7L03nvvFQXnpOfBp2QyqfPnz5dtTg8AAAAAAID6CHx1ADf4tbKy4j02OjpK0AsAAAAAAKAJBL4AAAAAAAAQSF2zxxcAAAAAAADQCAJfAAAAAAAACCQCXwAAAAAAAAgkAl8AAAAAAAAIJAJfAAAAAAAACCQCXwAAAAAAAAgkAl+oyrZtTU1NybKsdmcFAAAAAACgYV0V+FpaWtLg4GDZ39LSUruzVlEqlaqY38HBQU1NTbU7e1VlMhkdOnRIw8PDWlxcbHd2jE1NTXn1e+jQIWUymarHzs3NVX2+kfMAAAAAAIDO1VWBr1gspmw2q+XlZY2MjOju3bvKZrOKxWJtzVcmk9Hq6mrZ42NjY0okEhodHdXa2pqy2ayy2aySyaQePXok27bbkNv6hoaGdO/ePS0vLysSibQ7O0ampqYUjUa9Op6YmNBHH31UtFrNsiwdP35cg4ODOn/+/JbPAwAAAAAAukNXBb461f379xsKYsViMf3yl7/UxsbGNuaq96yvr3v/Pnr0qCKRiNLptPdYOBzWzZs3tby8rD179mz5PAAAAAAAoDsQ+GqSZVlKJpMNHf/1119r3759Ghoa2sacdRf3ttCt3rZ65swZnTlzpuixnTt3qr+/vy3nAQAAAAAA7ReowJe7B1gqlSraD+z06dPeiiw3wJJKpYr24Crcc6vwGJe775MbmLFtW6dPn9aBAwe0srKieDyuwcFBHT9+vOZtcZZlFa0OK7z97tChQ1pdXdXp06fLzlV4nPvn5s/Ny+nTp/Xb3/7WK49bDvc8JmVvhLsXWGl+KrWJyZ5sAwMDvgWYZmdntWPHjqaDi36dBwAAAAAAtF6gAl+xWEyJREJzc3Oan59XNpvV2tqaJHl7cLn7bs3NzUmSd8yjR4+8AJB7TKEzZ85ofHzc+38oFNLFixe1tram0dFRJZNJZbNZ3bx5U+FwuOi1t2/f1vDwsAYHB3XkyBE9e/bMe869/W58fFwTExPat2+fPvnkE/3ud78rOtfVq1cVj8e9vaeWl5d1584dZTIZhUIhnTx5Un/+85/185//XMvLy96m9Gtra/rxj38sy7KMym4qk8no3LlzunXrlneehYWFouBXJpPR559/Xra/WS6XKzvf2NiY7t2713SAyQ3ora+vl63casd5AAAAAABA+wQq8OXau3evF6wIhUJ66623yoIte/fu1djYmHfMyZMn9eDBg23ZxLxwc/tqt0W+//77unPnjlZXV3X16lUdPXq06PkzZ854+XXzPDAwUHTMyMiI9u3bJ0mKRCI6fPiwJOnp06fK5/PecX6UfWZmRuPj415gLhQKKR6Pa2FhoeZ+Z7FYrKgcfhsbG1M2m9XIyEhTv8jo13kAAAAAAED7BDLwFY1GGz7GDeBs96/37dmzRy+99FLZ4+FwWOPj4/rXf/1XnThxomzVmFR8a+Hw8LDm5+e3lIdmy27bth49euTd3un+xeNx5XI5L/A1NDSk1157TcPDwy0PHsViMU1MTGhmZqYjzgMAAAAAAFrvh+3OQKewLEtPnjzZ9nTC4bB++tOfVn3+lVde0czMTNntdVNTU1pcXNStW7cUDodl27bOnTvnS562WvZkMqlYLFbzmLGxMY2NjcmyLL333nuSpGvXrlUM7PktEol4K9BCoVDbzwMAAAAAAForkCu+tsK9FbAVARnp+eotd98x9//Ly8v67LPPJKloA/hMJqMHDx5sW8Co0bKHQiHt3r274l5d1Taud/cym5yc1NWrV7ee2Qrczf1L9ymrlL9WnAcAAAAAAHSGng18Xbp0ybv1zrIsJRIJxeNxL/hTuMpHer7Z+ZUrV8rOUxoEymQy3ubx1ViWpcuXL+tHP/qRpOcBl//6r//SL3/5S0nP9/tKJpNFtx6m02ml02nv/7Ozs5qfn9fm5mbd9Botu4kTJ07o0qVLRYGu0l91dH9ds1Aul6t4K6q7mXy1wJmJwvNmMhldunRJ8Xi8bJWWZVlKp9NF+55t5TwAAAAAAKCz/cBxHKfdmTC1tLSkeDxe9rh7y10qldLk5KQkKZFIaGxsrOpjm5ub+stf/qLbt28XPeeybVu//vWvi55fX1/XlStXyo7NZDJ69913tbGxodHRUZ0/f16hUKgo7VLucaurq16Zksmk9u3bV5SuW7bSsru/Ojk5OanPPvtM//7v/67bt28X5XN0dFRvvPGGzp49q9dff13Xrl3Tl19+Wbfs9eq5UrlNz1NYP4VSqZQuXbqk69evb+mXHUvba2BgoOxc7u2WKysr3mOlx5mcBwAAAAAAdIeuCnz5xV2ZtJ2/LtipernsAAAAAACgt/Tc5vaFq7AWFhYqrj4Kql4uOwAAAAAA6D09ueILAAAAAAAAwdezm9sDAAAAAAAg2Ah8AQAAAAAAIJAIfAEAAAAAACCQCHwBAAAAAAAgkAh8dbm5uTllMpl2ZwMAAAAAAKDjEPhqgm3bWl1dbVv6lmXp8ePHGhoaalseAAAAAAAAOlXXBL5SqZQGBwcr/k1NTbUlP8PDw/ruu+98PW8jK7gePnyon/zkJ2X5KqybVCrla/4AAAAAAAC6xQ/bnQFTY2NjkqSFhQWdP39eoVBIkrS0tKRkMinbtr3HWpkfP1iWpffee08rKysaGBjQ9evX677Gtm09fPhQb7/9tvdYKpXS+vq6stmsJCmTyejdd9/1Pb8AAAAAAADdoGtWfFUTi8X0y1/+UhsbG+3OypaFw2HdvHlTy8vL2rNnj9FrVldX1d/f7/3ftm0tLCxoZGTEe2xoaEgTExNaX1/3Pc8AAAAAAACdrqsDX5Zl6euvv9a+fft6ap8r27b17bffat++fWXPzc/PtyFHAAAAAAAAnafrA1+2bXv/d/e3SqVSRXtdVdoDbGlpqWgvrKWlpbJjMpmMDh06VHe/rMJznT59uihP22F1dVV79+4turUzFArp4sWLOnPmTNGx6+vrRavAAAAAAAAAekXXBb5u376t4eFhDQ4O6siRI3r27Jn33NjYmBKJhObm5iRJ2WxWa2trevToUVHwa2lpSR9++KHu3r2rbDar5eVlJRKJouCXuz/WhQsXvGPu3LlTtvH83Nyc5ufnvbQkbesvPdZa7VUqk8no2bNnRscCAAAAAAAETdcFvkZHR7W2tqZsNqtkMlnxmL1793qbuYdCIZ08eVIPHjzwVoglk0lduHDBuz0yHA5rcnLS2yRfkmZmZjQxMaFYLOad98mTJ8rn82VpuausQqGQ3nrrLeVyOd/L7aq02qsSy7I0MzOjjz/+uKWb/gMAAAAAAHSKrgt8FdqzZ49eeumlssej0WjR/8PhsKTnwaCNjQ3lcrmijeElqb+/X7lcThsbG7JtW48ePVIkEik6x82bN4sCYZXS2k6mq70sy9LZs2f1/vvvE/QCAAAAAAA9q6sDX+FwWD/96U/rHmdZlp48eeL9f9euXV4wrPBcu3btkvQ8wLSdq7a2ymS1lxv0+uSTT8rKCAAAAAAA0Eu6OvDlymQyNffVcm9PDIfDGhgYUF9fn9LpdNEx6XRafX19GhgYUCgUUiQSqRj8mpub2/bN6ysxWe1VLejVrjwDAAAAAAC0U9cHvizL0uXLl/WjH/3Ie+zSpUveJvSWZSmRSCgejyscDisUCikejyuRSMiyrLJjQqGQd0zheaTnvxrZ39+/bbcPWpaldDpdto+YZLbaa3Z2tizolclktL6+zi2PAAAAAACg5/yw3RkwlUqlNDk5Ken5LzsWGh0dLQrsvPfee7p8+bJ3XCKR8Da7l6RYLKbJyUkdOHDAeyyZTBbt3xWLxXThwgUdOXLEeyyRSHjHFOZHev6LkpUeM2FZlt577z2trKxIkuLxuAYGBnT9+nUNDQ15q71+8Ytf1DzHf/zHf+jTTz8tey6RSBjlAwAAAAAAIEh+4DiO0+5M+CmVSkkyDzp1g6WlJUkq21gfAAAAAAAA1QUq8FW44mp0dFTnz5/nFj8AAAAAAIAeFajAFwAAAAAAAODq+s3tAQAAAAAAgEoIfAEAAAAAACCQCHwBAAAAAAAgkAh8AQAAAAAAIJAIfAEAAAAAACCQCHwBAAAAAAAgkAh8dRDbtjU1NSXLsnw7p2VZ+vrrr30733bZjrKb8Kt+qp0nk8no+PHjymQyTacBAAAAAAAa03WBr6mpKQ0ODmpwcFCHDh2qGVCYm5ur+nwj59lumUxGhw4d0vDwsBYXF305p23bOn36tA4cOKDHjx/7cs7tsB1lN+FX/dQ7Tz6f19/+9rdmsgoAAAAAALaoqwJfU1NTikajymazymazmpiY0EcffVS0SsiyLB0/flyDg4M6f/78ls/TSkNDQ7p3756Wl5cViUR8OWcoFNLFixc1Pj6+5XNkMhmtrq76kp9qtqPsJvyoH5Pz9Pf368UXX2wqDQAAAAAAsDVdFfiSpPX1de/fR48eVSQSUTqd9h4Lh8O6efOmlpeXtWfPni2fJyii0eiWX3v//n3Ztu1jbjpPM/WzHecBAAAAAAD++WG7M9CIM2fOlD22c+dO9ff3t+U8QWZZlpLJpCYnJ9udla4WDocViUQUDofbnRUAAAAAAHpO1634KjQ7O6sdO3ZoaGio5edZWlry9gibmpoqe2xpaUlS8a2X7l8qlWoqv6b5On36tDY3N4uer5efwj2rVlZWFI/HNTg4qOPHj1e9pbTV5Sqs30bzU69+pL/vO9bseaTnt0K+8cYbCoVCWyw5AAAAAADYqq4MfKVSKQ0ODmp9fb3i6q1WnCcWiymZTGp0dFQffPCB99jly5d19+5dxWIxSdLVq1cVj8e9/cSWl5d1586dbdlMf2lpSR9++KHu3r2rbDarkydP6tq1a0XH1MuPu2fV2tqaRkdHlUwmlc1mdfPmzaJVS+0s1/LyshKJRFHwyyQ/JvWTyWR07tw53bp1S9lsVmtra1pYWCgKfpmcBwAAAAAAtF9XBr7GxsaUzWY1MjLS1C8yNnueffv2aefOndrY2JD0fLXU//3f/2lgYMA75syZMxobG/P+HwqFip730/z8vCYmJryVa0NDQ5qYmCg6xq/8tKpctm0rmUzqwoULXrnC4bAmJyeVTCa9PchM8mNSPzMzMxofH/eCfKFQSPF4XAsLC15aJucBAAAAAADt15WBL1csFtPExIRmZmbacp5QKKTXXnvNe93q6qr27t1bdltb4a1zw8PDmp+fbyq/lViWpcXFRaNfRvQrP60o18bGhnK5XNn+a/39/crlcl7QsV5+TOrHtm09evTIu73T/YvH48rlcrJtu6F6BgAAAAAA7dVVm9tXEolEvNU4zeyjtNXz7N+/X8lkUqurq5qfn9f7779f9PzU1JQWFxd169YthcNh2batc+fObTmfzfIrP60s165du8o2hw+Hw9q1a9e25CeZTHq3qpYq3OfMRCgU0r/8y79sKR8AAAAAAKA5XbPiy9103d1I3pXL5dpyHtfAwIAikYiOHTumaDRaFKDJZDJ68OCBrl27tu2/6hcKhSquQlpfX/c9P60s18DAgPr6+pROp4seT6fT6uvr08DAgFF+TOonFApp9+7dFfuCu5+YyXkAAAAAAEBn6JrAlysajXr/zmQyunTpkuLxeNkqLcuylE6nlc/nmzpPPe4eUAMDA9q/f3/Z8+l0uihoMzs7q/n5eW1ubmpubq6htEzykUgkvFVJS0tL+vbbb7eUn9IgUCaTKXq+neWyLEuJRKKoverlx7R+Tpw4oUuXLhVtnF+4sb3peQpfW+lXKAEAAAAAQAs4XWRzc9M5deqUE41GnWg06hw8eNBJp9NFx+TzeefYsWPeMZWOMzlPI/L5vJNIJJzNzc2y5xYXF4vyMj097UxPTzvRaNRZXFyseIz75z7fCPfc0WjUSSQS3v+np6eN8+NKp9POwYMHnWg06pw6daqofI2cpxbTspceV+/5avmpVz+l5S59rpHzFB63lbYEAAAAAADN+YHjOE67g28AAAAAAACA37ruVkcAAAAAAADABIEvAAAAAAAABBKBLwAAAAAAAAQSgS8AAAAAAAAEEoEvAAAAAAAABBKBLwAAAAAAAAQSgS8AAAAAAAAEEoEvAAAAAAAABBKBLwAAAAAAAAQSgS8AAAAAAAAEUmADX5lMRsePH1cmkyEt0iIt0gIAAAAA9KDABr7C4bB27dpFWqRFWqQFAAAAAOhRP2x3BkylUilNTk5WfT6ZTEqS4vG4ksmk9uzZo76+PoXDYS0tLXmP53K5uucxOYa0SIu0Oj+tWCxW9XkAAAAAQPD9wHEcp92Z8JMbIPvnf/5nvfLKK/qf//kf/du//ZsSiYTGxsZIi7RIi7QAAAAAAD0icIEvV+HKkO1e9UFapEVawUgLAAAAABAsgdvjK5VKaXBwUJ9//rkuX76s+fl5DQ4OKpVKkRZpkRZpAQAAAAB6SOD2+JqcnPT2Bbp69ao++OADjYyMKB6PKxKJ+LoHEWmRFml1dlqsEAMAAAC6ZYxiAAAgAElEQVSA3hbYWx0zmYzOnTunCxcuKBwOkxZpkRZpAQAAAAB6TOBudSz05MkTWZZFWqRFWqQFAAAAAOhBgV3xBQAAAAAAgN4W6BVfAAAAAAAA6F0EvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL58YNu2PvvsM9m23e6s9DzaAgAAAAAAuAh8AT6Zm5tTJpNpdzY6RiqV0uDgoPc3NTXV7izBZ430edu2dfr06aI+kUqltiWtVui0/Pil08rVafkJKuq5N9HuAIBeQeAL8IFlWXr8+LGGhobanZWOsWPHDt29e1fZbFbZbFZnzpxpd5bgo0b7fCgU0sWLF73+kEwmty2t7VYtP7Zta2pqSpZltSlnxRrNz3aVy7Isff3111t6Xbva3bZtra6utjzddjCp5622YRDZtq25ubl2Z6Np7R5f3VqHfs3znXa9qKWX5kMAwdWzga9MJqNDhw5pcHBQx48fL7rwuCsTDh06VPRN2I0bN7riAoXm1Oob1Tx8+FA/+clPih6bmpryVraU9iVX6aqoWitgan0z22ha1Y4pPWcjK3IaZVLPW2mLVqf1hz/8oagul5aWWrbSzTQt97ilpSXf0q7U57dLK9MyUZoft+8MDw9rcXGxjTlrLj/NlKtaH0ulUjpw4IAeP37cWCEq5KdVUqmUhoeH9d1337UsTZM5vJ7S64n7V28+q1XP7vuham24HXNLJ3P7xjfffNPurDStWrtvd5t2ax36Nc932vWinnbMh52k8L1hvffrhfP46dOnfd92pfD8bvqWZen48eMNr6JvVuEq/qmpKS9vp0+f1tdff71tdWCq265Nle6KaGf9meq2epbTg/L5vHPs2DFnenracRzHWVxcdI4dO+bk83nHcRxnenramZ6edtLptPOb3/zG2dzcdPL5vPPVV19VPN/m5qZz/fp1Z3Nzs2VlQGXNtkW9vlEtzS+++KLosUQi4Z3DcZ73qdLzTE9PO4lEwvt/Op12Dh48WPQ6Nz/RaNQ5ePCgk06ny9I3TevUqVNevaTTaefYsWMVz+eWOxqNFp23UV988UXV85vU81baopVpbW5uOqdOnXIWFxe9xxYXF4va1D2m8DG/NJKW27cK81rpmJWVFaO0K/X5Ri0uLhr1Lz/S8lOt/OTzeefUqVMN99Ht0kh+mi1XrT7mXlMb0Yp2r9Xnt5LnrTKZw01cvny5bM5dXFysOe5N67k0jy6TucVEI/NPu5XOvd2oVrv71aa1dHMd+jXPd9r1opZWzoedxmRuct9/uXVU+p7SL6XpuGp9Rt1OpZ+TC/vzV1991da+3Yp5zC+V+stW3wf4yaTvd1M9O47j9OSKry+//FKRSERHjx6VJO3bt0+RSERffvmlJOnx48fav3+/BgYGtGPHDtm2rcXFRb388svtzDZaoF7fqGR1dVX9/f1lj6+vr3v/Pnr0qCKRiNLptKTnkf2FhQWNjIx4xwwNDWliYqLodeFwWDdv3tTy8rL27NlTNQ+10rIsS3fu3NHJkycVCoW8tN58803NzMyUncu27YZuQ9sKk3reSlu0Ki3btnXu3DmdPHlSsVjMe+zbb7/VBx984B0XCoV08uRJPXjwwNfVoo2mNTQ0pHv37nl5reT+/fvG3yxV6/PboZVpmei0/Pil2XKZ9LFW5sdEI31+u9Waw03Ytq1oNFp025o7T+zbt6/q60zrORqNVnzcr3bvpLboBbXa3e+xDATd6uqqdu/erbGxMUl/f+/u/j+owuGwnj59Ktu2FQqFtHPnTu/9p/tYu3TTPHb16lW9+eabRf1lbGxMhw8fbuudZibX5W6qZ6kHb3V0Aw5vvfWWNyBDoZDeeustLSwsVGxg97FO2V8G22OrfaPSB4szZ86U7Wm1c+fOsjea8/PzTee7XlrupBkOh4uOGRkZ0aNHj8rKNTs7qzfeeEOjo6NN560Sk3putC3cW3xKl9puR1pu0Oudd94p+5D5n//5n9rY2Cgr85MnT3wPfPmZlmVZxsFOkw/TfmllWiY6LT9+6bRytSI/jfT57WZ6vaglFArp7bffLnpsdXVVe/furfrho1PavZPaohd0SrsDnaLae0hJyufzNT/8u18WV/tyoJG0uk1psOvp06dF9dXOwFcrNdOmmUxGn3/+edFCCNfPfvYzbW5u+pHFhgX1utyTga9cLqdIJFL0eCQSUS6XK5rcbNvWo0ePtLKyEshv+FGskb7hqvfBwjU7O6sdO3Z4gRJ3o+/SDzvr6+sVJ79GlKZVS2m5MpmMvvnmm20Leklm9byVthgYGCgbp36nVS3oJT1v076+vrJVdPl8XpFIRAMDA3VqxpxpWvX2LSvcv2dlZUXxeLzunkC1+nzpnmPNvrmrlJb7BqNwLwt3b4nStGrlp/A5d2809zzVym863qspzU+luindT6R0z47C/Ty28uuYlTRTrkb2xivcg6rW3hX12r3wPIX72hXmxT1/4bFLS0sN9/nCNquU51pt6j6XSqXqnqdQI3N4NaarvUzG8unTp8vefJu2e60xuJX5pxKTviGZj516Y7DaOQvb1TSt0r03f/vb35Yda5KfRubeau1er039GoOmdViv7CZzeCNjsJF23271+o/JdXA7yt7MebZyza1ku/phpfeQ0t+DN4XtUViuwveQhXtw1drftVpafjKZE5ptr1AopB07dnjBrlwu571vLpxf6vVnP8dyvXmskXFhMj+7ttqm+XxeL774YsW7eoaGhrRv376Gxk6z7yFNr8vtqudqTK+5PRf4sixLf/vb32oe89JLL+n+/fuyLEs7d+7Us2fPtLm5WXciQ3cz6RuFTD5YuIN5fX297q8aZjIZPXv2bMvfwlZLy13pVTopla42s21bMzMz+tWvfrWt39KY1HOjbTE2NqZ79+6VfVD0M61aQS+pcjAzlUopkUjok08+8bVOTdNylyAvLy+XBfYKz7O2tqbR0VElk0lls1ndvHmzbIWgVLvPu99ara2tFf1yYy6X21IZq6U1NjamRCJR9NiZM2c0Pj7eUH5isVjRr0tOTU1pZGREd+/elVQ+XppdJbG0tKQPP/zQ+6XT5eVlJRKJojeimUxG7777ri5cuOAdc+fOnaKNzq9evap4PO6VqdIxjWi2XPX6mMv9BbdsNqu1tTVJzwM8pvlx2730PI8ePfKuy0NDQ7p7967Gx8e9cTA2Nqbf/e53Wl5eViwWa6jPz83NaX5+vijPhb9sVq9NY7GYl+da53E1cr2oZ3V1VS+88MKWVnuVluvkyZO6du1a0TEm7V5vDJq0RbUN+ws/yJn0Dcls7JiMwULhcFjxeFzJZFIXL1706tskraWlJS0sLHj1c/36dW1sbGh5edm75SWTyejcuXO6deuWV66FhYWywJjp3Fur3eu1qV9j0LQO65XdZA43HYMm9dxK9fqPyXWwkbKb9Plm67DRa24129EPq72HlJ6PmUQioWvXrnn1k0wmvXnefQ/5xz/+USMjI0X5qdR/aqXlF5M5wa/2ikajyuVysixLhw8f1vr6uizLKgoC1evPfo7levOY6XlM5mdXM21q8h7ZtC1M5rF6bWH6Hqkd9VyL6Xvjngt8mTh8+LCSyaSOHDmiV155RS+99JJu3bql5eVlSQrE8lQ0z2SVxNjYmLLZrEZGRmr+UpdlWZqZmdHHH3+85QBJtbTC4bBeffVVXb582YuyV7oYz87OamRkpGLAA9LGxob++te/Gh/vvgGrFkTyU6vSanRlUCwW2/IeF82urmokP1euXNHIyIhisZiGhoZ08+bNsjcwzeTHvRXiwoUL3nnD4bAmJyeVTCa9cTkzM6OJiYmiN+VPnjxRPp/3/n/mzJmiMoRCoaZWE25HPVeyd+9eL9+hUEjxeLzircT18lN6ntJ97UKhkKLRaNEeh1L5rd6meXYDUO7tz+6bVNM2rXeeQqbXi3ps29bnn3+u/fv3Vz2mVj3Pz89rYmLCK5e7/6QfGp0T3Dqp9lc4Vur1DZOxYzIGCxV+SCxkklYulyu6xX5gYEADAwNFAYCZmRmNj497/bfW2ClUrZ79GO9+j8FqddhI2evN4fXG4Fbrebv4Oc+blN2kz/tZhybXXJNyteJaEIvFit5buYHa0i+P3377ba8O291/KimdE/xqr0gkovX1df33f/+3otGonj17pnw+rxdeeMF7fSP9udmxbKreeUzm53aoVT8mber3e8h6WlXPpuXqucBXOBzWiy++WPeYmzdvKpvNKhKJ6IUXXtCePXsUDoe9yDaCx6RvuBpdJRGLxTQxMVFxM3nLsnT27Fm9//77vnz4rJSWuwn68PCwBgcHJT3/liYSiSgUCsmyLNm23ZLNCU3HoGlbtCqtoaEh/elPf9KNGzfqfiC1LEv/7//9v5ZsbNqqtOr1+aGhIb322msaHh5u6kO7SVomGsnP+Ph4zb7fbH42NjaUy+XKlsH39/crl8tpY2PDu7W+8Jsz91pUmrfCJebDw8Nb3iuwlXv9lO5/0t/fr++//77sVuJ6+Sk9T6UVrYcPH9Z3330nSUqn0/qnf/onX/JcyKRNTc5TSa3rhQk37WpvZmvVs2VZWlxcrLl6z5Sfc4IJk75Ra+w0Mgal5184JJNJHT58uGJ+6o3TSCRS9IFkY2NDGxsbXr7d/Li3mrh/8Xi86DZ803r2a7z7OQar1aFp2V315vBaY7DRtFrFr3nepOwmfd7POqzXXiZaeS0oFYlEyvbILZ0zK13jWqXenOBne/X392vHjh2SpNdff11Pnz5VLpcrCzCa9udmxnIj6p2n3vzsl0avtdXqp5E29WtuMdHKejYp1w8bPmuXC4VC3t49hR3HvT+79J5kSUVvbN3XInga6Rtb+da0cHC7r3ODXp988omvk2lpWu7S1YsXL3rHTE1NeVH21dVVffrpp/r000+LznP79m1vBYNfQTHTejZti1amFQqF9PHHH9e85TGoTFc4jo2NybIsvffee5Kka9euNdy3/VqF1En52bVrV1m64XBYu3btkvT3fULqmZqa0uLiom7duqVwOOzdgrsVrVrtZWor+bEsS0+ePCl6LBwO69mzZ8pkMsrn8/rpT3/qd1Yl1W/TZlS6Xpi6f/++nj59WvX5Vra7X2NwK0r7Rr2xYzoGpeffuieTSY2MjOjs2bM6f/58UX2ajNNYLKZcLqfh4WFJzwOV169fL6sbk+uvST1vV7tvdQzWq0PJrOx+aWVa9fg5z9fSSJ830c463I5rgW3b+vWvf63du3dXvf3cry9q/WYyJ/jRXuFwWP/7v/+rf/iHf1A4HNbOnTu1vr7e8HzYaUzn52YV/hBZ6bndfYgbSbNem3ZaW/hVz6bl6rkVX5V+ra3Sr7pJ0sOHD/Xyyy+3K6toMdO+Ue9bU3djwNL94ErfXFQLes3NzRl/Q2SaVinLsvTgwQPvVhj3/nH3z723O5FIlN1O0iyTem5knLY6LTf4VWvlVzgc1jvvvLOl+mlUK9JqdKWA+43x5OSkrl69uq1pdUN+BgYG1NfX591y4Uqn0+rr69PAwEBRkLaUOydkMhk9ePDAl8BBK1d7VZLP59XX12c8r9Y6j1R++8qBAwd048YNSdvzy1ImbWpiq3N4Levr6zXTq1XPbj9s5JwmmhmDW1XYN0zGjskYdLnfusdiMe3evbtovzrTcere4uded0v3iAmFQtq9e3fF/FTbcqNaPW/neN/qGKxVh1sp+1a1Mi0Tfs7z9TTS5+udp911uB3XAjcwWPqjU7lcTrt371YoFFI4HNabb75Ztrqk9BrnB7eeS7l3bVRSaU7ws71CoZCePn0qx3G8ze6j0WjRXn2t6s9+qjc/+2VgYECRSET3798ve25xcdH4PCZt2olt4Uc9N1Kungt8Sc+XvuZyOe8iu7q6qlwuV7TU2rZtPXz4UENDQwqHw0qn07IsS/Pz877cAoDOZNI3TL81LVzemclkdOnSJcXjce91s7OzZUGvTCZT9k2J9Pyilk6nq+4zUi+tVCrl/eqGbds6e/asXn311batWDKpZ5NjXLV+StjvtKS/B78uX75cMc1a+ZmamvL1th8/fhq79IKZyWS8jWMlsz7v/nJLoVwu1/CydJO0SpdGp1IpXblypW35qcfdZyGRSHgriS3LUiKR8Mape8ylS5eK+kYqlVJ/f7+XfjqdLgq2zM7Oan5+Xpubm0Vt1opyNSKZTJaVvTCwbJqfwvoprMPSNzvuB/x//Md/rHieen2+HpM2bUS9Odx03nBvd6imXj1XKtfS0pK+/fbbhsojmY/BZtvCVa9v1Bs7pmOw1AcffKCFhYWispqMU3c/2cLbUkrb+MSJE7p06VLRuUv36DSpZz/Hu19jsFClOjQpu19amZYJk/5jch2sZ6t9vhK/6tB0rvOzH1Z7H+Xu51W6KXwymdSJEye8x06cOKHPP//cK6+7B2Sla0Gz79mi0WjR9dS2bd24caOofCZzgl/t5c7f7mdjdxuVQn69b2klk/nZ1UybumNwcnKyrC0eP37cUIDKpE1N28Kv63I9jdRzLcZ9zOlR+XzeOXbsmBONRp1jx445+Xy+6Pl0Ou2srKx4/19cXHSi0ahz6tQpZ3Nzs+jYzc1N5/r162WPo/X8aItafcP0/Jubm86pU6ecaDTqRKNR5+DBg046na6YRunf9PR0zeNKz1UvLcd53p8PHjxYMY1S09PTNdMz9cUXX9R8Xb0xaHqMm+da+fQzrVKXL18uS7dWfhKJRN02aESttErbvVZ7Fh5bOM+Z9nl3jiz8qzRfFh5fWgdbHV/T09Nl9VovP6X9vFJ+myl7NBp1FhcXax5X+nylY0rrqNLzblnc89XLj5/lMuljX331lZPJZIrmssJymeZnenrauX79elnbV7K5uel88cUXNc9Xrc8X9g33/JUeq1RHhXVjeh6TOTyRSBjPxYlEoun3KoX5TCQS3v/dPJu0eyNzQrW2MGXSN0zGTrXjKj2XSCTK6qra/FOa1ubmppNIJMquM/l83kkkEkXlr3f9rlfPpu1u0qZ+jEHTOqxXdpM5vJGxvJV6rjaP12JyHpO+Wu862Mw8Vq2em6lDk/ZyHLO5zu9rQb33kKV5r9TmpWWv1i/qpWWiMD+VzmU69/rRXo7z/BrvzmUrKyt181Pan/0cy/XmMZPzNDI/u69vtk39aotG57Fq18HSc5Wm1456rsW0XD9wHMfxK2rXq2zb1vT0tH7xi190zF4pvWq726LwZ+pRWyqV0uTkpPf/8fHxqnsk9Br3p4i7oR/51efdvTJu377tPZZIJIo25e+08dVp+fFLp5XLND/uN5cmP+TQaWXsBEGuk0b6Ridw992ZnJwsao+lpSUlk8mK+11tlZ/tzhhEJ6AfYju1cn7uZe2oZwJfPiDw1TloC3Q627b1+9//Xu+//37H3GMPdLrCQPro6GjVN0RTU1O6cuUKgfYeYto3Oo37pn9lZcV7rJPzzxisrlJblnr99dc7am+dbkU/RCt02/zcrVpdzwS+AKBF3F8Z6bVfhAQAAACAdiHwBQAAAAAAgEDqyV91BAAAAAAAQPAR+AIAAAAAAEAgEfjygW3b+uyzz2Tbdruz0vNoCwAAAAAA4CLwBXSYubk5ZTKZdmejY6RSKQ0ODnp/U1NT7c4S0JWYWwAAQCexbVunT58ueq+fSqXanS0EEIEvoINYlqXHjx/zi38FduzYobt37yqbzSqbzfKz1MAWdMLcYtu2pqamZFlW2/IAc7QXmtHL/aeXy+4X6rB3hEIhXbx40Xufn0wm250lBFTPBr4ymYwOHTqkwcFBHT9+vGhidSPPhw4dKvp2/MaNG0zAPWZqaqritw6Fq5BK+0mlY0y/vXj48KF+8pOflOXBz7RqrfpoNK1qx5Seczu/uak1lhs5ppF0TOq60dU1f/jDH4qOb7Se66mWn0bLVYtJPW9lXGwnP+u5cPycPn267JZrk/ElSUtLSxocHNTS0tKW81Kq0tzSKm6/GB4e1uLiYlvysBV+zBulTK4p1cbFduSnkm5tr07jV3v5dY2j/2w/P8tO/+m9/uOnXr1+ATU5PSifzzvHjh1zpqenHcdxnMXFRefYsWNOPp93HMdxpqennenpaSedTju/+c1vnM3NTSefzztfffVVxfNtbm46169fdzY3N1tWBlTmZ1ssLi460WjU6yeu6elp59SpU14a6XTaOXbsmJNOp4uOSSQS3v/T6bRz8ODBsnOV5v2LL74oeiyRSBS9Znp6uqivmqbl9vloNOocPHiwKK+NplWv7IWq1WEjvvjii6rnrzeWTY8xkU6nnZWVlZrHmNRzqc3NTefUqVPO4uKi91ij9dxMfkzK1Uhateq5tFxu2ZvpH83wq55Ly1FaF45jNr5c7hgu7BOVjjFtt0pzSzvk83nn1KlTDY+9dvBr3ihkek2pNC62Iz/1dFN7+a3ZedGv9vLrGkf/aa1my07/6e3+06xuv34tLi627X0hgq0nV3x9+eWXikQiOnr0qCRp3759ikQi+vLLLyVJjx8/1v79+zUwMKAdO3bItm0tLi7q5Zdfbme20UK2bVdcamtZlu7cuaOTJ08qFApJkoaGhvTmm29qZmbGe+3CwoJGRka81w0NDWliYkLr6+tV01xdXVV/f3/Z44WvOXr0qCKRiNLpdENphcNh3bx5U8vLy9qzZ0/VPNRKy6TsharVoZ/qjWXTY/xiWs8u27Z17tw5nTx5UrFYTFLj9exnfppRr55t29Y333xTVK5QKKR4PK6FhYWW/yCFn/W8urqq3bt3a2xsTNLf6939v6vW+Co0NDSke/fueX2ikvv37xvXWbW5BdX5PW9Umw9Nx0Ur5zE0Nr4q8au9/LrG0X+6C/0HzeD6BVTWc4EvN1Dw1ltvFQ3St956q+qHL/cx9l3qHbOzs3rjjTc0Ojpa9Li7NDccDhc9PjIyokePHhX1n/n5eeP0bNvWt99+q3379hU9fubMmbI9rXbu3Fn2IbaRtKqpl1YjZZeq16FfTMZyo+PdXa5d6RazfD7va3DGDXq98847RXNLo/VcK88mGilXtbRM6/np06fK5/NFr+3v79eePXu817VKo/VcjfuGMBqN1jzOdCybsCzLOKhcbW7pVaW3ZJT+LS0tbel9Qj215sN642I78oPqao2vVvYfv65x9J/OQf9BM7h+Ac3pycBXLpdTJBIpejwSiSiXyxUNQNu29ejRI62srPBteQ/JZDL65ptvGg7YuP3H3aSx9EPu+vp60cqsQqurq9q7d2/dD/+zs7PasWOHFyjZSlqmStOqpXTsbLUOG2EylhsZ766BgYGK491tm+PHjze9P1W1oFc9jebZRKPlqpSWST273wJ++OGH3t5Wtm3rxo0b+tnPfralvG+XavVcSWHZC/fwqvfro5XGV709MNz9Jw8cOKCVlRXF4/G6+2XUmlvcvcRK3zi3S2l+KuXFJM+1jhkbG/M20K30F4vFtjRv1FJrPjQZF37nxy+taK963DFx+vRp/fa3v/XGnvsBsXBsWJZVNM+VznUm46uV/cevaxz9xzwf7rztzuWlc2vpnpiNvgeg//inU/pPI+cx6T+l/TGTyWh1dVUS1y+gWT0X+LIsS3/7299qHvPSSy/p/v37sixLO3fu1LNnz7S5uWn0YQbdzbZtzczM6Fe/+lXFD4ru6pDSD5n1VlxlMhk9e/as4qoLkxUZ7pv49fX1ur9qWCstE9XSMi17vTr0i8lYNjmm0NjYmO7du1cxGGXbthKJhK5du6ZsNqvl5WUlk8mG3yDVC3o12sdq5dk0P6blqpaWaT3HYjFdv35d7777rgYHB3XkyJGGg39+2epYLuWW/Y9//KNGRkaUzWa1tramR48e1dwEttJYdm9xXF5eLnuTKP090L22tqbR0VElk0lls1ndvHmzbOWaVHtuyWQy+vzzz7W2tlb0S0q5XK6h8vtlaWlJH374ofcLrsvLy0okEkX90CTPfpSr0XmjFpP5sN648DM/fumU9gqFQjp58qT+/Oc/6+c//7mWl5e9DbHX1tb04x//2BvjV69eVTwe99JZXl7WnTt3vA9sjY6vavxqL7+ucfSf2mKxWNEvyU1NTWlkZER3796V9PdrRCaT0blz53Tr1i1vnl9YWPD9B1roP/V1Uv9pJK16/WdpaUmJRELLy8vKZrMaGRnRkSNHGgoOcf0Cquu5wJeJw4cPK5lM6siRI3rllVf00ksv6datW1peXpaktn4jju01OzurkZGRqm9yw+GwXn31VV2+fNm7ENV702NZlmZmZvTxxx9XvHCYrPZyv+UZGRmp+Wtw9dIyUS0t07LXq8NuFYvFij4AhcNhxePxhgMlGxsb+utf/1r1+a30sWb4VS4Tbv+8e/eu96GisJyt5Hc9v/32296eXLX2LjMdy34wXUnqisViZfuStYJ7u+iFCxe8N8vhcFiTk5NKJpM1+4dJnttVLslsPuykcWGiE9trZGTEC/BGIhEdPnxYUvFtOGfOnCk6bygU0sDAQEPpoHmd2H9cV65c0cjIiGKxmIaGhnTz5k0vjzMzMxofH/fGcjv3qOxlndx/ap2nXv9xyzU5OekdE4vFND4+3nRetiqI1y/0tp4LfIXDYb344ot1j7l586ay2awikYheeOEF7dmzR+FwWNFotG3fiGN7WZYl27ZrbigtSR988IEkaXh4WIODg5KkaDSqSCRS9gHTsiydPXtW77//fsUPn43uvxOLxTQxMVFx8+16aTWqUlr1ym5ah34wHcv1jmlGJBJpaD8o6fmqnj/96U+6ceNG1aBHI31sOzRaLpN6tm1bV69e9fqnu7pp9+7d+v3vf+9HthvmZz2XrtDq7+/X999/X7UOa41lP9SbW4aGhvTaa69peHh42wNw9WxsbCiXy5XdQtvf30VTQw4AAAvUSURBVK9cLqeNjQ1JZnmud4zJHil+zRsm86HJuNjueaxRrWwvvxXeajQ8PNxwgL+V/cevaxz9x9z4+HjF8epufeLe/ur+xePxhm7Xov80rxP7T73zmPQf27b1/fff19y2gusX0JyeC3yFQiHvvuJC7v3HhR923OXNhZNQpdtPEAzpdFqffvqpdwEZHh7W7du3NTk5WXSvvns7hLuceWxsTOvr60UbN0p/D0R98sknVb8taXRFhlQ5KGGS1laUplWv7KZ16AeTsdzIeK/F3fvFr1udQ6GQPv7446rBL9M+1iy/ymVSzxsbG3r27FlZ/k+cOKFnz5615dtBP+q5mTd1WwmcmmpkJemtW7f00Ucf1dwrbLvt2rWrbO4Kh8PatWtX0WMmea51jMkeKX7NGybzocm48Cs/fmpVe/lpampKH330UdGtRo3uhdnK/uPXNY7+4x/39tfCv0ZuhaX/+KMT+4/Jebqp/wT5+oXe1ZOBr9Jfkqj0ixOS9PDhQ7388svtyipazN3nwf1z9/lIJBLeBaUSy7L04MED7d+/v+ixSoGoubm5on5Xa0VGtaBE6cXDJK16TNMqVVr2rdbhVpiM5UbGey3u5pylH5JyuZx27969pQt3veBXoUp9zA9+lcu0njc2Njp6+ftW6jkcDuvNN98sWzmSz+fV19fn/arRVsbXVjW6ktRd5Tw5OamrV69uS55qGRgYUF9fn9LpdNHj6XRafX19FW9HM8nzVsvl17xhOh/WGxd+5ccvndZeJjKZjB48eKBr165t+234frWXX9c4+k/zQqGQdu/eXXHO9nv7E/pPbZ3efyqdx6T/hEIh9fX1lf1CYqO4fgHV9VzgS3q+h1cul9Ps7Kyk59+M53I5b08I6fmgfPjwoYaGhhQOh5VOp2VZlubn51n11eNSqZT3TY5t2zp79qxeffXVog26Z2dnywJRmUxG6+vr3iRvutorGo0WnePSpUuKx+Pe60zSclmWpXQ6XfXCWi8tk7K3kslYNjnG5S4jL30j6+57VbpRaTKZ1IkTJ8rOU6+eXW7w6/Lly0VpNlLP1fJskp9Gy1UrrXr1PDQ0pFdffbXoDaVt27p8+bJee+01r49NTU217NY7k3o2yc+JEyf0+eefe3uEuXt1FI4dqf74MlX6JjqTyWhubs573mRuSaVSZe2Yy+WK8tiqtnD3OkkkEkW/wJdIJMrmn3p5NjnGhMm84Uf9mI6LVuXHRCe2l4l0Ol30YXl2dlbz8/Pa3NwsGj/1xpcJv9rLr2sc/ad5J06c0KVLl8qu1duB/lNdJ/Yfk/PU6z9ugKhwn7KlpSVduXKlobxI3Xn9AlrC6VH5fN45duyYE41GnWPHjjn5fL7o+XQ67aysrHj/X1xcdKLRqHPq1Clnc3Oz6NjNzU3n+vXrZY+j9fxqi+npaScajXp/Bw8edNLptOM4z/vGwYMHveemp6eLXlvYt0r/3GNN87m5uemcOnWqYj5M06p2XOm56qVlUnbTOmzEF198UfN19cay6TFunmvls7RMi4uLVdNptNyXL1827mOmeTbNT71ymaRVml61ek4kElX7aeHztcrsF5N6TiQSRm1Yeq7SOtzK+KrVfwqPLbwumc4t7jWt8K/0+uZXW1RKq1IdlR5X7/lKeTY5xlS9/mzaNxyn/nxYb1yY5qfX2qtwXE1PT3t1cOrUKef69etFdVWa1vT0tNcupXmvNr4a4Vf/8esaR/+prHRs1jpHvWuGadlN0H+6o/80ch7T9xzu84lEwkkkEm3tP47TmutXocXFxZa8B0Tv+YHjOE67g2/dzrZtTU9P6xe/+AVLNtusW9rC/canFZvAd7tUKqXJyUnv/+Pj4zpz5kwbc4Tt5v6cPOOjcX7PLbRFd6G90Az6D5pB//FfL9Spbdv69a9/rdu3b3uPJRKJtv0aM4Lrh+3OANCLgnwB89vY2BgXvx7iLvHfs2dPm3PSnfycW2iL7hK09rIsS++9955WVlaqHvP666+3ZN+uXkD/QTPoP/4qDAZduXIl0IEg94eGLl682O6sIOBY8QUA6Ai2bevcuXN655132rZvHJ6jLboL7YVm0H/QDPoPgG5A4AsAAAAAAACB1JO/6ggAAAAAAIDgI/AFAAAAAACAQCLwBQAAAAAAgEAi8AUAAAAAAIBAIvAFAAAAAACAQCLwBQAAAAAAgEAi8AUAAAAAAIBAIvAFAAAAAACAQCLwBQAAAAAAgEAi8AUAAAAAAIBAIvAFAAAAAACAQCLwBQAAAAAAgEAi8AUAAAAAAIBA+mG7M1Do+++/b3cWAAAAAAAAEBCs+AIAAAAAAEAgddSKr+3wl7/8pd1ZAALvjTfeaHcWAAAAAAAow4ovAAAAAAAABBKBLwAAAAAAAAQSgS8AAAAAAAAEUlcHvm7fvt3uLAAAAAAAAKBDdW3gi6AXAAAAAAAAaunKwBdBLwAAAAAAANTTdYEvgl4AAAAAAAAw0VWBL4JeAAAAAAAAMNVVga/R0dF2ZwEAAAAAAABdoqsCXxLBLwAAAAAAAJjpusCXRPALAAAAAAAA9XVl4Esi+AUAAAAAAIDaujbwJRH8AgAAAAAAQHVdHfgCAAAAAAAAqiHwBQAAAAAAgEAi8AUAAAAAAIBA+oHjOE67M+H6/vvv250FAAAAAAAABAQrvgAAAAAAABBIHbXiCwAAAAAAAPALK74AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEgEvgAAAAAAABBIBL4AAAAAAAAQSAS+AAAAAAAAEEj/H1TXQE2MEf9WAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "3hay-9C2wY7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(model, params, ex_params, args.restore_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "V0V4aR3kmkOe",
        "outputId": "48e4faed-1d0b-4a28-b58c-ab20f60729ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=*==*==*==*==*==*==*==*==*==*=\n",
            "Loading train data...\n",
            "InputExamples: 62335\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-69b13d28e80d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-2cc08c785840>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, params, ex_params, restore_file)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Load training data and val data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mex_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mex_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7a5db8aa10f9>\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, data_sign, ex_params)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \"\"\"\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# InputExamples to InputFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_sign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mex_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{len(features)} {data_sign} data loaded!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7a5db8aa10f9>\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(self, data_sign, ex_params)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"please notice that the data can only be train/val/test!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             features = convert_examples_to_features(self.params, examples, self.tokenizer, rel2idx, data_sign,\n\u001b[0;32m---> 96\u001b[0;31m                                                     ex_params)\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;31m# save data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6af3efd54caa>\u001b[0m in \u001b[0;36mconvert_examples_to_features\u001b[0;34m(params, examples, tokenizer, rel2idx, data_sign, ex_params)\u001b[0m\n\u001b[1;32m    209\u001b[0m         convert_func = functools.partial(convert, max_text_len=max_text_len, tokenizer=tokenizer, rel2idx=rel2idx,\n\u001b[1;32m    210\u001b[0m                                          data_sign=data_sign, ex_params=ex_params)\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluate"
      ],
      "metadata": {
        "id": "fX5PqL1dXh22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /usr/bin/env python\n",
        "# coding=utf-8\n",
        "\"\"\"Evaluate the model\"\"\"\n",
        "import json\n",
        "import logging\n",
        "import random\n",
        "import argparse\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# from metrics import tag_mapping_nearest, tag_mapping_corres\n",
        "# from utils import Label2IdxSub, Label2IdxObj\n",
        "# import utils\n",
        "# from dataloader import CustomDataLoader\n",
        "\n",
        "# load args\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--seed', type=int, default=2020, help=\"random seed for initialization\")\n",
        "parser.add_argument('--ex_index', type=str, default=1)\n",
        "parser.add_argument('--corpus_type', type=str, default=\"NYT\", help=\"NYT, WebNLG, NYT*, WebNLG*\")\n",
        "parser.add_argument('--device_id', type=int, default=0, help=\"GPU index\")\n",
        "parser.add_argument('--restore_file', default='last', help=\"name of the file containing weights to reload\")\n",
        "\n",
        "parser.add_argument('--corres_threshold', type=float, default=0.5, help=\"threshold of global correspondence\")\n",
        "parser.add_argument('--rel_threshold', type=float, default=0.5, help=\"threshold of relation judgement\")\n",
        "parser.add_argument('--ensure_corres', action='store_true', help=\"correspondence ablation\")\n",
        "parser.add_argument('--ensure_rel', action='store_true', help=\"relation judgement ablation\")\n",
        "parser.add_argument('--emb_fusion', type=str, default=\"concat\", help=\"way to embedding\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCW5wiJpYCZM",
        "outputId": "45e464f6-b3f0-4e60-adb9-42f64e39f034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--emb_fusion'], dest='emb_fusion', nargs=None, const=None, default='concat', type=<class 'str'>, choices=None, help='way to embedding', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def get_metrics(correct_num, predict_num, gold_num):\n",
        "    p = correct_num / predict_num if predict_num > 0 else 0\n",
        "    r = correct_num / gold_num if gold_num > 0 else 0\n",
        "    f1 = 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
        "    return {\n",
        "        'correct_num': correct_num,\n",
        "        'predict_num': predict_num,\n",
        "        'gold_num': gold_num,\n",
        "        'precision': p,\n",
        "        'recall': r,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "\n",
        "def span2str(triples, tokens):\n",
        "    def _concat(token_list):\n",
        "        result = ''\n",
        "        for idx, t in enumerate(token_list):\n",
        "            if idx == 0:\n",
        "                result = t\n",
        "            elif t.startswith('##'):\n",
        "                result += t.lstrip('##')\n",
        "            else:\n",
        "                result += ' ' + t\n",
        "        return result\n",
        "\n",
        "    output = []\n",
        "    for triple in triples:\n",
        "        rel = triple[-1]\n",
        "        sub_tokens = tokens[triple[0][1]:triple[0][-1]]\n",
        "        obj_tokens = tokens[triple[1][1]:triple[1][-1]]\n",
        "        sub = _concat(sub_tokens)\n",
        "        obj = _concat(obj_tokens)\n",
        "        output.append((sub, obj, rel))\n",
        "    return output\n",
        "\n",
        "\n",
        "def evaluate(model, data_iterator, params, ex_params, mark='Val'):\n",
        "    \"\"\"Evaluate the model on `steps` batches.\"\"\"\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "    rel_num = params.rel_num\n",
        "\n",
        "    predictions = []\n",
        "    ground_truths = []\n",
        "    correct_num, predict_num, gold_num = 0, 0, 0\n",
        "\n",
        "    for batch in tqdm(data_iterator, unit='Batch', ascii=True):\n",
        "        # to device\n",
        "        batch = tuple(t.to(params.device) if isinstance(t, torch.Tensor) else t for t in batch)\n",
        "        input_ids, attention_mask, triples, input_tokens = batch\n",
        "        bs, seq_len = input_ids.size()\n",
        "\n",
        "        # inference\n",
        "        with torch.no_grad():\n",
        "            pred_seqs, pre_corres, xi, pred_rels = model(input_ids, attention_mask=attention_mask,\n",
        "                                                         ex_params=ex_params)\n",
        "\n",
        "            # (sum(x_i), seq_len)\n",
        "            pred_seqs = pred_seqs.detach().cpu().numpy()\n",
        "            # (bs, seq_len, seq_len)\n",
        "            pre_corres = pre_corres.detach().cpu().numpy()\n",
        "        if ex_params['ensure_rel']:\n",
        "            # (bs,)\n",
        "            xi = np.array(xi)\n",
        "            # (sum(s_i),)\n",
        "            pred_rels = pred_rels.detach().cpu().numpy()\n",
        "            # decode by per batch\n",
        "            xi_index = np.cumsum(xi).tolist()\n",
        "            # (bs+1,)\n",
        "            xi_index.insert(0, 0)\n",
        "\n",
        "        for idx in range(bs):\n",
        "            if ex_params['ensure_rel']:\n",
        "                pre_triples = tag_mapping_corres(predict_tags=pred_seqs[xi_index[idx]:xi_index[idx + 1]],\n",
        "                                                 pre_corres=pre_corres[idx],\n",
        "                                                 pre_rels=pred_rels[xi_index[idx]:xi_index[idx + 1]],\n",
        "                                                 label2idx_sub=Label2IdxSub,\n",
        "                                                 label2idx_obj=Label2IdxObj)\n",
        "            else:\n",
        "                pre_triples = tag_mapping_corres(predict_tags=pred_seqs[idx * rel_num:(idx + 1) * rel_num],\n",
        "                                                 pre_corres=pre_corres[idx],\n",
        "                                                 label2idx_sub=Label2IdxSub,\n",
        "                                                 label2idx_obj=Label2IdxObj)\n",
        "\n",
        "            gold_triples = span2str(triples[idx], input_tokens[idx])\n",
        "            pre_triples = span2str(pre_triples, input_tokens[idx])\n",
        "            ground_truths.append(list(set(gold_triples)))\n",
        "            predictions.append(list(set(pre_triples)))\n",
        "            # counter\n",
        "            correct_num += len(set(pre_triples) & set(gold_triples))\n",
        "            predict_num += len(set(pre_triples))\n",
        "            gold_num += len(set(gold_triples))\n",
        "    metrics = get_metrics(correct_num, predict_num, gold_num)\n",
        "    # logging loss, f1 and report\n",
        "    metrics_str = \"; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics.items())\n",
        "    logging.info(\"- {} metrics:\\n\".format(mark) + metrics_str)\n",
        "    return metrics, predictions, ground_truths\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "49Kg5ZJBXcos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # args = parser.parse_args()\n",
        "    args =parser.parse_args(args=[])\n",
        "    params = Params(ex_index=args.ex_index, corpus_type=args.corpus_type)\n",
        "    ex_params = {\n",
        "        'corres_threshold': args.mat_threshold,\n",
        "        'rel_threshold': args.rel_pre_threshold,\n",
        "        'ensure_corres': args.ensure_match,\n",
        "        'ensure_rel': args.ensure_relpre,\n",
        "        'emb_fusion': args.emb_fusion\n",
        "    }\n",
        "\n",
        "    torch.cuda.set_device(args.device_id)\n",
        "    print('current device:', torch.cuda.current_device())\n",
        "    mode = args.mode\n",
        "    # Set the random seed for reproducible experiments\n",
        "    random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    params.seed = args.seed\n",
        "\n",
        "    # Set the logger\n",
        "    set_logger()\n",
        "\n",
        "    # get dataloader\n",
        "    dataloader = CustomDataLoader(params)\n",
        "\n",
        "    # Define the model\n",
        "    logging.info('Loading the model...')\n",
        "    logging.info(f'Path: {os.path.join(params.model_dir, args.restore_file)}.pth.tar')\n",
        "    # Reload weights from the saved file\n",
        "    model, optimizer = load_checkpoint(os.path.join(params.model_dir, args.restore_file + '.pth.tar'))\n",
        "    model.to(params.device)\n",
        "    logging.info('- done.')\n",
        "\n",
        "    logging.info(\"Loading the dataset...\")\n",
        "    loader = dataloader.get_dataloader(data_sign=mode, ex_params=ex_params)\n",
        "    logging.info('-done')\n",
        "\n",
        "    logging.info(\"Starting prediction...\")\n",
        "    _, predictions, ground_truths = evaluate(model, loader, params, ex_params, mark=mode)\n",
        "    with open(params.data_dir / f'{mode}_triples.json', 'r', encoding='utf-8') as f_src:\n",
        "        src = json.load(f_src)\n",
        "        df = pd.DataFrame(\n",
        "            {\n",
        "                'text': [sample['text'] for sample in src],\n",
        "                'pre': predictions,\n",
        "                'truth': ground_truths\n",
        "            }\n",
        "        )\n",
        "        df.to_csv(params.ex_dir / f'{mode}_result.csv')\n",
        "    logging.info('-done')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "HD6QyuRQYLdU",
        "outputId": "239d1365-7ab8-423f-e2d8-cdf8d3bfae8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--seed SEED] [--ex_index EX_INDEX]\n",
            "                             [--corpus_type CORPUS_TYPE]\n",
            "                             [--device_id DEVICE_ID] --epoch_num EPOCH_NUM\n",
            "                             [--restore_file RESTORE_FILE]\n",
            "                             [--corres_threshold CORRES_THRESHOLD]\n",
            "                             [--rel_threshold REL_THRESHOLD] [--ensure_corres]\n",
            "                             [--ensure_rel] [--emb_fusion EMB_FUSION]\n",
            "                             [--num_negs NUM_NEGS]\n",
            "ipykernel_launcher.py: error: the following arguments are required: --epoch_num\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}