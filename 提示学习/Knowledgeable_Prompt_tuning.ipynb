{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Knowledgeable Prompt-tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i53KcvTl3KJa",
        "outputId": "c67b7a5d-ce7a-437f-82ba-3046f9277d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openprompt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwv5OquR3Opj",
        "outputId": "c6edbc7b-32b0-4bc1-d6b2-fbd79b418511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openprompt\n",
            "  Downloading openprompt-1.0.0-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 30.4 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.10.0\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 71.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from openprompt) (3.2.5)\n",
            "Requirement already satisfied: tqdm>=4.62.2 in /usr/local/lib/python3.7/dist-packages (from openprompt) (4.64.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from openprompt) (1.4.1)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 81.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from openprompt) (6.0.1)\n",
            "Collecting rouge==1.0.0\n",
            "  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from openprompt) (0.3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge==1.0.0->openprompt) (1.15.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 56.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.10.0->openprompt) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.10.0->openprompt) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.10.0->openprompt) (3.0.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->openprompt) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->openprompt) (0.70.12.2)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 60.4 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 12.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.4 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->openprompt) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->openprompt) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->openprompt) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.10.0->openprompt) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 75.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->openprompt) (21.4.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.10.0->openprompt) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->openprompt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->openprompt) (2022.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->openprompt) (3.17.3)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, responses, huggingface-hub, yacs, transformers, tensorboardX, sentencepiece, rouge, datasets, openprompt\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.6.0 multidict-6.0.2 openprompt-1.0.0 pyyaml-6.0 responses-0.18.0 rouge-1.0.0 sentencepiece-0.1.96 tensorboardX-2.5 tokenizers-0.12.1 transformers-4.19.2 urllib3-1.25.11 xxhash-3.0.0 yacs-0.1.8 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/pacqcudxbn0rk2g/KnowledgeablePromptTuning-main.zip?dl=0  -O KnowledgeablePromptTuning-main.zip\n",
        "!unzip -q KnowledgeablePromptTuning-main.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_SWfH867Fkn",
        "outputId": "02608d75-2a52-44f6-a03a-d41c49d9990f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 07:58:56--  https://www.dropbox.com/s/pacqcudxbn0rk2g/KnowledgeablePromptTuning-main.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/pacqcudxbn0rk2g/KnowledgeablePromptTuning-main.zip [following]\n",
            "--2022-05-23 07:58:57--  https://www.dropbox.com/s/raw/pacqcudxbn0rk2g/KnowledgeablePromptTuning-main.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8b5b89e504c57398284c695321.dl.dropboxusercontent.com/cd/0/inline/BlyuJ7qYc5a0j2tF6lkDbfaTdHSnWFpPQKG98jFz9T5TMSVZfFeWJ70lf5tBbHOHxbYRyiIgQh8iglyrIftgp0oXZFWNnfzTw1qNN_N57bP0rtwXj0FJbqufsh3KCA21ZkjDpCXAvskbmGQSfkj8d2XuVFgBXwzp9IQbo12F3plJ3w/file# [following]\n",
            "--2022-05-23 07:58:57--  https://uc8b5b89e504c57398284c695321.dl.dropboxusercontent.com/cd/0/inline/BlyuJ7qYc5a0j2tF6lkDbfaTdHSnWFpPQKG98jFz9T5TMSVZfFeWJ70lf5tBbHOHxbYRyiIgQh8iglyrIftgp0oXZFWNnfzTw1qNN_N57bP0rtwXj0FJbqufsh3KCA21ZkjDpCXAvskbmGQSfkj8d2XuVFgBXwzp9IQbo12F3plJ3w/file\n",
            "Resolving uc8b5b89e504c57398284c695321.dl.dropboxusercontent.com (uc8b5b89e504c57398284c695321.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc8b5b89e504c57398284c695321.dl.dropboxusercontent.com (uc8b5b89e504c57398284c695321.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BlzWeLrAga2hQprKaZ7KnM1MIUZ_bQ-_m9qapHIqSESvW_x4HoslOz3KiWeLEeDmbsKT4PcMEt_tfOLAtS86F0YoEBJ9nzpCykYJxa0eWCX_9HNolesZTYikHlvIF6fZNxc1OC7uDHqp5aRdNl7icOk-8xJNJXnN4jjz9TUD0AZpS9yKzc89Hsw8jXiso1WRpde0dklDg_52dOv06KQnLnVniSlHrEahAi8hr7CH-Guvda8Qx2M-CstT1LmPf29mxF-_q5GByqF_QKQC_5kwrlb82BqQhx1eSjLiv46eQPwbpa3M7ISPCC7h5ROnEFChnLFbY49IF5Xt3z0xfSfFveCZvOqWyeFjyuOajvxqng6ucAdWF0fokjQnnOYcYvcgtwbrULEjSQR-ymUoefwzXRYJtmmsZK9wfoZ0AZcc7axbkg/file [following]\n",
            "--2022-05-23 07:58:57--  https://uc8b5b89e504c57398284c695321.dl.dropboxusercontent.com/cd/0/inline2/BlzWeLrAga2hQprKaZ7KnM1MIUZ_bQ-_m9qapHIqSESvW_x4HoslOz3KiWeLEeDmbsKT4PcMEt_tfOLAtS86F0YoEBJ9nzpCykYJxa0eWCX_9HNolesZTYikHlvIF6fZNxc1OC7uDHqp5aRdNl7icOk-8xJNJXnN4jjz9TUD0AZpS9yKzc89Hsw8jXiso1WRpde0dklDg_52dOv06KQnLnVniSlHrEahAi8hr7CH-Guvda8Qx2M-CstT1LmPf29mxF-_q5GByqF_QKQC_5kwrlb82BqQhx1eSjLiv46eQPwbpa3M7ISPCC7h5ROnEFChnLFbY49IF5Xt3z0xfSfFveCZvOqWyeFjyuOajvxqng6ucAdWF0fokjQnnOYcYvcgtwbrULEjSQR-ymUoefwzXRYJtmmsZK9wfoZ0AZcc7axbkg/file\n",
            "Reusing existing connection to uc8b5b89e504c57398284c695321.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39334375 (38M) [application/zip]\n",
            "Saving to: ‘KnowledgeablePromptTuning-main.zip’\n",
            "\n",
            "KnowledgeablePrompt 100%[===================>]  37.51M  14.1MB/s    in 2.7s    \n",
            "\n",
            "2022-05-23 07:59:01 (14.1 MB/s) - ‘KnowledgeablePromptTuning-main.zip’ saved [39334375/39334375]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## agnews"
      ],
      "metadata": {
        "id": "QCGGquYU_VrD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "DPe7eYvQ3EPI",
        "outputId": "29b6762d-658d-48b7-f9ee-a07d786c7c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing: 7600it [00:09, 800.61it/s]\n",
            "100%|██████████| 760/760 [03:00<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================\n",
            "dataset agnews\ttemp 1\tseed 144\tverb manual\tcali False\tfilt none\tnocut False\tmaxsplit -1\t\n",
            "Acc: 0.7890789473684211\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bf6052c7596b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{args.result_file}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sfs_scripts/results_fewshot_manual_kpt.txt'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "from openprompt.data_utils.text_classification_dataset import AgnewsProcessor, DBpediaProcessor, ImdbProcessor, AmazonProcessor\n",
        "from openprompt.data_utils.huggingface_dataset import YahooAnswersTopicsProcessor\n",
        "import torch\n",
        "from openprompt.data_utils.utils import InputExample\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "from openprompt import PromptDataLoader\n",
        "from openprompt.prompts import ManualVerbalizer, KnowledgeableVerbalizer\n",
        "from openprompt.prompts import ManualTemplate\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(\"\")\n",
        "parser.add_argument(\"--shot\", type=int, default=0)\n",
        "parser.add_argument(\"--seed\", type=int, default=144)\n",
        "\n",
        "parser.add_argument(\"--plm_eval_mode\", action=\"store_true\")\n",
        "parser.add_argument(\"--model\", type=str, default='roberta')\n",
        "parser.add_argument(\"--model_name_or_path\", default='roberta-large')\n",
        "parser.add_argument(\"--result_file\", type=str, default=\"sfs_scripts/results_fewshot_manual_kpt.txt\")\n",
        "parser.add_argument(\"--openprompt_path\", type=str, default=\"datasets\")\n",
        "\n",
        "parser.add_argument(\"--verbalizer\", default='manual',type=str)\n",
        "parser.add_argument(\"--calibration\", action=\"store_true\")\n",
        "parser.add_argument(\"--nocut\", action=\"store_true\")\n",
        "parser.add_argument(\"--filter\", default=\"none\", type=str)\n",
        "parser.add_argument(\"--template_id\", default=1,type=int)\n",
        "parser.add_argument(\"--max_token_split\", default=-1, type=int)\n",
        "parser.add_argument(\"--dataset\",default='agnews',type=str)\n",
        "parser.add_argument(\"--write_filter_record\", action=\"store_true\")\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "from openprompt.utils.reproduciblity import set_seed\n",
        "set_seed(args.seed)\n",
        "\n",
        "from openprompt.plms import load_plm\n",
        "plm, tokenizer, model_config, WrapperClass = load_plm(args.model, args.model_name_or_path)\n",
        "\n",
        "dataset = {}\n",
        "\n",
        "if args.dataset == \"agnews\":\n",
        "    dataset['train'] = AgnewsProcessor().get_train_examples(f\"{args.openprompt_path}/TextClassification/agnews/\")\n",
        "    dataset['test'] = AgnewsProcessor().get_test_examples(f\"{args.openprompt_path}/TextClassification/agnews/\")\n",
        "    class_labels =AgnewsProcessor().get_labels()\n",
        "    scriptsbase = \"TextClassification/agnews\"\n",
        "    scriptformat = \"txt\"\n",
        "    cutoff=0.5 if (not args.nocut) else 0.0\n",
        "    max_seq_l = 128\n",
        "    batch_s = 10\n",
        "elif args.dataset == \"dbpedia\":\n",
        "    dataset['train'] = DBpediaProcessor().get_train_examples(f\"{args.openprompt_path}/datasets/TextClassification/dbpedia/\")\n",
        "    dataset['test'] = DBpediaProcessor().get_test_examples(f\"{args.openprompt_path}/datasets/TextClassification/dbpedia/\")\n",
        "    class_labels =DBpediaProcessor().get_labels()\n",
        "    scriptsbase = \"TextClassification/dbpedia\"\n",
        "    scriptformat = \"txt\"\n",
        "    cutoff=0.5 if (not args.nocut) else 0.0\n",
        "    max_seq_l = 128\n",
        "    batch_s = 30\n",
        "elif args.dataset == \"yahoo\":\n",
        "    dataset['train'] = YahooAnswersTopicsProcessor().get_train_examples(f\"{args.openprompt_path}/datasets/TextClassification/yahoo_answers_topics/\")\n",
        "    dataset['test'] = YahooAnswersTopicsProcessor().get_test_examples(f\"{args.openprompt_path}/datasets/TextClassification/yahoo_answers_topics/\")\n",
        "    class_labels =YahooAnswersTopicsProcessor().get_labels()\n",
        "    scriptsbase = \"TextClassification/yahoo_answers_topics\"\n",
        "    scriptformat = \"json\"\n",
        "    cutoff=0.5 if (not args.nocut) else 0.0\n",
        "    max_seq_l = 128\n",
        "    batch_s = 30\n",
        "elif args.dataset == \"imdb\":\n",
        "    dataset['train'] = ImdbProcessor().get_train_examples(f\"{args.openprompt_path}/datasets/TextClassification/imdb/\")\n",
        "    dataset['test'] = ImdbProcessor().get_test_examples(f\"{args.openprompt_path}/datasets/TextClassification/imdb/\")\n",
        "    class_labels = ImdbProcessor().get_labels()\n",
        "    scriptsbase = \"TextClassification/imdb\"\n",
        "    scriptformat = \"txt\"\n",
        "    cutoff=0\n",
        "    max_seq_l = 512\n",
        "    batch_s = 5\n",
        "elif args.dataset == \"amazon\":\n",
        "    dataset['train'] = AmazonProcessor().get_train_examples(f\"{args.openprompt_path}/datasets/TextClassification/amazon/\")\n",
        "    dataset['test'] = AmazonProcessor().get_test_examples(f\"{args.openprompt_path}/datasets/TextClassification/amazon/\")\n",
        "    class_labels = AmazonProcessor().get_labels()\n",
        "    scriptsbase = \"TextClassification/amazon\"\n",
        "    scriptformat = \"txt\"\n",
        "    cutoff=0\n",
        "    max_seq_l = 512\n",
        "    batch_s = 5\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "mytemplate = ManualTemplate(tokenizer=tokenizer).from_file(f\"{args.openprompt_path}/scripts/{scriptsbase}/manual_template.txt\", choice=args.template_id)\n",
        "# mytemplate=ManualTemplate(\n",
        "#     text = '{\"placeholder\":\"text_a\"} It was {\"mask\"}',\n",
        "#     tokenizer = tokenizer,\n",
        "# )\n",
        "\n",
        "if args.verbalizer == \"kpt\":\n",
        "    myverbalizer = KnowledgeableVerbalizer(tokenizer, classes=class_labels, candidate_frac=cutoff, max_token_split=args.max_token_split).from_file(f\"{args.openprompt_path}/scripts/{scriptsbase}/knowledgeable_verbalizer.{scriptformat}\")\n",
        "elif args.verbalizer == \"manual\":\n",
        "    myverbalizer = ManualVerbalizer(tokenizer, classes=class_labels).from_file(f\"{args.openprompt_path}/scripts/{scriptsbase}/manual_verbalizer.{scriptformat}\")\n",
        "elif args.verbalizer == \"soft\":\n",
        "    raise NotImplementedError\n",
        "elif args.verbalizer == \"auto\":\n",
        "    raise NotImplementedError\n",
        "\n",
        "# (contextual) calibration\n",
        "if args.calibration:\n",
        "    from openprompt.data_utils.data_sampler import FewShotSampler\n",
        "    support_sampler = FewShotSampler(num_examples_total=200, also_sample_dev=False)\n",
        "    dataset['support'] = support_sampler(dataset['train'], seed=args.seed)\n",
        "\n",
        "    for example in dataset['support']:\n",
        "        example.label = -1 # remove the labels of support set for clarification\n",
        "    support_dataloader = PromptDataLoader(dataset=dataset[\"support\"], template=mytemplate, tokenizer=tokenizer,\n",
        "        tokenizer_wrapper_class=WrapperClass, max_seq_length=max_seq_l, decoder_max_length=3,\n",
        "        batch_size=batch_s,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
        "        truncate_method=\"tail\")\n",
        "\n",
        "\n",
        "from openprompt import PromptForClassification\n",
        "use_cuda = True\n",
        "prompt_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer, freeze_plm=False, plm_eval_mode=args.plm_eval_mode)\n",
        "if use_cuda:\n",
        "    prompt_model=  prompt_model.cuda()\n",
        "\n",
        "\n",
        "myrecord = \"\"\n",
        "# HP\n",
        "if args.calibration:\n",
        "    org_label_words_num = [len(prompt_model.verbalizer.label_words[i]) for i in range(len(class_labels))]\n",
        "    from contextualize_calibration import calibrate\n",
        "    # calculate the calibration logits\n",
        "    cc_logits = calibrate(prompt_model, support_dataloader)\n",
        "    print(\"the calibration logits is\", cc_logits)\n",
        "    myrecord += \"Phase 1 {}\\n\".format(org_label_words_num)\n",
        "\n",
        "    myverbalizer.register_calibrate_logits(cc_logits.mean(dim=0))\n",
        "    new_label_words_num = [len(myverbalizer.label_words[i]) for i in range(len(class_labels))]\n",
        "    myrecord += \"Phase 2 {}\\n\".format(new_label_words_num)\n",
        "\n",
        "\n",
        "    from filter_method import *\n",
        "    if args.filter == \"tfidf_filter\":\n",
        "        record = tfidf_filter(myverbalizer, cc_logits, class_labels)\n",
        "        myrecord += record\n",
        "    elif args.filter == \"none\":\n",
        "        pass\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    # register the logits to the verbalizer so that the verbalizer will divide the calibration probability in producing label logits\n",
        "    # currently, only ManualVerbalizer and KnowledgeableVerbalizer support calibration.\n",
        "\n",
        "#\n",
        "if args.write_filter_record:\n",
        "    record_prefix = \"=\"*20+\"\\n\"\n",
        "    record_prefix += f\"dataset {args.dataset}\\t\"\n",
        "    record_prefix += f\"temp {args.template_id}\\t\"\n",
        "    record_prefix += f\"seed {args.seed}\\t\"\n",
        "    record_prefix += f\"cali {args.calibration}\\t\"\n",
        "    record_prefix += f\"filt {args.filter}\\t\"\n",
        "    record_prefix += \"\\n\"\n",
        "    myrecord = record_prefix +myrecord\n",
        "    with open(\"../sfs_scripts/filter_record_file.txt\",'a')  as fout_rec:\n",
        "        fout_rec.write(myrecord)\n",
        "    exit()\n",
        "\n",
        "\n",
        "# zero-shot test\n",
        "test_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer,\n",
        "    tokenizer_wrapper_class=WrapperClass, max_seq_length=max_seq_l, decoder_max_length=3,\n",
        "    batch_size=batch_s,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
        "    truncate_method=\"tail\")\n",
        "allpreds = []\n",
        "alllabels = []\n",
        "pbar = tqdm(test_dataloader)\n",
        "for step, inputs in enumerate(pbar):\n",
        "    if use_cuda:\n",
        "        inputs = inputs.cuda()\n",
        "    logits = prompt_model(inputs)\n",
        "    labels = inputs['label']\n",
        "    alllabels.extend(labels.cpu().tolist())\n",
        "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "\n",
        "\n",
        "  # roughly ~0.853 when using template 0\n",
        "\n",
        "\n",
        "\n",
        "content_write = \"=\"*20+\"\\n\"\n",
        "content_write += f\"dataset {args.dataset}\\t\"\n",
        "content_write += f\"temp {args.template_id}\\t\"\n",
        "content_write += f\"seed {args.seed}\\t\"\n",
        "content_write += f\"verb {args.verbalizer}\\t\"\n",
        "content_write += f\"cali {args.calibration}\\t\"\n",
        "content_write += f\"filt {args.filter}\\t\"\n",
        "content_write += f\"nocut {args.nocut}\\t\"\n",
        "content_write += f\"maxsplit {args.max_token_split}\\t\"\n",
        "content_write += \"\\n\"\n",
        "content_write += f\"Acc: {acc}\"\n",
        "content_write += \"\\n\\n\"\n",
        "\n",
        "print(content_write)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{args.result_file}\", \"a\") as fout:\n",
        "    fout.write(content_write)"
      ],
      "metadata": {
        "id": "DHF0518A9_6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(allpreds[:10],alllabels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7rpbWGq-MRx",
        "outputId": "bd81ae63-a8d0-43f5-94fb-348f348f4773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 3, 0, 2, 0, 3, 3, 3, 3] [2, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        }
      ]
    }
  ]
}